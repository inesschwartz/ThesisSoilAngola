{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SOC Stock Model Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plan: \n",
    "- **Gather the covariates** using the SCORPAN model \n",
    "- **add harmonized and transformed soc** (response)\n",
    "- **clean and process training data** -- Take out variables with moderate to high amnts of missing data, impute variables w low to mod\n",
    "- **Handle categorical variables** --> Convert text/categorical variables (e.g., moist_color_name, friability) to numeric codes or one-hot encoding.\n",
    "- **Handle numeric predictors**. Scale/normalize if using regression methods sensitive to magnitude (optional, regression kriging is usually OK without scaling).Ensure no extreme outliers that could bias the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prepare Training Data to estimate SOC stock throughout Angola\n",
    "import pandas as pd\n",
    "\n",
    "training_data = pd.read_csv(\"/Users/inesschwartz/Desktop/training_data_with_log_soc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean and process dataset\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Calculate missing percentage per column\n",
    "missing_pct = training_data.isna().mean() * 100\n",
    "\n",
    "# Categorize by missingness\n",
    "missing_category = pd.cut(\n",
    "    missing_pct,\n",
    "    bins=[-1, 10, 30, 100],\n",
    "    labels=['Low (<10%)', 'Moderate (10–30%)', 'High (>30%)']\n",
    ")\n",
    "\n",
    "# Combine into a summary table\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Missing_Percent': missing_pct,\n",
    "    'Category': missing_category\n",
    "}).sort_values(by='Missing_Percent', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns to drop due to high missingness (>30%) and organic_carbon:\n",
      "['gypsum', 'caco3', 'structure_class', 'structure_type', 'conductivity', 'friability', 'total_n', 'exchangable_bases_sum', 'pore_diameter', 'thick_contents_count', 'thick_contents_nature', 'atm_15', 'p205', 'root_diameter', 'eg', 'durability', 'organic_carbon']\n"
     ]
    }
   ],
   "source": [
    "# Identify high missingness columns and drop from dataset\n",
    "high_missing_cols = missing_summary[missing_summary['Category'] == 'High (>30%)'].index.tolist()\n",
    "\n",
    "# Add organic_carbon to the drop list\n",
    "cols_to_drop = high_missing_cols + ['organic_carbon']\n",
    "\n",
    "print(\"Columns to drop due to high missingness (>30%) and organic_carbon:\")\n",
    "print(cols_to_drop)\n",
    "\n",
    "# Drop these columns from the dataset (ignore errors if a column is not present)\n",
    "training_data.drop(columns=cols_to_drop, inplace=True, errors='ignore')\n",
    "\n",
    "# Save new dataframe to CSV\n",
    "training_data.to_csv(\"/Users/inesschwartz/Desktop/training_data_cleaning.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing_Percent</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>moist_color_name</th>\n",
       "      <td>29.315961</td>\n",
       "      <td>Moderate (10–30%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moist_value</th>\n",
       "      <td>26.927253</td>\n",
       "      <td>Moderate (10–30%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moist_chroma</th>\n",
       "      <td>26.818675</td>\n",
       "      <td>Moderate (10–30%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moist_hue</th>\n",
       "      <td>24.647123</td>\n",
       "      <td>Moderate (10–30%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>structure_degree</th>\n",
       "      <td>21.715527</td>\n",
       "      <td>Moderate (10–30%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>free_iron</th>\n",
       "      <td>19.001086</td>\n",
       "      <td>Moderate (10–30%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moisture_degree</th>\n",
       "      <td>18.892508</td>\n",
       "      <td>Moderate (10–30%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eq_hum</th>\n",
       "      <td>17.698154</td>\n",
       "      <td>Moderate (10–30%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pore_quantity</th>\n",
       "      <td>15.092291</td>\n",
       "      <td>Moderate (10–30%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dry_color_name</th>\n",
       "      <td>10.423453</td>\n",
       "      <td>Moderate (10–30%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cec</th>\n",
       "      <td>10.423453</td>\n",
       "      <td>Moderate (10–30%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Missing_Percent           Category\n",
       "moist_color_name        29.315961  Moderate (10–30%)\n",
       "moist_value             26.927253  Moderate (10–30%)\n",
       "moist_chroma            26.818675  Moderate (10–30%)\n",
       "moist_hue               24.647123  Moderate (10–30%)\n",
       "structure_degree        21.715527  Moderate (10–30%)\n",
       "free_iron               19.001086  Moderate (10–30%)\n",
       "moisture_degree         18.892508  Moderate (10–30%)\n",
       "eq_hum                  17.698154  Moderate (10–30%)\n",
       "pore_quantity           15.092291  Moderate (10–30%)\n",
       "dry_color_name          10.423453  Moderate (10–30%)\n",
       "cec                     10.423453  Moderate (10–30%)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Moderate missingness\n",
    "moderate_missing = missing_summary[missing_summary['Category'] == 'Moderate (10–30%)']\n",
    "moderate_missing\n",
    "\n",
    "#drop moist_color_name, moist_color_name, moist_chroma, moist_hue\n",
    "# replace missing/blank \"structure_degree\", \"pore_quantity\", \"compaction\" categorical descriptions with \"missing\"\n",
    "# replace missing/black \"eq_hum\", \"cec\", \"ph_kcl\",\"dry_hue\", \"dry_chroma\",  numeric descriptions with n/a or null (whatever best for floats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing_Percent</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>compaction</th>\n",
       "      <td>9.337676</td>\n",
       "      <td>Low (&lt;10%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ph_kcl</th>\n",
       "      <td>7.817590</td>\n",
       "      <td>Low (&lt;10%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soluble_sodium</th>\n",
       "      <td>5.646037</td>\n",
       "      <td>Low (&lt;10%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dry_hue</th>\n",
       "      <td>4.668838</td>\n",
       "      <td>Low (&lt;10%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dry_chroma</th>\n",
       "      <td>4.234528</td>\n",
       "      <td>Low (&lt;10%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precip_coldest_quarter32733</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>Low (&lt;10%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_temp_coldest_month32733</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>Low (&lt;10%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_temp_wettest_quarter32733</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>Low (&lt;10%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_temp_warmest_quarter32733</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>Low (&lt;10%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_soc_stock</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>Low (&lt;10%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Missing_Percent    Category\n",
       "compaction                             9.337676  Low (<10%)\n",
       "ph_kcl                                 7.817590  Low (<10%)\n",
       "soluble_sodium                         5.646037  Low (<10%)\n",
       "dry_hue                                4.668838  Low (<10%)\n",
       "dry_chroma                             4.234528  Low (<10%)\n",
       "...                                         ...         ...\n",
       "precip_coldest_quarter32733            0.000000  Low (<10%)\n",
       "min_temp_coldest_month32733            0.000000  Low (<10%)\n",
       "mean_temp_wettest_quarter32733         0.000000  Low (<10%)\n",
       "mean_temp_warmest_quarter32733         0.000000  Low (<10%)\n",
       "log_soc_stock                          0.000000  Low (<10%)\n",
       "\n",
       "[69 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# low missingness\n",
    "low_missing = missing_summary[missing_summary['Category'] == 'Low (<10%)']\n",
    "low_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## handle moderate and low missing data via knn imputation = uses similarity between samples\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "training_data[moderate_missing] = imputer.fit_transform(training_data[moderate_missing])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "identify numeric vs categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric predictors:\n",
      "['site_info_id', 'X_coord', 'Y_coord', 'MRVBF', 'RLD', 'aspect', 'aspect_classes', 'aspect_cos', 'aspect_sin', 'dem_filledfiltered', 'flow_accumulation', 'relief', 'ridge_levels', 'roughness', 'slope', 'twi_300m', 'valleydepth2', 'annual_mean_temp', 'annual_precip2', 'isothermality_32733', 'max_temp_warmest_month32733', 'mean_temp_driest_quarter32733', 'mean_temp_warmest_quarter32733', 'mean_temp_wettest_quarter32733', 'min_temp_coldest_month32733', 'precip_coldest_quarter32733', 'precip_driest_month32733', 'precip_driest_quarter32733', 'precip_seasonality2', 'precip_warmest_quarter32733', 'precip_wettest_month32733', 'precip_wettest_quarter32733', 'temp_annual_range32733', 'temp_seasonality32733', 'landsurface_value', 'eco_value', 'eco_subclass_code', 'eco_class_code', 'eco_division_code', 'faosoil_id', 'thick_sand', 'fine_sand', 'silt', 'clay', 'eq_hum', 'free_iron', 'organic_material', 'ph_h2o', 'ph_kcl', 'cec', 'soluble_sodium', 'porosity', 'bulk_density', 'horizon_layer', 'year', 'dry_value', 'dry_chroma', 'moist_value', 'moist_chroma']\n",
      "\n",
      "Categorical predictors:\n",
      "['profile', 'district', 'landsurface_label', 'eco_subclass_clean', 'eco_class_clean', 'eco_division_clean', 'FAOSOIL', 'DOMSOI', 'africa_lithology_90m.img.vat_lithology', 'moisture_degree', 'root_quantity', 'texture', 'structure_degree', 'pore_quantity', 'dry_color_name', 'dry_hue', 'moist_color_name', 'moist_hue', 'compaction']\n"
     ]
    }
   ],
   "source": [
    "## identify numerica vs categorical variables\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "training_data\n",
    "\n",
    "# Separate numeric and categorical predictors\n",
    "numeric_cols = training_data.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "categorical_cols = training_data.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Remove response variable from predictors\n",
    "numeric_cols.remove('log_soc_stock')  # response variable\n",
    "\n",
    "print(\"Numeric predictors:\")\n",
    "print(numeric_cols)\n",
    "\n",
    "print(\"\\nCategorical predictors:\")\n",
    "print(categorical_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns included: ['district', 'landsurface_label', 'eco_subclass_clean', 'eco_class_clean', 'eco_division_clean', 'DOMSOI', 'africa_lithology_90m.img.vat_lithology', 'structure_degree', 'pore_quantity', 'dry_hue']\n",
      "Categorical columns skipped (too many categories): ['profile', 'FAOSOIL', 'moisture_degree', 'root_quantity', 'texture', 'dry_color_name', 'compaction']\n",
      "Numeric columns: ['site_info_id', 'X_coord', 'Y_coord', 'MRVBF', 'RLD', 'aspect', 'aspect_classes', 'aspect_cos', 'aspect_sin', 'dem_filledfiltered', 'flow_accumulation', 'relief', 'ridge_levels', 'roughness', 'slope', 'twi_300m', 'valleydepth2', 'annual_mean_temp', 'annual_precip2', 'isothermality_32733', 'max_temp_warmest_month32733', 'mean_temp_driest_quarter32733', 'mean_temp_warmest_quarter32733', 'mean_temp_wettest_quarter32733', 'min_temp_coldest_month32733', 'precip_coldest_quarter32733', 'precip_driest_month32733', 'precip_driest_quarter32733', 'precip_seasonality2', 'precip_warmest_quarter32733', 'precip_wettest_month32733', 'precip_wettest_quarter32733', 'temp_annual_range32733', 'temp_seasonality32733', 'landsurface_value', 'eco_value', 'eco_subclass_code', 'eco_class_code', 'eco_division_code', 'faosoil_id', 'thick_sand', 'fine_sand', 'silt', 'clay', 'eq_hum', 'free_iron', 'organic_material', 'ph_h2o', 'ph_kcl', 'cec', 'soluble_sodium', 'porosity', 'bulk_density', 'horizon_layer', 'year', 'dry_value', 'dry_chroma', 'moist_value']\n",
      "\n",
      "Top 20 Features by Importance:\n",
      "                       feature  importance\n",
      "189           organic_material    0.512087\n",
      "197                       year    0.063109\n",
      "171        precip_seasonality2    0.056035\n",
      "195               bulk_density    0.030017\n",
      "196              horizon_layer    0.016083\n",
      "184                  fine_sand    0.014356\n",
      "192                        cec    0.013156\n",
      "144                    X_coord    0.011704\n",
      "147                        RLD    0.011586\n",
      "191                     ph_kcl    0.011526\n",
      "153          flow_accumulation    0.010932\n",
      "173  precip_wettest_month32733    0.010155\n",
      "161             annual_precip2    0.010005\n",
      "188                  free_iron    0.009940\n",
      "190                     ph_h2o    0.008790\n",
      "143               site_info_id    0.008112\n",
      "187                     eq_hum    0.008029\n",
      "185                       silt    0.007722\n",
      "159               valleydepth2    0.007613\n",
      "183                 thick_sand    0.006807\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# ======================================================\n",
    "# --- Handle missing data and drop unwanted columns ---\n",
    "# ======================================================\n",
    "\n",
    "# Drop specific unwanted columns\n",
    "cols_to_drop = ['moist_color_name', 'moist_chroma', 'moist_hue']\n",
    "training_data.drop(columns=cols_to_drop, inplace=True, errors='ignore')\n",
    "\n",
    "# Replace missing categorical values with \"missing\"\n",
    "missing_cat_cols = ['structure_degree', 'pore_quantity', 'compaction']\n",
    "for col in missing_cat_cols:\n",
    "    if col in training_data.columns:\n",
    "        training_data[col] = training_data[col].fillna(\"missing\").replace(\"\", \"missing\")\n",
    "\n",
    "# Replace missing numeric values with NaN (null for floats)\n",
    "missing_num_cols = ['eq_hum', 'cec', 'ph_kcl', 'dry_hue', 'dry_chroma']\n",
    "for col in missing_num_cols:\n",
    "    if col in training_data.columns:\n",
    "        training_data[col] = training_data[col].replace(\"\", np.nan)\n",
    "\n",
    "# ======================================================\n",
    "# --- Feature selection with categorical + numeric ---\n",
    "# ======================================================\n",
    "\n",
    "# Separate target\n",
    "y = training_data['log_soc_stock']\n",
    "X = training_data.drop(columns=['log_soc_stock'], errors='ignore')\n",
    "\n",
    "# Automatically detect categorical and numeric columns\n",
    "all_categorical = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Safeguard: keep only categorical columns with <= 50 unique categories\n",
    "cat_limit = 50\n",
    "categorical_cols = [col for col in all_categorical if X[col].nunique() <= cat_limit]\n",
    "\n",
    "print(\"Categorical columns included:\", categorical_cols)\n",
    "print(\"Categorical columns skipped (too many categories):\",\n",
    "      [col for col in all_categorical if col not in categorical_cols])\n",
    "print(\"Numeric columns:\", numeric_cols)\n",
    "\n",
    "# Preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
    "        ('num', 'passthrough', numeric_cols)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# Model\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "# Fit model\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "# Get feature names after OHE\n",
    "ohe_feature_names = []\n",
    "if categorical_cols:\n",
    "    ohe_feature_names = pipeline.named_steps['preprocessor'] \\\n",
    "        .named_transformers_['cat'] \\\n",
    "        .get_feature_names_out(categorical_cols)\n",
    "\n",
    "all_feature_names = np.concatenate([ohe_feature_names, numeric_cols])\n",
    "\n",
    "# Feature importances\n",
    "importances = pipeline.named_steps['model'].feature_importances_\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': all_feature_names,\n",
    "    'importance': importances\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 20 Features by Importance:\")\n",
    "print(feature_importance.head(20))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
