{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making training dataset\n",
    "\n",
    "1. bring on chemical and physical soil variables (*to what depth??*)\n",
    "\n",
    "2. extract vectors (soil type, lithology, and ecosystem type) per profile/sample site\n",
    "3. extract rasters (bioclimatic and DEM/terrain) per profile/sample site\n",
    "4. merge into one training dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lab_sample_id</th>\n",
       "      <th>analysis_id</th>\n",
       "      <th>morpho_id</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>profile</th>\n",
       "      <th>soil_biology_id</th>\n",
       "      <th>eg</th>\n",
       "      <th>thick_sand</th>\n",
       "      <th>fine_sand</th>\n",
       "      <th>silt</th>\n",
       "      <th>...</th>\n",
       "      <th>dry_chroma</th>\n",
       "      <th>moist_color_name</th>\n",
       "      <th>moist_hue</th>\n",
       "      <th>moist_value</th>\n",
       "      <th>moist_chroma</th>\n",
       "      <th>compaction</th>\n",
       "      <th>durability</th>\n",
       "      <th>friability</th>\n",
       "      <th>thick_contents_count</th>\n",
       "      <th>thick_contents_nature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>458</td>\n",
       "      <td>Bg_113/57_4_1</td>\n",
       "      <td>Bg_113/57_4_1</td>\n",
       "      <td>5040</td>\n",
       "      <td>113_57</td>\n",
       "      <td></td>\n",
       "      <td>59.0</td>\n",
       "      <td>42.9</td>\n",
       "      <td>13.1</td>\n",
       "      <td>10.9</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>894</td>\n",
       "      <td>Bg_253/57_4_1</td>\n",
       "      <td>Bg_253/57_4_1</td>\n",
       "      <td>5456</td>\n",
       "      <td>253_57</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Irregularmente pouco compacto e medianamente c...</td>\n",
       "      <td>Muito firme (com alguns torroes da mesma cor, ...</td>\n",
       "      <td></td>\n",
       "      <td>Raro</td>\n",
       "      <td>Saibro quartzoso e de gres</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>B_109/62_1_1</td>\n",
       "      <td>B_109/62_1_1</td>\n",
       "      <td>11011</td>\n",
       "      <td>109_62</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>48.5</td>\n",
       "      <td>17.6</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Pardo-avermelhado</td>\n",
       "      <td>5YR</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Pequena</td>\n",
       "      <td>Brando e brando a ligeiramente duro</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1549</td>\n",
       "      <td>Cb_20/59_3_1</td>\n",
       "      <td>Cb_20/59_3_1</td>\n",
       "      <td>7277</td>\n",
       "      <td>20_59</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Pardo-avermelhado</td>\n",
       "      <td>5YR</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5965</td>\n",
       "      <td>Mj_27/63_3_1</td>\n",
       "      <td>Mj_27/63_3_1</td>\n",
       "      <td>13391</td>\n",
       "      <td>27_63</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Laranja a pardo-avermelhado-escuro</td>\n",
       "      <td>5YR</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Media a grande</td>\n",
       "      <td>Ligeiramente duro</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   lab_sample_id    analysis_id      morpho_id sample_id profile  \\\n",
       "0            458  Bg_113/57_4_1  Bg_113/57_4_1      5040  113_57   \n",
       "1            894  Bg_253/57_4_1  Bg_253/57_4_1      5456  253_57   \n",
       "2              7   B_109/62_1_1   B_109/62_1_1     11011  109_62   \n",
       "3           1549   Cb_20/59_3_1   Cb_20/59_3_1      7277   20_59   \n",
       "4           5965   Mj_27/63_3_1   Mj_27/63_3_1     13391   27_63   \n",
       "\n",
       "  soil_biology_id    eg  thick_sand  fine_sand  silt  ...  dry_chroma  \\\n",
       "0                  59.0        42.9       13.1  10.9  ...         6.0   \n",
       "1                   NaN         NaN        0.0   0.0  ...         7.0   \n",
       "2                   1.0        15.3       48.5  17.6  ...         2.0   \n",
       "3                   NaN         NaN        NaN   NaN  ...         6.0   \n",
       "4                   NaN         NaN        NaN   NaN  ...         6.0   \n",
       "\n",
       "                     moist_color_name moist_hue  moist_value moist_chroma  \\\n",
       "0                                                                           \n",
       "1                                                                           \n",
       "2                   Pardo-avermelhado       5YR          4.0          3.0   \n",
       "3                   Pardo-avermelhado       5YR          4.0          4.0   \n",
       "4  Laranja a pardo-avermelhado-escuro       5YR          4.0          6.0   \n",
       "\n",
       "                                          compaction  \\\n",
       "0                                                      \n",
       "1  Irregularmente pouco compacto e medianamente c...   \n",
       "2                                            Pequena   \n",
       "3                                                      \n",
       "4                                     Media a grande   \n",
       "\n",
       "                                          durability  friability  \\\n",
       "0                                                                  \n",
       "1  Muito firme (com alguns torroes da mesma cor, ...               \n",
       "2                Brando e brando a ligeiramente duro               \n",
       "3                                                                  \n",
       "4                                  Ligeiramente duro               \n",
       "\n",
       "  thick_contents_count       thick_contents_nature  \n",
       "0                                                   \n",
       "1                 Raro  Saibro quartzoso e de gres  \n",
       "2                                                   \n",
       "3                                                   \n",
       "4                                                   \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load data from database\n",
    "\n",
    "# === 1. Imports ===\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# === 2. Connect to PostgreSQL ===\n",
    "USER = \"inesschwartz\"\n",
    "PASSWORD = \"aa4862aa\"\n",
    "HOST = \"localhost\"\n",
    "PORT = \"5432\"\n",
    "DB = \"soils_angola\"\n",
    "\n",
    "engine = create_engine(f\"postgresql://{USER}:{PASSWORD}@{HOST}:{PORT}/{DB}\")\n",
    "\n",
    "# === 3. Load tables ===\n",
    "analyses = pd.read_sql(\"SELECT * FROM analyses\", engine)\n",
    "morpho = pd.read_sql(\"SELECT * FROM morpho\", engine)\n",
    "site_info = pd.read_sql(\"SELECT * FROM site_info\", engine)\n",
    "samples = pd.read_sql(\"SELECT * FROM samples\", engine)\n",
    "\n",
    "\n",
    "# Subset analyses, keep all morpho columns\n",
    "analyses_subset = analyses.copy()\n",
    "morpho_subset = morpho.copy()\n",
    "\n",
    "# Filter only profiles present in site_info\n",
    "valid_profiles = site_info['profile'].dropna().unique()\n",
    "analyses_filtered = analyses_subset[analyses_subset['profile'].isin(valid_profiles)]\n",
    "morpho_filtered = morpho_subset[morpho_subset['profile'].isin(valid_profiles)]\n",
    "\n",
    "# Ensure merge keys have same dtype\n",
    "analyses_filtered['sample_id'] = analyses_filtered['sample_id'].astype(str)\n",
    "morpho_filtered['sample_id'] = morpho_filtered['sample_id'].astype(str)\n",
    "\n",
    "# === 5. Merge analyses and morpho ===\n",
    "combined_data = pd.merge(\n",
    "    analyses_filtered,\n",
    "    morpho_filtered,\n",
    "    on=['profile', 'morpho_id'],\n",
    "    how='inner',\n",
    "    suffixes=('', '_morpho')\n",
    ")\n",
    "\n",
    "combined_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lab_sample_id</th>\n",
       "      <th>analysis_id</th>\n",
       "      <th>morpho_id</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>profile</th>\n",
       "      <th>soil_biology_id</th>\n",
       "      <th>eg</th>\n",
       "      <th>thick_sand</th>\n",
       "      <th>fine_sand</th>\n",
       "      <th>silt</th>\n",
       "      <th>...</th>\n",
       "      <th>site_info_id</th>\n",
       "      <th>X_coord</th>\n",
       "      <th>Y_coord</th>\n",
       "      <th>district</th>\n",
       "      <th>geo_features_id</th>\n",
       "      <th>climate_id</th>\n",
       "      <th>topo_id</th>\n",
       "      <th>soil_type_id</th>\n",
       "      <th>geom</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>458</td>\n",
       "      <td>Bg_113/57_4_1</td>\n",
       "      <td>Bg_113/57_4_1</td>\n",
       "      <td>5040</td>\n",
       "      <td>113_57</td>\n",
       "      <td></td>\n",
       "      <td>59.0</td>\n",
       "      <td>42.9</td>\n",
       "      <td>13.1</td>\n",
       "      <td>10.9</td>\n",
       "      <td>...</td>\n",
       "      <td>2400</td>\n",
       "      <td>14.624539</td>\n",
       "      <td>-13.315070</td>\n",
       "      <td>Benguela</td>\n",
       "      <td>197</td>\n",
       "      <td>197</td>\n",
       "      <td>197</td>\n",
       "      <td>112</td>\n",
       "      <td>0101000020E6100000000000A0C33F2D40000000E050A1...</td>\n",
       "      <td>1957.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>894</td>\n",
       "      <td>Bg_253/57_4_1</td>\n",
       "      <td>Bg_253/57_4_1</td>\n",
       "      <td>5456</td>\n",
       "      <td>253_57</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2045</td>\n",
       "      <td>15.001662</td>\n",
       "      <td>-12.341700</td>\n",
       "      <td>Benguela</td>\n",
       "      <td>1945</td>\n",
       "      <td>1945</td>\n",
       "      <td>1945</td>\n",
       "      <td>1194</td>\n",
       "      <td>0101000020E6100000000000E0D9002E4000000040F3AE...</td>\n",
       "      <td>1957.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>B_109/62_1_1</td>\n",
       "      <td>B_109/62_1_1</td>\n",
       "      <td>11011</td>\n",
       "      <td>109_62</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>48.5</td>\n",
       "      <td>17.6</td>\n",
       "      <td>...</td>\n",
       "      <td>2523</td>\n",
       "      <td>16.778372</td>\n",
       "      <td>-13.896562</td>\n",
       "      <td>Bie</td>\n",
       "      <td>137</td>\n",
       "      <td>137</td>\n",
       "      <td>137</td>\n",
       "      <td>76</td>\n",
       "      <td>0101000020E61000000000006043C73040000000200ACB...</td>\n",
       "      <td>1962.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1549</td>\n",
       "      <td>Cb_20/59_3_1</td>\n",
       "      <td>Cb_20/59_3_1</td>\n",
       "      <td>7277</td>\n",
       "      <td>20_59</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>33</td>\n",
       "      <td>12.553629</td>\n",
       "      <td>-4.762017</td>\n",
       "      <td>Cabinda</td>\n",
       "      <td>1288</td>\n",
       "      <td>1288</td>\n",
       "      <td>1288</td>\n",
       "      <td>789</td>\n",
       "      <td>0101000020E610000000000040751B2940000000404E0C...</td>\n",
       "      <td>1959.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5965</td>\n",
       "      <td>Mj_27/63_3_1</td>\n",
       "      <td>Mj_27/63_3_1</td>\n",
       "      <td>13391</td>\n",
       "      <td>27_63</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1060</td>\n",
       "      <td>17.135303</td>\n",
       "      <td>-9.595469</td>\n",
       "      <td>Malanje</td>\n",
       "      <td>2105</td>\n",
       "      <td>2105</td>\n",
       "      <td>2105</td>\n",
       "      <td>1289</td>\n",
       "      <td>0101000020E610000000000040A322314000000060E130...</td>\n",
       "      <td>1963.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   lab_sample_id    analysis_id      morpho_id sample_id profile  \\\n",
       "0            458  Bg_113/57_4_1  Bg_113/57_4_1      5040  113_57   \n",
       "1            894  Bg_253/57_4_1  Bg_253/57_4_1      5456  253_57   \n",
       "2              7   B_109/62_1_1   B_109/62_1_1     11011  109_62   \n",
       "3           1549   Cb_20/59_3_1   Cb_20/59_3_1      7277   20_59   \n",
       "4           5965   Mj_27/63_3_1   Mj_27/63_3_1     13391   27_63   \n",
       "\n",
       "  soil_biology_id    eg  thick_sand  fine_sand  silt  ...  site_info_id  \\\n",
       "0                  59.0        42.9       13.1  10.9  ...          2400   \n",
       "1                   NaN         NaN        0.0   0.0  ...          2045   \n",
       "2                   1.0        15.3       48.5  17.6  ...          2523   \n",
       "3                   NaN         NaN        NaN   NaN  ...            33   \n",
       "4                   NaN         NaN        NaN   NaN  ...          1060   \n",
       "\n",
       "     X_coord    Y_coord  district geo_features_id climate_id  topo_id  \\\n",
       "0  14.624539 -13.315070  Benguela             197        197      197   \n",
       "1  15.001662 -12.341700  Benguela            1945       1945     1945   \n",
       "2  16.778372 -13.896562       Bie             137        137      137   \n",
       "3  12.553629  -4.762017   Cabinda            1288       1288     1288   \n",
       "4  17.135303  -9.595469   Malanje            2105       2105     2105   \n",
       "\n",
       "   soil_type_id                                               geom    year  \n",
       "0           112  0101000020E6100000000000A0C33F2D40000000E050A1...  1957.0  \n",
       "1          1194  0101000020E6100000000000E0D9002E4000000040F3AE...  1957.0  \n",
       "2            76  0101000020E61000000000006043C73040000000200ACB...  1962.0  \n",
       "3           789  0101000020E610000000000040751B2940000000404E0C...  1959.0  \n",
       "4          1289  0101000020E610000000000040A322314000000060E130...  1963.0  \n",
       "\n",
       "[5 rows x 112 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === 6. Join with site_info ===\n",
    "merged_final = pd.merge(\n",
    "    combined_data,\n",
    "    site_info,\n",
    "    on='profile',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# === 7. Optionally merge 'year' from samples ===\n",
    "if 'sample_id' in samples.columns and 'year' in samples.columns:\n",
    "    merged_final = pd.merge(\n",
    "        merged_final,\n",
    "        samples[['sample_id', 'year']],\n",
    "        on='sample_id',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "merged_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lab_sample_id',\n",
       " 'analysis_id',\n",
       " 'morpho_id',\n",
       " 'sample_id',\n",
       " 'profile',\n",
       " 'soil_biology_id',\n",
       " 'eg',\n",
       " 'thick_sand',\n",
       " 'fine_sand',\n",
       " 'silt',\n",
       " 'clay',\n",
       " 'eq_hum',\n",
       " 'atm_1/3',\n",
       " 'atm_15',\n",
       " 'caco3',\n",
       " 'gypsum',\n",
       " 'free_iron',\n",
       " 'organic_carbon',\n",
       " 'total_n',\n",
       " 'p205',\n",
       " 'organic_material',\n",
       " 'ph_h2o',\n",
       " 'ph_kcl',\n",
       " 'Ca++',\n",
       " 'Mg++',\n",
       " 'Na+',\n",
       " 'K+',\n",
       " 'exchangable_bases_sum',\n",
       " 'cec',\n",
       " 'v',\n",
       " 'conductivity',\n",
       " 'soluble_sodium',\n",
       " 'Min_<0,002',\n",
       " 'Min_0,05-0,02',\n",
       " 'Min_0,2-0,05',\n",
       " 'Min_2-0,2',\n",
       " 'porosity',\n",
       " 'bulk_density',\n",
       " 'sample_depth',\n",
       " 'sample_id_morpho',\n",
       " 'horizon_layer',\n",
       " 'upper_depth',\n",
       " 'lower_depth',\n",
       " 'moisture_degree',\n",
       " 'root_quantity',\n",
       " 'root_diameter',\n",
       " 'texture',\n",
       " 'structure_type',\n",
       " 'structure_class',\n",
       " 'structure_degree',\n",
       " 'pore_diameter',\n",
       " 'pore_quantity',\n",
       " 'pore_shape',\n",
       " 'dry_color_name',\n",
       " 'dry_hue',\n",
       " 'dry_value',\n",
       " 'dry_chroma',\n",
       " 'moist_color_name',\n",
       " 'moist_hue',\n",
       " 'moist_value',\n",
       " 'moist_chroma',\n",
       " 'compaction',\n",
       " 'durability',\n",
       " 'friability',\n",
       " 'thick_contents_count',\n",
       " 'thick_contents_nature',\n",
       " 'site_info_id',\n",
       " 'X_coord',\n",
       " 'Y_coord',\n",
       " 'district',\n",
       " 'year']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of columns to drop\n",
    "cols_to_drop = [\n",
    "    'geo_features_id',\n",
    "    'climate_id',\n",
    "    'topo_id',\n",
    "    'soil_type_id',\n",
    "    'geom',\n",
    "    'field_sample_code',  \n",
    "    'depth',\n",
    "    'al',\n",
    "    'si',\n",
    "    'p',\n",
    "    's',\n",
    "    'cl',\n",
    "    'ti',\n",
    "    'cr',\n",
    "    'mn',\n",
    "    'fe',\n",
    "    'co',\n",
    "    'ni',\n",
    "    'cu',\n",
    "    'zn',\n",
    "    'arsenic',\n",
    "    'se',\n",
    "    'rb',\n",
    "    'sr',\n",
    "    'zr',\n",
    "    'nb',\n",
    "    'mo',\n",
    "    'cd',\n",
    "    'sn',\n",
    "    'sb',\n",
    "    'ba',\n",
    "    'ta',\n",
    "    'w',\n",
    "    'pt',\n",
    "    'au',\n",
    "    'hg',\n",
    "    'tl',\n",
    "    'pb',\n",
    "    'bi',\n",
    "    'th',\n",
    "    'u'\n",
    "]\n",
    "\n",
    "# Drop these columns if they exist in the DataFrame\n",
    "merged_final = merged_final.drop(columns=[col for col in cols_to_drop if col in merged_final.columns])\n",
    "\n",
    "# Check the remaining columns\n",
    "list(merged_final.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "k should be 1 <= k <= 5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 74\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m numeric_cols:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;66;03m# Use spline for key variables (SOC, total_n, bulk_density)\u001b[39;00m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morganic_carbon\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_n\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbulk_density\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m---> 74\u001b[0m         profile_harmonized[col] \u001b[38;5;241m=\u001b[39m \u001b[43mfit_mpspline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdepth_top\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprofile\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mupper_depth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdepth_bottom\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprofile\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlower_depth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprofile\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlam\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtarget_depths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;66;03m# Thickness-weighted average\u001b[39;00m\n\u001b[1;32m     83\u001b[0m         thickness \u001b[38;5;241m=\u001b[39m profile[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlower_depth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m profile[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupper_depth\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[0;32mIn[18], line 37\u001b[0m, in \u001b[0;36mfit_mpspline\u001b[0;34m(depth_top, depth_bottom, values, lam, target_depths)\u001b[0m\n\u001b[1;32m     34\u001b[0m values \u001b[38;5;241m=\u001b[39m values[unique_indices]\n\u001b[1;32m     36\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;28mlen\u001b[39m(values)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m spline \u001b[38;5;241m=\u001b[39m \u001b[43mUnivariateSpline\u001b[49m\u001b[43m(\u001b[49m\u001b[43munique_midpoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m top, bottom \u001b[38;5;241m=\u001b[39m target_depths\n\u001b[1;32m     40\u001b[0m integral \u001b[38;5;241m=\u001b[39m spline\u001b[38;5;241m.\u001b[39mintegral(top, bottom)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/scipy/interpolate/_fitpack2.py:238\u001b[0m, in \u001b[0;36mUnivariateSpline.__init__\u001b[0;34m(self, x, y, w, bbox, k, s, ext, check_finite)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y, w\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, bbox\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28;01mNone\u001b[39;00m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, s\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    236\u001b[0m              ext\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, check_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 238\u001b[0m     x, y, w, bbox, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mext \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[43mcheck_finite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# _data == x,y,w,xb,xe,k,s,n,t,c,fp,fpint,nrdata,ier\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m FITPACK_LOCK:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/scipy/interpolate/_fitpack2.py:275\u001b[0m, in \u001b[0;36mUnivariateSpline.validate_input\u001b[0;34m(x, y, w, bbox, k, s, ext, check_finite)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbbox shape should be (2,)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m k \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m--> 275\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk should be 1 <= k <= 5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m s \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms should be s >= 0.0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: k should be 1 <= k <= 5"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "from collections import Counter\n",
    "\n",
    "# ------------------------------\n",
    "# 1) Mass-preserving spline function\n",
    "# ------------------------------\n",
    "def fit_mpspline(depth_top, depth_bottom, values, lam=1.0, target_depths=[0,30]):\n",
    "    depth_top = np.array(depth_top)\n",
    "    depth_bottom = np.array(depth_bottom)\n",
    "    values = np.array(values)\n",
    "    \n",
    "    mask = ~np.isnan(depth_top) & ~np.isnan(depth_bottom) & ~np.isnan(values)\n",
    "    depth_top = depth_top[mask]\n",
    "    depth_bottom = depth_bottom[mask]\n",
    "    values = values[mask]\n",
    "    \n",
    "    n = len(values)\n",
    "    if n == 0:\n",
    "        return np.nan\n",
    "    elif n == 1:\n",
    "        return values[0]\n",
    "    elif n == 2:\n",
    "        thickness = depth_bottom - depth_top\n",
    "        return np.average(values, weights=thickness)\n",
    "    \n",
    "    midpoints = (depth_top + depth_bottom)/2\n",
    "    sort_idx = np.argsort(midpoints)\n",
    "    midpoints = midpoints[sort_idx]\n",
    "    values = values[sort_idx]\n",
    "    \n",
    "    unique_midpoints, unique_indices = np.unique(midpoints, return_index=True)\n",
    "    values = values[unique_indices]\n",
    "    \n",
    "    k = min(3, len(values)-1)\n",
    "    spline = UnivariateSpline(unique_midpoints, values, s=lam, k=k)\n",
    "    \n",
    "    top, bottom = target_depths\n",
    "    integral = spline.integral(top, bottom)\n",
    "    return integral / (bottom - top)\n",
    "\n",
    "# ------------------------------\n",
    "# 2) Identify variable types\n",
    "# ------------------------------\n",
    "# Drop IDs, coordinates, depth columns\n",
    "drop_cols = ['lab_sample_id','analysis_id','morpho_id','sample_id','sample_id_morpho',\n",
    "             'site_info_id','X_coord','Y_coord','profile','upper_depth','lower_depth','sample_depth']\n",
    "\n",
    "# Separate numeric and categorical variables\n",
    "numeric_cols = merged_final.select_dtypes(include=np.number).columns.tolist()\n",
    "numeric_cols = [col for col in numeric_cols if col not in drop_cols]\n",
    "\n",
    "categorical_cols = merged_final.select_dtypes(include=['object','category']).columns.tolist()\n",
    "categorical_cols = [col for col in categorical_cols if col not in drop_cols]\n",
    "\n",
    "# ------------------------------\n",
    "# 3) Create harmonized dataset per profile\n",
    "# ------------------------------\n",
    "profiles = merged_final['profile'].unique()\n",
    "harmonized_list = []\n",
    "\n",
    "for pid in profiles:\n",
    "    profile = merged_final[merged_final['profile'] == pid].copy()\n",
    "    if profile.empty:\n",
    "        continue\n",
    "    \n",
    "    profile_harmonized = {'profile': pid}\n",
    "    \n",
    "    # 3a) Numeric variables -> spline or thickness-weighted average\n",
    "    for col in numeric_cols:\n",
    "        # Use spline for key variables (SOC, total_n, bulk_density)\n",
    "        if col in ['organic_carbon','total_n','bulk_density']:\n",
    "            profile_harmonized[col] = fit_mpspline(\n",
    "                depth_top=profile['upper_depth'],\n",
    "                depth_bottom=profile['lower_depth'],\n",
    "                values=profile[col],\n",
    "                lam=1.0,\n",
    "                target_depths=[0,30]\n",
    "            )\n",
    "        else:\n",
    "            # Thickness-weighted average\n",
    "            thickness = profile['lower_depth'] - profile['upper_depth']\n",
    "            valid_mask = ~profile[col].isna() & ~thickness.isna()\n",
    "            if valid_mask.sum() > 0:\n",
    "                profile_harmonized[col] = np.average(profile[col][valid_mask], weights=thickness[valid_mask])\n",
    "            else:\n",
    "                profile_harmonized[col] = np.nan\n",
    "    \n",
    "    # 3b) Categorical / ordinal variables -> mode\n",
    "    for col in categorical_cols:\n",
    "        vals = profile[col].dropna()\n",
    "        if not vals.empty:\n",
    "            profile_harmonized[col] = vals.mode().iloc[0]  # dominant category\n",
    "        else:\n",
    "            profile_harmonized[col] = np.nan\n",
    "    \n",
    "    # Optional: include coordinates and other profile-level metadata\n",
    "    meta_cols = ['X_coord','Y_coord','district','year']\n",
    "    for col in meta_cols:\n",
    "        if col in profile.columns:\n",
    "            profile_harmonized[col] = profile[col].iloc[0]\n",
    "    \n",
    "    harmonized_list.append(profile_harmonized)\n",
    "\n",
    "# ------------------------------\n",
    "# 4) Convert to DataFrame\n",
    "# ------------------------------\n",
    "profile_0_30cm = pd.DataFrame(harmonized_list)\n",
    "\n",
    "# Check\n",
    "print(profile_0_30cm.head())\n",
    "print(f\"Shape: {profile_0_30cm.shape} (profiles x variables)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract soil data, lithology and ecoystem data from .tif to csv per profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import os\n",
    "import re  # for regex\n",
    "\n",
    "# --- Input paths ---\n",
    "points_path = \"/Volumes/One_Touch/angola_soils_thesis/GIS_Angola/data_processed/usable_site_info_epsg32733.gpkg\"\n",
    "soil_path = \"/Volumes/One_Touch/angola_soils_thesis/GIS_Angola/data_processed/angola_soil_data2_32733.gpkg\"\n",
    "lithology_path = \"/Volumes/One_Touch/angola_soils_thesis/GIS_Angola/data_processed/lithology2.gpkg\"\n",
    "\n",
    "# --- Load data ---\n",
    "points = gpd.read_file(points_path)\n",
    "soil = gpd.read_file(soil_path)[[\"FAOSOIL\", \"DOMSOI\", \"faosoil_id\", \"geometry\"]]\n",
    "lithology = gpd.read_file(lithology_path)[[\"africa_lithology_90m.img.vat_lithology\", \"geometry\"]]\n",
    "\n",
    "# --- Ensure CRS matches ---\n",
    "if points.crs != soil.crs:\n",
    "    soil = soil.to_crs(points.crs)\n",
    "if points.crs != lithology.crs:\n",
    "    lithology = lithology.to_crs(points.crs)\n",
    "\n",
    "# --- Spatial join ---\n",
    "points_soil = gpd.sjoin(points, soil, how=\"left\", predicate=\"intersects\")\n",
    "\n",
    "# Drop index_right from first join\n",
    "if \"index_right\" in points_soil.columns:\n",
    "    points_soil = points_soil.drop(columns=[\"index_right\"])\n",
    "\n",
    "points_soil_lith = gpd.sjoin(points_soil, lithology, how=\"left\", predicate=\"intersects\")\n",
    "\n",
    "# Drop index_right from second join\n",
    "if \"index_right\" in points_soil_lith.columns:\n",
    "    points_soil_lith = points_soil_lith.drop(columns=[\"index_right\"])\n",
    "\n",
    "# --- Remove numbers from lithology column ---\n",
    "# Example: \"1. Carbonate\" → \"Carbonate\"\n",
    "points_soil_lith[\"africa_lithology_90m.img.vat_lithology\"] = points_soil_lith[\n",
    "    \"africa_lithology_90m.img.vat_lithology\"\n",
    "].apply(lambda x: re.sub(r\"^\\d+\\.\\s*\", \"\", str(x)))\n",
    "\n",
    "# Drop multiple columns\n",
    "points_soil_lith_clean = points_soil_lith\n",
    "points_soil_lith_clean = points_soil_lith_clean.drop(columns=[\"geo_features_id\", \"climate_id\", \"topo_id\", \"soil_type_id\"])\n",
    "points_soil_lith_clean = points_soil_lith_clean.drop(columns=[\"geometry\"])\n",
    "\n",
    "# --- Save clean CSV ---\n",
    "output_csv = \"/Volumes/One_Touch/angola_soils_thesis/GIS_Angola/tables/soil_samples_with_vector_clean.csv\"\n",
    "points_soil_lith_clean.to_csv(output_csv, index=False)\n",
    "\n",
    "print(\"✅ CSV saved at:\", output_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the landsurfaceforms raster values per profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV saved at: /Volumes/One_Touch/angola_thesis_gis/GIS_Angola/tables/landsurface_sample_points.csv\n"
     ]
    }
   ],
   "source": [
    "## extract the “landsurfaceforms” raster values at your sample points\n",
    "\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "# --- Load your points ---\n",
    "points_path = \"/Volumes/One_Touch/angola_thesis_gis/GIS_Angola/tables/joined_landsurf_test.gpkg\"\n",
    "points = gpd.read_file(points_path)\n",
    "\n",
    "# --- Load your raster ---\n",
    "raster_path = \"/Volumes/One_Touch/angola_thesis_gis/GIS_Angola/data_processed/landsurfaceforms/landsurfaceforms.tif\"\n",
    "raster = rasterio.open(raster_path)\n",
    "\n",
    "# --- Ensure points are in the same CRS as the raster ---\n",
    "if points.crs != raster.crs:\n",
    "    points = points.to_crs(raster.crs)\n",
    "\n",
    "# --- Extract raster values at point locations ---\n",
    "coords = [(x, y) for x, y in zip(points.geometry.x, points.geometry.y)]\n",
    "points['landsurface_value'] = [val[0] for val in raster.sample(coords)]\n",
    "\n",
    "# --- Optional: convert codes to descriptive categories ---\n",
    "# Example: update according to your raster's legend\n",
    "landsurface_lookup = {\n",
    "    1: \"smooth_plains\",\n",
    "    2: \"irregular_plains\",\n",
    "    3: \"escarpments\",\n",
    "    4: \"hills\",\n",
    "    5: \"breaks\",\n",
    "    6: \"low_mountains\",\n",
    "    7: \"high_mountains/deep_canyons\"\n",
    "}\n",
    "points['landsurface_label'] = points['landsurface_value'].map(landsurface_lookup)\n",
    "\n",
    "# --- Save to CSV ---\n",
    "output_csv = \"/Volumes/One_Touch/angola_thesis_gis/GIS_Angola/tables/landsurface_sample_points.csv\"\n",
    "points.drop(columns='geometry').to_csv(output_csv, index=False)\n",
    "\n",
    "print(\"CSV saved at:\", output_csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bioclimatic rasters to csv for each sample point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CSV saved at: /Volumes/One_Touch/angola_soils_thesis/GIS_Angola/tables/soil_samples_with_bioclim1.csv\n"
     ]
    }
   ],
   "source": [
    "#### bioclimatic rasters to csv for each sample point\n",
    "\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# --- Input paths ---\n",
    "points_path = \"/Volumes/One_Touch/angola_soils_thesis/GIS_Angola/data_processed/usable_site_info_epsg32733.gpkg\"\n",
    "bioclimraster_folder = \"/Volumes/One_Touch/angola_soils_thesis/GIS_Angola/data_processed/bioclimatic32733/\"\n",
    "\n",
    "# --- Load point data ---\n",
    "points = gpd.read_file(points_path)\n",
    "\n",
    "# --- Get list of rasters (assuming .tif files) ---\n",
    "bioclimraster_files = sorted(glob.glob(os.path.join(bioclimraster_folder, \"*.tif\")))\n",
    "\n",
    "# --- Reproject points once (using first raster as reference) ---\n",
    "if bioclimraster_files:\n",
    "    with rasterio.open(bioclimraster_files[0]) as src_ref:\n",
    "        if points.crs != src_ref.crs:\n",
    "            points = points.to_crs(src_ref.crs)\n",
    "\n",
    "# --- Extract raster values for each point ---\n",
    "coords = [(x, y) for x, y in zip(points.geometry.x, points.geometry.y)]\n",
    "\n",
    "for raster_path in bioclimraster_files:\n",
    "    name = os.path.splitext(os.path.basename(raster_path))[0]  # e.g. bio1.tif → \"bio1\"\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        values = []\n",
    "        for val in src.sample(coords):\n",
    "            # Handle NoData / masked values\n",
    "            if val is None or np.isnan(val[0]):\n",
    "                values.append(np.nan)\n",
    "            else:\n",
    "                values.append(val[0])\n",
    "        points[name] = values\n",
    "\n",
    "# --- Save to CSV (without geometry column) ---\n",
    "output_csv = \"/Volumes/One_Touch/angola_soils_thesis/GIS_Angola/tables/soil_samples_with_bioclim1.csv\"\n",
    "points.drop(columns=\"geometry\").to_csv(output_csv, index=False)\n",
    "\n",
    "print(\"✅ CSV saved at:\", output_csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## terrain / DEM features to csv for each sample point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Extracted MRVBF\n",
      "✅ Extracted RLD\n",
      "✅ Extracted aspect\n",
      "✅ Extracted aspect_classes\n",
      "✅ Extracted aspect_cos\n",
      "✅ Extracted aspect_sin\n",
      "✅ Extracted dem_filledfiltered\n",
      "✅ Extracted flow_accumulation\n",
      "✅ Extracted relief\n",
      "✅ Extracted ridge_levels\n",
      "✅ Extracted roughness\n",
      "✅ Extracted slope\n",
      "✅ Extracted twi_300m\n",
      "✅ Extracted valleydepth2\n",
      "✅ CSV saved at: /Volumes/One_Touch/angola_soils_thesis/GIS_Angola/tables/soil_samples_with_terrain.csv\n"
     ]
    }
   ],
   "source": [
    "## terrain / DEM features to csv for each sample point\n",
    "\n",
    "\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# --- Input paths ---\n",
    "points_path = \"/Volumes/One_Touch/angola_soils_thesis/GIS_Angola/data_processed/usable_site_info_epsg32733.gpkg\"\n",
    "terrain_folder = \"/Volumes/One_Touch/angola_soils_thesis/GIS_Angola/data_processed/DEM_characteristics\"\n",
    "\n",
    "# --- Load point data ---\n",
    "points = gpd.read_file(points_path)\n",
    "\n",
    "# --- Get list of rasters (assuming .tif files) ---\n",
    "terrain_files = sorted(glob.glob(os.path.join(terrain_folder, \"*.tif\")))\n",
    "\n",
    "# --- Reproject points once (using first raster as reference) ---\n",
    "if terrain_files:\n",
    "    with rasterio.open(terrain_files[0]) as src_ref:\n",
    "        if points.crs != src_ref.crs:\n",
    "            points = points.to_crs(src_ref.crs)\n",
    "\n",
    "# --- Extract raster values for each point ---\n",
    "coords = [(x, y) for x, y in zip(points.geometry.x, points.geometry.y)]\n",
    "\n",
    "for raster_path in terrain_files:\n",
    "    name = os.path.splitext(os.path.basename(raster_path))[0]\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        values = []\n",
    "        for val in src.sample(coords):\n",
    "            if val is None or np.isnan(val[0]):\n",
    "                values.append(np.nan)\n",
    "            else:\n",
    "                values.append(val[0])\n",
    "        points[name] = values\n",
    "    print(f\"✅ Extracted {name}\")\n",
    "\n",
    "# --- Add categorical labels for aspect_classes ---\n",
    "if \"aspect_classes\" in points.columns:\n",
    "    aspect_lookup = {\n",
    "        1: \"N\", 2: \"NE\", 3: \"E\", 4: \"SE\",\n",
    "        5: \"S\", 6: \"SW\", 7: \"W\", 8: \"NW\"\n",
    "    }\n",
    "    points[\"aspect_label\"] = points[\"aspect_classes\"].map(aspect_lookup)\n",
    "\n",
    "# --- ridge_levels left as numeric (bands 100–500).\n",
    "#     If you want labels like \"100-200m\", we can map them here later.\n",
    "\n",
    "# --- Save to CSV (without geometry column) ---\n",
    "output_csv = \"/Volumes/One_Touch/angola_soils_thesis/GIS_Angola/tables/soil_samples_with_terrain.csv\"\n",
    "points.drop(columns=\"geometry\").to_csv(output_csv, index=False)\n",
    "\n",
    "print(\"✅ CSV saved at:\", output_csv)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
