{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## random forest model to calculate soc map\n",
    "\n",
    "## what I need: \n",
    "# 1) cov_final = \"/Users/inesschwartz/Desktop/final_training_dataset.csv\"\n",
    "# X = cov_final(drop.log_soc_stock)\n",
    "# Y = cov_final(log_soc_stock)\n",
    "# W = sample_weight\n",
    "# 1km aligned raster stack covariates for prediction (not yet built)\n",
    "\n",
    "#steps to build model\n",
    "# 1)  train weighted RF using  sample_weight\n",
    "# 2) Out of sample CV predictions per point\n",
    "# 3) spacial cross val\n",
    "    # Split points into spatial folds / blocks\n",
    "    # Train model on training folds with sample_weight\n",
    "    # Predict held-out fold\n",
    "    #          Compute metrics: weighted RMSE, R², bias\n",
    "    #       Diagnostic plots: observed vs predicted, residual spatial patterns \n",
    "# 4) Random Forest SOC map apply final, tuned RF model (trained with the declustering sample_weight) to the 1 km raster stack of predictor covariates.\n",
    "# 5) Uncertainty: model variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create prediction grid aligned with final covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================\n",
    "# Create prediction grid aligned with final covariates\n",
    "# ================================================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# -----------------------------\n",
    "# 1️⃣ Load final training dataset\n",
    "# -----------------------------\n",
    "cov_final = pd.read_csv(\"/Users/inesschwartz/Desktop/final_training_dataset.csv\")\n",
    "predictor_cols = [col for col in cov_final.columns if col not in ['log_soc_stock', 'sample_weight']]\n",
    "\n",
    "# -----------------------------\n",
    "# 2️⃣ Define raster folders / files\n",
    "# -----------------------------\n",
    "dem_folder = \"/Volumes/One_Touch/angola_soils_thesis/GIS_Angola/data_processed/covariates_rasters/dem_1km/\"\n",
    "bioclim_folder = \"/Volumes/One_Touch/angola_soils_thesis/GIS_Angola/data_processed/covariates_rasters/bioclimatic32733_cleaned/\"\n",
    "\n",
    "# Individual categorical rasters\n",
    "ecosystem_raster = \"/Volumes/One_Touch/angola_soils_thesis/GIS_Angola/data_processed/covariates_rasters/labelled_ecosystems32733_1km.tif\"\n",
    "litho_raster = \"/Volumes/One_Touch/angola_soils_thesis/GIS_Angola/data_processed/covariates_rasters/lithology_1km.tif\"\n",
    "landsurface_raster = \"/Volumes/One_Touch/angola_soils_thesis/GIS_Angola/data_processed/covariates_rasters/landsurfaceforms_1km.tif\"\n",
    "soil_raster = \"/Volumes/One_Touch/angola_soils_thesis/GIS_Angola/data_processed/covariates_rasters/angola_soil_data_raster_1km.tif\"\n",
    "\n",
    "# Helper to list valid .tif files only\n",
    "def list_valid_tifs(folder):\n",
    "    return [\n",
    "        os.path.join(folder, f)\n",
    "        for f in os.listdir(folder)\n",
    "        if f.endswith('.tif') and not f.startswith('._')\n",
    "    ]\n",
    "\n",
    "terrain_files = list_valid_tifs(dem_folder)\n",
    "bioclim_files = list_valid_tifs(bioclim_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bioclim filenames only:\n",
      "['isothermality_32733.tif', 'max_temp_warmest_month32733.tif', 'mean_temp_driest_quarter32733.tif', 'mean_temp_warmest_quarter32733.tif', 'mean_temp_wettest_quarter32733.tif', 'min_temp_coldest_month32733.tif', 'precip_coldest_quarter32733.tif', 'precip_driest_month32733.tif', 'precip_driest_quarter32733.tif', 'precip_warmest_quarter32733.tif', 'precip_wettest_month32733.tif', 'precip_wettest_quarter32733.tif', 'temp_annual_range32733.tif', 'temp_seasonality32733.tif', 'precip_seasonality2.tif', 'annual_precip2.tif', 'annual_mean_temp.tif', 'mean_temp_coldest_quarter32733.tif', '2mean_temp_coldest_quarter32733.tif']\n"
     ]
    }
   ],
   "source": [
    "#  get the filenames (without full path)\n",
    "print(\"\\nbioclim filenames only:\")\n",
    "print([os.path.basename(f) for f in bioclim_files])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['X_coord', 'Y_coord', 'site_info_id', 'profile', 'district',\n",
       "       'landsurface_value', 'litho_value', 'formation', 'annual_mean_temp',\n",
       "       'annual_precip', 'isothermality', 'precip_driest_month',\n",
       "       'precip_seasonality', 'precip_wettest_month', 'temp_annual_range',\n",
       "       'temp_seasonality', 'MRVBF', 'RLD', 'aspect', 'aspect_cos',\n",
       "       'aspect_sin', 'DEM', 'flow_accumulation', 'relief', 'slope', 'TWI',\n",
       "       'valleydepth', 'faosoil_id', 'log_soc_stock'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "DataSourceError",
     "evalue": "/Volumes/One_Touch/angola_soils_thesis/GIS_Angola/data_processed/angola_soil_data2_32733.gpkg: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDataSourceError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 104\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# 5️⃣ Clip to soil polygons\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[1;32m    103\u001b[0m soil_gpkg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Volumes/One_Touch/angola_soils_thesis/GIS_Angola/data_processed/angola_soil_data2_32733.gpkg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 104\u001b[0m soil \u001b[38;5;241m=\u001b[39m \u001b[43mgpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43msoil_gpkg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m covariate_stack \u001b[38;5;241m=\u001b[39m covariate_stack\u001b[38;5;241m.\u001b[39mrio\u001b[38;5;241m.\u001b[39mclip(soil\u001b[38;5;241m.\u001b[39mgeometry, soil\u001b[38;5;241m.\u001b[39mcrs, drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# 6️⃣ Flatten to 2D DataFrame for prediction\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/geopandas/io/file.py:294\u001b[0m, in \u001b[0;36m_read_file\u001b[0;34m(filename, bbox, mask, columns, rows, engine, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m             from_bytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyogrio\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read_file_pyogrio\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiona\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mis_file_like(filename):\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/geopandas/io/file.py:547\u001b[0m, in \u001b[0;36m_read_file_pyogrio\u001b[0;34m(path_or_bytes, bbox, mask, rows, **kwargs)\u001b[0m\n\u001b[1;32m    538\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    539\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minclude_fields\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore_fields\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m keywords are deprecated, and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    540\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future release. You can use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m keyword \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    543\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m    544\u001b[0m     )\n\u001b[1;32m    545\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minclude_fields\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 547\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpyogrio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pyogrio/geopandas.py:265\u001b[0m, in \u001b[0;36mread_dataframe\u001b[0;34m(path_or_buffer, layer, encoding, columns, read_geometry, force_2d, skip_features, max_features, where, bbox, mask, fids, sql, sql_dialect, fid_as_index, use_arrow, on_invalid, arrow_to_pandas_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_arrow:\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;66;03m# For arrow, datetimes are read as is.\u001b[39;00m\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;66;03m# For numpy IO, datetimes are read as string values to preserve timezone info\u001b[39;00m\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;66;03m# as numpy does not directly support timezones.\u001b[39;00m\n\u001b[1;32m    264\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatetime_as_string\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mread_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mread_geometry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_geometry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgdal_force_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[43msql\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[43msql_dialect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msql_dialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_fids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfid_as_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_arrow:\n\u001b[1;32m    285\u001b[0m     meta, table \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pyogrio/raw.py:198\u001b[0m, in \u001b[0;36mread\u001b[0;34m(path_or_buffer, layer, encoding, columns, read_geometry, force_2d, skip_features, max_features, where, bbox, mask, fids, sql, sql_dialect, return_fids, datetime_as_string, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Read OGR data source into numpy arrays.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03mIMPORTANT: non-linear geometry types (e.g., MultiSurface) are converted\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    194\u001b[0m \n\u001b[1;32m    195\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    196\u001b[0m dataset_kwargs \u001b[38;5;241m=\u001b[39m _preprocess_options_key_value(kwargs) \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m--> 198\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mogr_read\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mget_vsi_path_or_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mread_geometry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_geometry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_features\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_mask_to_wkb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43msql\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43msql_dialect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msql_dialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_fids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_fids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatetime_as_string\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatetime_as_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32mpyogrio/_io.pyx:1240\u001b[0m, in \u001b[0;36mpyogrio._io.ogr_read\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpyogrio/_io.pyx:220\u001b[0m, in \u001b[0;36mpyogrio._io.ogr_open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mDataSourceError\u001b[0m: /Volumes/One_Touch/angola_soils_thesis/GIS_Angola/data_processed/angola_soil_data2_32733.gpkg: No such file or directory"
     ]
    }
   ],
   "source": [
    "# ================================================\n",
    "# Fast prediction grid aligned with final covariates\n",
    "# ================================================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rioxarray as rxr\n",
    "from shapely.geometry import Point\n",
    "import xarray as xr\n",
    "\n",
    "# -----------------------------\n",
    "# 1️⃣ Load final training dataset\n",
    "# -----------------------------\n",
    "cov_final = pd.read_csv(\"/Users/inesschwartz/Desktop/final_training_dataset.csv\")\n",
    "predictor_cols = [c for c in cov_final.columns if c not in ['log_soc_stock', 'sample_weight']]\n",
    "\n",
    "# -----------------------------\n",
    "# 2️⃣ Define raster folders / files\n",
    "# -----------------------------\n",
    "dem_folder = \"/Volumes/One_Touch/angola_soils_thesis/GIS_Angola/data_processed/covariates_rasters/\"\n",
    "bioclim_folder = \"/Volumes/One_Touch/angola_soils_thesis/GIS_Angola/data_processed/covariates_rasters/bioclimatic32733_cleaned/\"\n",
    "\n",
    "ecosystem_raster = \"/Volumes/One_Touch/angola_soils_thesis/GIS_Angola/data_processed/covariates_rasters/labelled_ecosystems32733_1km.tif\"\n",
    "litho_raster = \"/Volumes/One_Touch/angola_soils_thesis/GIS_Angola/data_processed/covariates_rasters/lithology_1km.tif\"\n",
    "landsurface_raster = \"/Volumes/One_Touch/angola_soils_thesis/GIS_Angola/data_processed/covariates_rasters/landsurfaceforms_1km.tif\"\n",
    "soil_raster = \"/Volumes/One_Touch/angola_soils_thesis/GIS_Angola/data_processed/covariates_rasters/angola_soil_data_raster_1km.tif\"\n",
    "\n",
    "# -----------------------------\n",
    "# 3️⃣ Map raster filenames to predictor columns\n",
    "# -----------------------------\n",
    "raster_to_colname = {\n",
    "    # terrain\n",
    "    \"aspect_cos_1km\": \"aspect_cos\",\n",
    "    \"aspect_sin_1km.tif\": \"aspect_sin\",\n",
    "    \"dem_filledfiltered_1km.tif\": \"DEM\",\n",
    "    \"MRVBF_1km.tif\": \"MRVBF\",\n",
    "    \"RLD_1km.tif\": \"RLD\",\n",
    "    \"flow_accumulation_1km.tif\": \"flow_accumulation\",\n",
    "    \"relief_1km.tif\": \"relief\",\n",
    "    \"slope_1km.tif\": \"slope\",\n",
    "    \"twi_300m_1km.tif\": \"TWI\",\n",
    "    \"valleydepth2_1km.tif\": \"valleydepth\",\n",
    "    # bioclim\n",
    "    \"annual_mean_temp.tif\": \"annual_mean_temp\",\n",
    "    \"precip_seasonality2.tif\": \"precip_seasonality\",\n",
    "    \"precip_wettest_month.tif\": \"precip_wettest_month\",\n",
    "    \"temp_annual_range32733.tif\": \"temp_annual_range\",\n",
    "    \"temp_seasonality32733.tif\": \"temp_seasonality\",\n",
    "    # categorical\n",
    "    ecosystem_raster: \"formation\",\n",
    "    landsurface_raster: \"landsurface_value\",\n",
    "    litho_raster: \"litho_value\",\n",
    "    soil_raster: \"faosoil_id\"\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# 4️⃣ Load rasters as a stack using rioxarray\n",
    "# -----------------------------\n",
    "all_rasters = list(raster_to_colname.keys())\n",
    "stack_list = []\n",
    "\n",
    "for raster in all_rasters:\n",
    "    da = rxr.open_rasterio(raster, masked=True).squeeze()\n",
    "    da = da.rename(raster_to_colname[raster])\n",
    "    stack_list.append(da)\n",
    "\n",
    "# Merge into a single xarray dataset\n",
    "covariate_stack = xr.merge(stack_list)\n",
    "\n",
    "# -----------------------------\n",
    "# 5️⃣ Clip to soil polygons\n",
    "# -----------------------------\n",
    "soil_gpkg = \"/Volumes/One_Touch/angola_soils_thesis/GIS_Angola/data_processed/angola_soil_data2_32733.gpkg\"\n",
    "soil = gpd.read_file(soil_gpkg)\n",
    "\n",
    "covariate_stack = covariate_stack.rio.clip(soil.geometry, soil.crs, drop=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 6️⃣ Flatten to 2D DataFrame for prediction\n",
    "# -----------------------------\n",
    "flat_stack = covariate_stack.to_array().stack(pixel=(\"y\", \"x\")).transpose(\"pixel\", \"variable\")\n",
    "X_grid = flat_stack.to_pandas()\n",
    "X_grid.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Handle categorical variables\n",
    "categorical_cols = [v for v in raster_to_colname.values() if X_grid[v].dtype != float]\n",
    "for col in categorical_cols:\n",
    "    X_grid[col] = X_grid[col].astype(str)\n",
    "X_grid_encoded = pd.get_dummies(X_grid, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Align columns to training dataset\n",
    "for col in predictor_cols:\n",
    "    if col not in X_grid_encoded.columns:\n",
    "        X_grid_encoded[col] = 0\n",
    "X_grid_encoded = X_grid_encoded[predictor_cols]\n",
    "\n",
    "# -----------------------------\n",
    "# 7️⃣ Save prediction grid\n",
    "# -----------------------------\n",
    "out_csv = \"/Volumes/One_Touch/angola_soils_thesis/GIS_Angola/prediction_grid_covariates_fast.csv\"\n",
    "X_grid_encoded.to_csv(out_csv, index=False)\n",
    "\n",
    "print(\"✅ Prediction grid ready:\", X_grid_encoded.shape)\n",
    "print(f\"Saved to: {out_csv}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model\n",
    "\n",
    "# ================================================\n",
    "# Weighted Random Forest for SOC mapping\n",
    "# ================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# -----------------------------\n",
    "# 1️⃣ Load final training dataset\n",
    "# -----------------------------\n",
    "cov_final = pd.read_csv(\"/Users/inesschwartz/Desktop/final_training_dataset.csv\")\n",
    "\n",
    "# Separate predictors, target, and sample weights\n",
    "X = cov_final.drop(columns=['log_soc_stock', 'sample_weight'])\n",
    "y = cov_final['log_soc_stock']\n",
    "sample_weight = cov_final['sample_weight']\n",
    "\n",
    "predictor_cols = X.columns.tolist()\n",
    "\n",
    "# -----------------------------\n",
    "# 2️⃣ Spatial cross-validation setup\n",
    "# -----------------------------\n",
    "# If coordinates are available for block assignment:\n",
    "coords_available = all(col in cov_final.columns for col in ['X_coord','Y_coord'])\n",
    "if coords_available:\n",
    "    # Assign spatial blocks (example: 10 km blocks)\n",
    "    block_size = 10000  # meters\n",
    "    cov_final['block_x'] = np.digitize(cov_final['X_coord'], np.arange(cov_final['X_coord'].min(), cov_final['X_coord'].max()+block_size, block_size)) - 1\n",
    "    cov_final['block_y'] = np.digitize(cov_final['Y_coord'], np.arange(cov_final['Y_coord'].min(), cov_final['Y_coord'].max()+block_size, block_size)) - 1\n",
    "    cov_final['block_id'] = cov_final['block_x'].astype(str) + \"_\" + cov_final['block_y'].astype(str)\n",
    "else:\n",
    "    # If no spatial info, fallback to normal CV\n",
    "    cov_final['block_id'] = np.arange(len(cov_final))\n",
    "\n",
    "# 5-fold GroupKFold based on spatial blocks\n",
    "n_folds = 5\n",
    "gkf = GroupKFold(n_splits=n_folds)\n",
    "\n",
    "# -----------------------------\n",
    "# 3️⃣ Out-of-sample / spatial CV\n",
    "# -----------------------------\n",
    "cv_results = []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(gkf.split(X, y, groups=cov_final['block_id'])):\n",
    "    print(f\"Fold {fold+1}: Train={len(train_idx)} Test={len(test_idx)}\")\n",
    "\n",
    "    # Subset data\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    w_train = sample_weight.iloc[train_idx]\n",
    "\n",
    "    # Train weighted RF\n",
    "    rf = RandomForestRegressor(\n",
    "        n_estimators=500, \n",
    "        max_features='sqrt', \n",
    "        n_jobs=-1, \n",
    "        random_state=42\n",
    "    )\n",
    "    rf.fit(X_train, y_train, sample_weight=w_train)\n",
    "\n",
    "    # Predict held-out fold\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "    # Compute metrics\n",
    "    mse = mean_squared_error(y_test, y_pred, sample_weight=sample_weight.iloc[test_idx])\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    bias = np.mean(y_pred - y_test)\n",
    "    \n",
    "    cv_results.append({'fold': fold+1, 'RMSE': rmse, 'R2': r2, 'bias': bias})\n",
    "\n",
    "    # Diagnostic plot: observed vs predicted\n",
    "    plt.figure(figsize=(6,6))\n",
    "    sns.scatterplot(x=y_test, y=y_pred, alpha=0.6)\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "    plt.xlabel(\"Observed log(SOC)\")\n",
    "    plt.ylabel(\"Predicted log(SOC)\")\n",
    "    plt.title(f\"Observed vs Predicted - Fold {fold+1}\")\n",
    "    plt.show()\n",
    "\n",
    "# Summary of CV results\n",
    "cv_df = pd.DataFrame(cv_results)\n",
    "print(\"\\nSpatial CV Summary:\")\n",
    "print(cv_df.describe())\n",
    "\n",
    "# -----------------------------\n",
    "# 4️⃣ Train final RF on full dataset\n",
    "# -----------------------------\n",
    "rf_final = RandomForestRegressor(\n",
    "    n_estimators=500, \n",
    "    max_features='sqrt', \n",
    "    n_jobs=-1, \n",
    "    random_state=42\n",
    ")\n",
    "rf_final.fit(X, y, sample_weight=sample_weight)\n",
    "print(\"Final RF trained on full dataset.\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5️⃣ Predict SOC on raster stack / prediction grid\n",
    "# -----------------------------\n",
    "# Load prepared prediction grid CSV (with covariates aligned to training dataset)\n",
    "X_grid = pd.read_csv(\"/Volumes/One_Touch/angola_soils_thesis/GIS_Angola/prediction_grid_covariates.csv\")\n",
    "\n",
    "# Ensure columns match training predictors\n",
    "missing_cols = [c for c in predictor_cols if c not in X_grid.columns]\n",
    "for c in missing_cols:\n",
    "    X_grid[c] = 0\n",
    "X_grid = X_grid[predictor_cols]\n",
    "\n",
    "# Predict SOC\n",
    "soc_pred = rf_final.predict(X_grid)\n",
    "X_grid['log_soc_stock_pred'] = soc_pred\n",
    "\n",
    "# Optional: save prediction grid with SOC predictions\n",
    "out_csv = \"/Volumes/One_Touch/angola_soils_thesis/GIS_Angola/prediction_grid_SOC.csv\"\n",
    "X_grid.to_csv(out_csv, index=False)\n",
    "print(f\"Prediction grid with SOC saved to: {out_csv}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 6️⃣ Uncertainty estimation (variance across trees)\n",
    "# -----------------------------\n",
    "tree_preds = np.stack([tree.predict(X_grid) for tree in rf_final.estimators_], axis=0)\n",
    "soc_variance = np.var(tree_preds, axis=0)\n",
    "X_grid['soc_variance'] = soc_variance\n",
    "print(\"Uncertainty (variance) added to prediction grid.\")\n",
    "\n",
    "# Optional: save variance as separate column or layer\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
