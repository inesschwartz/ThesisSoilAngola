{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All models together to be run 50 times (once per subset/decluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**the modelling methodology**\n",
    "\n",
    "â€œEach declustered subset (DCáµ¢) was internally partitioned (80/20) to allow model validation on independent test data, ensuring that predictive performance and model stability were assessed under spatial independence. After internal validation, models were retrained on all samples in each DCáµ¢ to maximize predictive strength and produce the final maps used for ensemble averaging. The ensemble predictions were subsequently validated using the external holdout dataset (testâ‚) derived from the original data split.â€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running RF, OK, and RF+OK for 50 declustered subsets... â³\n",
      "âœ… Iteration 01 complete | RF RÂ²=0.332, OK RÂ²=-0.089, RF+OK RÂ²=0.275\n",
      "âœ… Iteration 02 complete | RF RÂ²=0.319, OK RÂ²=-0.086, RF+OK RÂ²=0.232\n",
      "âœ… Iteration 03 complete | RF RÂ²=0.329, OK RÂ²=-0.039, RF+OK RÂ²=0.269\n",
      "âœ… Iteration 04 complete | RF RÂ²=0.316, OK RÂ²=-0.045, RF+OK RÂ²=0.251\n",
      "âœ… Iteration 05 complete | RF RÂ²=0.335, OK RÂ²=-0.091, RF+OK RÂ²=0.278\n",
      "âœ… Iteration 06 complete | RF RÂ²=0.349, OK RÂ²=-0.102, RF+OK RÂ²=0.260\n",
      "âœ… Iteration 07 complete | RF RÂ²=0.321, OK RÂ²=-0.055, RF+OK RÂ²=0.286\n",
      "âœ… Iteration 08 complete | RF RÂ²=0.324, OK RÂ²=-0.057, RF+OK RÂ²=0.282\n",
      "âœ… Iteration 09 complete | RF RÂ²=0.326, OK RÂ²=-0.043, RF+OK RÂ²=0.262\n",
      "âœ… Iteration 10 complete | RF RÂ²=0.328, OK RÂ²=-0.084, RF+OK RÂ²=0.273\n",
      "âœ… Iteration 11 complete | RF RÂ²=0.328, OK RÂ²=-0.084, RF+OK RÂ²=0.273\n",
      "âœ… Iteration 12 complete | RF RÂ²=0.332, OK RÂ²=-0.088, RF+OK RÂ²=0.276\n",
      "âœ… Iteration 13 complete | RF RÂ²=0.323, OK RÂ²=-0.042, RF+OK RÂ²=0.260\n",
      "âœ… Iteration 14 complete | RF RÂ²=0.315, OK RÂ²=0.001, RF+OK RÂ²=0.301\n",
      "âœ… Iteration 15 complete | RF RÂ²=0.319, OK RÂ²=-0.086, RF+OK RÂ²=0.232\n",
      "âœ… Iteration 16 complete | RF RÂ²=0.334, OK RÂ²=-0.042, RF+OK RÂ²=0.306\n",
      "âœ… Iteration 17 complete | RF RÂ²=0.335, OK RÂ²=-0.091, RF+OK RÂ²=0.278\n",
      "âœ… Iteration 18 complete | RF RÂ²=0.347, OK RÂ²=-0.106, RF+OK RÂ²=0.253\n",
      "âœ… Iteration 19 complete | RF RÂ²=0.337, OK RÂ²=-0.040, RF+OK RÂ²=0.309\n",
      "âœ… Iteration 20 complete | RF RÂ²=0.339, OK RÂ²=-0.085, RF+OK RÂ²=0.287\n",
      "âœ… Iteration 21 complete | RF RÂ²=0.334, OK RÂ²=-0.090, RF+OK RÂ²=0.276\n",
      "âœ… Iteration 22 complete | RF RÂ²=0.333, OK RÂ²=-0.037, RF+OK RÂ²=0.300\n",
      "âœ… Iteration 23 complete | RF RÂ²=0.313, OK RÂ²=-0.004, RF+OK RÂ²=0.297\n",
      "âœ… Iteration 24 complete | RF RÂ²=0.347, OK RÂ²=-0.106, RF+OK RÂ²=0.253\n",
      "âœ… Iteration 25 complete | RF RÂ²=0.318, OK RÂ²=-0.045, RF+OK RÂ²=0.251\n",
      "âœ… Iteration 26 complete | RF RÂ²=0.332, OK RÂ²=-0.041, RF+OK RÂ²=0.293\n",
      "âœ… Iteration 27 complete | RF RÂ²=0.315, OK RÂ²=-0.004, RF+OK RÂ²=0.299\n",
      "âœ… Iteration 28 complete | RF RÂ²=0.334, OK RÂ²=-0.090, RF+OK RÂ²=0.277\n",
      "âœ… Iteration 29 complete | RF RÂ²=0.328, OK RÂ²=-0.084, RF+OK RÂ²=0.273\n",
      "âœ… Iteration 30 complete | RF RÂ²=0.342, OK RÂ²=-0.086, RF+OK RÂ²=0.289\n",
      "âœ… Iteration 31 complete | RF RÂ²=0.346, OK RÂ²=-0.097, RF+OK RÂ²=0.257\n",
      "âœ… Iteration 32 complete | RF RÂ²=0.324, OK RÂ²=-0.057, RF+OK RÂ²=0.282\n",
      "âœ… Iteration 33 complete | RF RÂ²=0.331, OK RÂ²=-0.074, RF+OK RÂ²=0.251\n",
      "âœ… Iteration 34 complete | RF RÂ²=0.330, OK RÂ²=-0.039, RF+OK RÂ²=0.297\n",
      "âœ… Iteration 35 complete | RF RÂ²=0.328, OK RÂ²=-0.084, RF+OK RÂ²=0.273\n",
      "âœ… Iteration 36 complete | RF RÂ²=0.335, OK RÂ²=-0.037, RF+OK RÂ²=0.303\n",
      "âœ… Iteration 37 complete | RF RÂ²=0.319, OK RÂ²=-0.055, RF+OK RÂ²=0.281\n",
      "âœ… Iteration 38 complete | RF RÂ²=0.332, OK RÂ²=-0.088, RF+OK RÂ²=0.276\n",
      "âœ… Iteration 39 complete | RF RÂ²=0.334, OK RÂ²=-0.090, RF+OK RÂ²=0.277\n",
      "âœ… Iteration 40 complete | RF RÂ²=0.347, OK RÂ²=-0.105, RF+OK RÂ²=0.251\n",
      "âœ… Iteration 41 complete | RF RÂ²=0.331, OK RÂ²=-0.074, RF+OK RÂ²=0.251\n",
      "âœ… Iteration 42 complete | RF RÂ²=0.346, OK RÂ²=-0.097, RF+OK RÂ²=0.257\n",
      "âœ… Iteration 43 complete | RF RÂ²=0.323, OK RÂ²=-0.048, RF+OK RÂ²=0.255\n",
      "âœ… Iteration 44 complete | RF RÂ²=0.330, OK RÂ²=-0.071, RF+OK RÂ²=0.253\n",
      "âœ… Iteration 45 complete | RF RÂ²=0.339, OK RÂ²=-0.085, RF+OK RÂ²=0.287\n",
      "âœ… Iteration 46 complete | RF RÂ²=0.335, OK RÂ²=-0.081, RF+OK RÂ²=0.283\n",
      "âœ… Iteration 47 complete | RF RÂ²=0.334, OK RÂ²=-0.090, RF+OK RÂ²=0.277\n",
      "âœ… Iteration 48 complete | RF RÂ²=0.319, OK RÂ²=-0.086, RF+OK RÂ²=0.232\n",
      "âœ… Iteration 49 complete | RF RÂ²=0.347, OK RÂ²=-0.106, RF+OK RÂ²=0.253\n",
      "âœ… Iteration 50 complete | RF RÂ²=0.323, OK RÂ²=-0.048, RF+OK RÂ²=0.255\n",
      "\n",
      "ğŸ“ All model results saved to: /Users/inesschwartz/Desktop/model/results_all_models.csv\n"
     ]
    }
   ],
   "source": [
    "# No cross validation steps --All models together to be run 50 times (once per subset/decluster) \n",
    "#  =========================================================\n",
    "# STEP â€” Run RF, OK, and RF+OK on all declustered subsets\n",
    "# =========================================================\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pykrige.ok import OrdinaryKriging\n",
    "\n",
    "# --- Paths ---\n",
    "decluster_dir = \"/Users/inesschwartz/Desktop/model/decluster_runs\"\n",
    "results_file = \"/Users/inesschwartz/Desktop/model/results_all_models.csv\"\n",
    "output_dir = \"/Users/inesschwartz/Desktop/model/predictions\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# --- Hyperparameters (from tuning step) ---\n",
    "rf_params = {\n",
    "    'n_estimators': 1500,\n",
    "    'min_samples_leaf': 3,\n",
    "    'max_features': 0.5,\n",
    "    'max_depth': None,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "# --- Fixed variogram parameters (from stability analysis) ---\n",
    "variogram_params = {\n",
    "    'model': 'gaussian',\n",
    "    'variogram_parameters': {'nugget': 0.0, 'sill': 0.18, 'range': 14000}\n",
    "}\n",
    "\n",
    "\n",
    "# --- Helper for metrics ---\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        'R2': r2_score(y_true, y_pred),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        'MAE': mean_absolute_error(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "# --- Results container ---\n",
    "results = []\n",
    "\n",
    "# --- Files ---\n",
    "files = sorted(glob.glob(os.path.join(decluster_dir, \"decluster_run_*.csv\")))\n",
    "print(f\"Running RF, OK, and RF+OK for {len(files)} declustered subsets... â³\")\n",
    "\n",
    "# =========================================================\n",
    "# MAIN LOOP\n",
    "# =========================================================\n",
    "for i, file in enumerate(files, start=1):\n",
    "    df = pd.read_csv(file)\n",
    "    target = 'log_soc_stock'\n",
    "\n",
    "    # --- Train/test split ---\n",
    "    train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    X_train = train.drop(columns=[target, 'X_coord', 'Y_coord', 'site_info_id'], errors='ignore')\n",
    "    y_train = train[target].values\n",
    "    X_test = test.drop(columns=[target, 'X_coord', 'Y_coord', 'site_info_id'], errors='ignore')\n",
    "    y_test = test[target].values\n",
    "\n",
    "    coords_train = train[['X_coord', 'Y_coord']].values\n",
    "    coords_test = test[['X_coord', 'Y_coord']].values\n",
    "\n",
    "    # =====================================================\n",
    "    # 1ï¸âƒ£ Ordinary Kriging (OK)\n",
    "    # =====================================================\n",
    "    ok = OrdinaryKriging(\n",
    "        x=coords_train[:, 0],\n",
    "        y=coords_train[:, 1],\n",
    "        z=y_train,\n",
    "        variogram_model=variogram_params['model'],\n",
    "        variogram_parameters=variogram_params['variogram_parameters'],\n",
    "        enable_plotting=False,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    y_pred_ok, _ = ok.execute('points', coords_test[:, 0], coords_test[:, 1])\n",
    "    metrics_ok = compute_metrics(y_test, y_pred_ok)\n",
    "    results.append({'iteration': i, 'model': 'OK', **metrics_ok})\n",
    "\n",
    "    # =====================================================\n",
    "    # 2ï¸âƒ£ Random Forest (RF)\n",
    "    # =====================================================\n",
    "    rf = RandomForestRegressor(**rf_params)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred_rf = rf.predict(X_test)\n",
    "    metrics_rf = compute_metrics(y_test, y_pred_rf)\n",
    "    results.append({'iteration': i, 'model': 'RF', **metrics_rf})\n",
    "\n",
    "    # =====================================================\n",
    "    # 3ï¸âƒ£ Hybrid RF + OK (residual kriging)\n",
    "    # =====================================================\n",
    "    residuals = y_train - rf.predict(X_train)\n",
    "    ok_resid = OrdinaryKriging(\n",
    "        x=coords_train[:, 0],\n",
    "        y=coords_train[:, 1],\n",
    "        z=residuals,\n",
    "        variogram_model=variogram_params['model'],\n",
    "        variogram_parameters=variogram_params['variogram_parameters'],\n",
    "        enable_plotting=False,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    residual_pred, _ = ok_resid.execute('points', coords_test[:, 0], coords_test[:, 1])\n",
    "    y_pred_rfok = y_pred_rf + residual_pred\n",
    "\n",
    "    metrics_rfok = compute_metrics(y_test, y_pred_rfok)\n",
    "    results.append({'iteration': i, 'model': 'RF+OK', **metrics_rfok})\n",
    "\n",
    "    print(f\"âœ… Iteration {i:02d} complete | RF RÂ²={metrics_rf['R2']:.3f}, OK RÂ²={metrics_ok['R2']:.3f}, RF+OK RÂ²={metrics_rfok['R2']:.3f}\")\n",
    "\n",
    "    # --- Save iteration predictions (optional) ---\n",
    "    out = test[['X_coord', 'Y_coord', target]].copy()\n",
    "    out['pred_RF'] = y_pred_rf\n",
    "    out['pred_OK'] = y_pred_ok\n",
    "    out['pred_RF_OK'] = y_pred_rfok\n",
    "    out.to_csv(os.path.join(output_dir, f\"predictions_iter_{i:03d}.csv\"), index=False)\n",
    "\n",
    "# =====================================================\n",
    "# Save all metrics\n",
    "# =====================================================\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(results_file, index=False)\n",
    "print(f\"\\nğŸ“ All model results saved to: {results_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Running calibration for first 10 declustered subsets...\n",
      "\n",
      "ğŸ“‚ Processing decluster subset 001 | n = 629\n",
      "âš™ï¸ Running internal 5-fold CV and validation...\n",
      "âœ… DC001 | RF RÂ²=0.333 | OK RÂ²=1.000 | Hybrid RÂ²=1.000\n",
      "\n",
      "ğŸ“‚ Processing decluster subset 002 | n = 629\n",
      "âš™ï¸ Running internal 5-fold CV and validation...\n",
      "âœ… DC002 | RF RÂ²=0.304 | OK RÂ²=1.000 | Hybrid RÂ²=1.000\n",
      "\n",
      "ğŸ“‚ Processing decluster subset 003 | n = 629\n",
      "âš™ï¸ Running internal 5-fold CV and validation...\n",
      "âœ… DC003 | RF RÂ²=0.321 | OK RÂ²=1.000 | Hybrid RÂ²=1.000\n",
      "\n",
      "ğŸ“‚ Processing decluster subset 004 | n = 629\n",
      "âš™ï¸ Running internal 5-fold CV and validation...\n",
      "âœ… DC004 | RF RÂ²=0.318 | OK RÂ²=1.000 | Hybrid RÂ²=1.000\n",
      "\n",
      "ğŸ“‚ Processing decluster subset 005 | n = 629\n",
      "âš™ï¸ Running internal 5-fold CV and validation...\n",
      "âœ… DC005 | RF RÂ²=0.325 | OK RÂ²=1.000 | Hybrid RÂ²=1.000\n",
      "\n",
      "ğŸ“‚ Processing decluster subset 006 | n = 629\n",
      "âš™ï¸ Running internal 5-fold CV and validation...\n",
      "âœ… DC006 | RF RÂ²=0.317 | OK RÂ²=1.000 | Hybrid RÂ²=1.000\n",
      "\n",
      "ğŸ“‚ Processing decluster subset 007 | n = 629\n",
      "âš™ï¸ Running internal 5-fold CV and validation...\n",
      "âœ… DC007 | RF RÂ²=0.324 | OK RÂ²=1.000 | Hybrid RÂ²=1.000\n",
      "\n",
      "ğŸ“‚ Processing decluster subset 008 | n = 629\n",
      "âš™ï¸ Running internal 5-fold CV and validation...\n",
      "âœ… DC008 | RF RÂ²=0.324 | OK RÂ²=1.000 | Hybrid RÂ²=1.000\n",
      "\n",
      "ğŸ“‚ Processing decluster subset 009 | n = 629\n",
      "âš™ï¸ Running internal 5-fold CV and validation...\n",
      "âœ… DC009 | RF RÂ²=0.309 | OK RÂ²=1.000 | Hybrid RÂ²=1.000\n",
      "\n",
      "ğŸ“‚ Processing decluster subset 010 | n = 629\n",
      "âš™ï¸ Running internal 5-fold CV and validation...\n",
      "âœ… DC010 | RF RÂ²=0.335 | OK RÂ²=1.000 | Hybrid RÂ²=1.000\n",
      "\n",
      "âœ… Calibration diagnostics complete.\n",
      "ğŸ“ Results saved to: /Users/inesschwartz/Desktop/model/results_calibration/calibration_results.csv\n"
     ]
    }
   ],
   "source": [
    "# # (Calibration Diagnostics Only) didn't handle ok data well...\n",
    "# # =========================================================\n",
    "# # STEP â€” Decluster modeling loop (Calibration Diagnostics Only)\n",
    "# # =========================================================\n",
    "\n",
    "# import os\n",
    "# import glob\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "# from sklearn.model_selection import KFold\n",
    "# from pykrige.ok import OrdinaryKriging\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# # =========================================================\n",
    "# # PATHS AND PARAMETERS\n",
    "# # =========================================================\n",
    "# decluster_dir = \"/Users/inesschwartz/Desktop/model/decluster_runs\"\n",
    "# output_dir = \"/Users/inesschwartz/Desktop/model/results_calibration\"\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# # --- RF parameters (from tuning) ---\n",
    "# rf_params = {\n",
    "#     'n_estimators': 1500,\n",
    "#     'min_samples_leaf': 3,\n",
    "#     'max_features': 0.5,\n",
    "#     'max_depth': None,\n",
    "#     'random_state': 42,\n",
    "#     'n_jobs': 4\n",
    "# }\n",
    "\n",
    "# # Variogram parameters\n",
    "# variogram_model = 'exponential'\n",
    "# variogram_params = {'nugget': 0.0022, 'sill': 0.22, 'range': 15000}\n",
    "\n",
    "# # =========================================================\n",
    "# # HELPER FUNCTIONS\n",
    "# # =========================================================\n",
    "# def compute_metrics(y_true, y_pred):\n",
    "#     \"\"\"Compute standard regression metrics.\"\"\"\n",
    "#     return {\n",
    "#         'R2': r2_score(y_true, y_pred),\n",
    "#         'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "#         'MAE': mean_absolute_error(y_true, y_pred)\n",
    "#     }\n",
    "\n",
    "# def cross_validate_rf(X, y, k=5):\n",
    "#     \"\"\"Run k-fold cross-validation for Random Forest.\"\"\"\n",
    "#     kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "#     metrics = []\n",
    "\n",
    "#     for train_idx, test_idx in kf.split(X):\n",
    "#         X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "#         y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "#         rf = RandomForestRegressor(**rf_params)\n",
    "#         rf.fit(X_train, y_train)\n",
    "#         y_pred = rf.predict(X_test)\n",
    "#         metrics.append(compute_metrics(y_test, y_pred))\n",
    "\n",
    "#     avg = pd.DataFrame(metrics).mean().to_dict()\n",
    "#     return avg\n",
    "\n",
    "# def run_ok(coords, values, variogram_params, model='exponential'):\n",
    "#     \"\"\"Run Ordinary Kriging with fixed variogram parameters.\"\"\"\n",
    "#     ok = OrdinaryKriging(\n",
    "#         x=coords[:, 0],\n",
    "#         y=coords[:, 1],\n",
    "#         z=values,\n",
    "#         variogram_model=model,\n",
    "#         variogram_parameters={\n",
    "#             'sill': variogram_params['sill'],\n",
    "#             'range': variogram_params['range'],\n",
    "#             'nugget': variogram_params['nugget']\n",
    "#         },\n",
    "#         enable_plotting=False,\n",
    "#         verbose=False\n",
    "#     )\n",
    "#     return ok\n",
    "\n",
    "# def run_rf_ok(X, y, coords, variogram_params):\n",
    "#     \"\"\"Run hybrid RF + OK (residual kriging).\"\"\"\n",
    "#     rf = RandomForestRegressor(**rf_params)\n",
    "#     rf.fit(X, y)\n",
    "#     y_pred_rf = rf.predict(X)\n",
    "#     residuals = y - y_pred_rf\n",
    "\n",
    "#     ok = run_ok(coords, residuals, variogram_params)\n",
    "#     residual_pred, _ = ok.execute('points', coords[:, 0], coords[:, 1])\n",
    "#     y_pred_hybrid = y_pred_rf + residual_pred.data\n",
    "#     return compute_metrics(y, y_pred_hybrid)\n",
    "\n",
    "# # =========================================================\n",
    "# # MAIN CALIBRATION LOOP\n",
    "# # =========================================================\n",
    "# files = sorted(glob.glob(os.path.join(decluster_dir, \"decluster_run_*.csv\")))\n",
    "# n_calibration = 10  # limit to first 10 DCs\n",
    "\n",
    "# print(f\"ğŸ” Running calibration for first {n_calibration} declustered subsets...\")\n",
    "\n",
    "# calibration_results = []\n",
    "\n",
    "# for i, file in enumerate(files[:n_calibration], start=1):\n",
    "#     df = pd.read_csv(file)\n",
    "#     print(f\"\\nğŸ“‚ Processing decluster subset {i:03d} | n = {len(df)}\")\n",
    "\n",
    "#     target = 'log_soc_stock'\n",
    "#     X = df.drop(columns=[target, 'X_coord', 'Y_coord', 'site_info_id'], errors='ignore')\n",
    "#     y = df[target].values\n",
    "#     coords = df[['X_coord', 'Y_coord']].values\n",
    "\n",
    "#     print(\"âš™ï¸ Running internal 5-fold CV and validation...\")\n",
    "\n",
    "#     # --- RF Cross-validation ---\n",
    "#     rf_cv_metrics = cross_validate_rf(X, y, k=5)\n",
    "\n",
    "#     # --- OK validation (LOO-style) --- CAN SKIP THIS\n",
    "# #     ok = run_ok(coords, y, variogram_params)\n",
    "#     y_pred_ok, _ = ok.execute('points', coords[:, 0], coords[:, 1])\n",
    "#     ok_metrics = compute_metrics(y, y_pred_ok)\n",
    "\n",
    "#     # --- RF+OK residual kriging ---\n",
    "#     hybrid_metrics = run_rf_ok(X, y, coords, variogram_params)\n",
    "\n",
    "#     # --- Store results ---\n",
    "#     calibration_results.append({'subset': i, 'model': 'RF_CV', **rf_cv_metrics})\n",
    "#     calibration_results.append({'subset': i, 'model': 'OK', **ok_metrics})\n",
    "#     calibration_results.append({'subset': i, 'model': 'RF+OK', **hybrid_metrics})\n",
    "\n",
    "#     print(f\"âœ… DC{i:03d} | RF RÂ²={rf_cv_metrics['R2']:.3f} | OK RÂ²={ok_metrics['R2']:.3f} | Hybrid RÂ²={hybrid_metrics['R2']:.3f}\")\n",
    "\n",
    "# # =========================================================\n",
    "# # SAVE RESULTS\n",
    "# # =========================================================\n",
    "# out_csv = os.path.join(output_dir, \"calibration_results.csv\")\n",
    "# pd.DataFrame(calibration_results).to_csv(out_csv, index=False)\n",
    "\n",
    "# print(\"\\nâœ… Calibration diagnostics complete.\")\n",
    "# print(f\"ğŸ“ Results saved to: {out_csv}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OLD: \n",
    "Calibration results summary (DCâ‚â€“â‚â‚€):\n",
    "Random Forest shows consistent moderate predictive ability (RÂ² â‰ˆ 0.32, RMSE â‰ˆ 0.44).\n",
    "However, Ordinary Kriging (OK) and hybrid RF+OK show perfect interpolation (RÂ²=1.0), indicating they were evaluated on the same training data rather than withheld samples.\n",
    "The next step is to implement Leave-One-Out (LOO) kriging validation to obtain unbiased performance estimates for OK and RF+OK before proceeding to ensemble modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Running RF (Spatial K-Fold), OK (LOO), and RF+OK (LOO) for 10 decluster subsets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calibration progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [3:18:05<00:00, 1188.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ Calibration results saved to: /Users/inesschwartz/Desktop/model/results_final/calibration_results_spatial.csv\n",
      "âœ… Spatial K-Fold + LOO calibration complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# STEP â€” Decluster modeling loop with Spatial K-Fold & LOO\n",
    "# =========================================================\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import KFold\n",
    "from pykrige.ok import OrdinaryKriging\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# =========================================================\n",
    "# PATHS AND PARAMETERS\n",
    "# =========================================================\n",
    "decluster_dir = \"/Users/inesschwartz/Desktop/model/decluster_runs\"\n",
    "output_dir = \"/Users/inesschwartz/Desktop/model/results_final\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Random Forest tuned parameters\n",
    "rf_params = {\n",
    "    'n_estimators': 1500,\n",
    "    'min_samples_leaf': 3,\n",
    "    'max_features': 0.5,\n",
    "    'max_depth': None,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': 4\n",
    "}\n",
    "\n",
    "# Variogram parameters (from calibration)\n",
    "variogram_model = 'exponential'\n",
    "variogram_params = {'nugget': 0.0022, 'sill': 0.22, 'range': 15000}\n",
    "\n",
    "# =========================================================\n",
    "# HELPER FUNCTIONS\n",
    "# =========================================================\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    \"\"\"Compute standard regression metrics.\"\"\"\n",
    "    return {\n",
    "        'R2': r2_score(y_true, y_pred),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        'MAE': mean_absolute_error(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "\n",
    "def spatial_kfold(coords, n_splits=5):\n",
    "    \"\"\"\n",
    "    Custom spatial K-Fold generator.\n",
    "    Splits data into roughly spatially distinct clusters\n",
    "    by sorting coordinates and splitting sequentially.\n",
    "    \"\"\"\n",
    "    # Sort by X + Y coordinate to ensure spatial grouping\n",
    "    idx = np.argsort(coords[:, 0] + coords[:, 1])\n",
    "    fold_sizes = np.full(n_splits, len(coords) // n_splits, dtype=int)\n",
    "    fold_sizes[:len(coords) % n_splits] += 1\n",
    "    current = 0\n",
    "    folds = []\n",
    "    for fold_size in fold_sizes:\n",
    "        start, stop = current, current + fold_size\n",
    "        test_idx = idx[start:stop]\n",
    "        train_idx = np.setdiff1d(np.arange(len(coords)), test_idx)\n",
    "        folds.append((train_idx, test_idx))\n",
    "        current = stop\n",
    "    return folds\n",
    "\n",
    "\n",
    "def cross_validate_rf_spatial(X, y, coords, n_splits=5):\n",
    "    \"\"\"Spatial K-Fold cross-validation for Random Forest.\"\"\"\n",
    "    folds = spatial_kfold(coords, n_splits)\n",
    "    metrics = []\n",
    "    for train_idx, test_idx in folds:\n",
    "        rf = RandomForestRegressor(**rf_params)\n",
    "        rf.fit(X.iloc[train_idx], y[train_idx])\n",
    "        y_pred = rf.predict(X.iloc[test_idx])\n",
    "        metrics.append(compute_metrics(y[test_idx], y_pred))\n",
    "    return pd.DataFrame(metrics).mean().to_dict()\n",
    "\n",
    "\n",
    "def loo_validate_ok(coords, values, variogram_params, model='exponential'):\n",
    "    \"\"\"Leave-One-Out Cross-Validation for Ordinary Kriging.\"\"\"\n",
    "    preds = np.zeros(len(values))\n",
    "    for i in range(len(values)):\n",
    "        mask = np.ones(len(values), dtype=bool)\n",
    "        mask[i] = False\n",
    "        ok = OrdinaryKriging(\n",
    "            x=coords[mask, 0],\n",
    "            y=coords[mask, 1],\n",
    "            z=values[mask],\n",
    "            variogram_model=model,\n",
    "            variogram_parameters={\n",
    "                'sill': variogram_params['sill'],\n",
    "                'range': variogram_params['range'],\n",
    "                'nugget': variogram_params['nugget']\n",
    "            },\n",
    "            enable_plotting=False,\n",
    "            verbose=False\n",
    "        )\n",
    "        zhat, _ = ok.execute('points',\n",
    "                             np.array([coords[i, 0]]),\n",
    "                             np.array([coords[i, 1]]))\n",
    "        preds[i] = zhat.data[0]\n",
    "    return compute_metrics(values, preds)\n",
    "\n",
    "\n",
    "def loo_validate_rf_ok(X, y, coords, variogram_params):\n",
    "    \"\"\"LOO validation for hybrid RF+OK (residual kriging).\"\"\"\n",
    "    preds = np.zeros(len(y))\n",
    "    for i in range(len(y)):\n",
    "        mask = np.ones(len(y), dtype=bool)\n",
    "        mask[i] = False\n",
    "        rf = RandomForestRegressor(**rf_params)\n",
    "        rf.fit(X.iloc[mask], y[mask])\n",
    "        y_pred_rf = rf.predict(X.iloc[mask])\n",
    "        residuals = y[mask] - y_pred_rf\n",
    "        ok = OrdinaryKriging(\n",
    "            x=coords[mask, 0],\n",
    "            y=coords[mask, 1],\n",
    "            z=residuals,\n",
    "            variogram_model='exponential',\n",
    "            variogram_parameters={\n",
    "                'sill': variogram_params['sill'],\n",
    "                'range': variogram_params['range'],\n",
    "                'nugget': variogram_params['nugget']\n",
    "            },\n",
    "            enable_plotting=False,\n",
    "            verbose=False\n",
    "        )\n",
    "        zhat, _ = ok.execute('points',\n",
    "                             np.array([coords[i, 0]]),\n",
    "                             np.array([coords[i, 1]]))\n",
    "        yhat_hybrid = rf.predict(X.iloc[[i]])[0] + zhat.data[0]\n",
    "        preds[i] = yhat_hybrid\n",
    "    return compute_metrics(y, preds)\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# MAIN CALIBRATION LOOP\n",
    "# =========================================================\n",
    "files = sorted(glob.glob(os.path.join(decluster_dir, \"decluster_run_*.csv\")))\n",
    "calibration_results = []\n",
    "\n",
    "print(f\"ğŸ” Running RF (Spatial K-Fold), OK (LOO), and RF+OK (LOO) for {len(files[:10])} decluster subsets...\")\n",
    "\n",
    "for i, file in enumerate(tqdm(files[:10], desc=\"Calibration progress\", ncols=100), start=1):\n",
    "    df = pd.read_csv(file)\n",
    "    target = 'log_soc_stock'\n",
    "    X = df.drop(columns=[target, 'X_coord', 'Y_coord', 'site_info_id'], errors='ignore')\n",
    "    y = df[target].values\n",
    "    coords = df[['X_coord', 'Y_coord']].values\n",
    "\n",
    "    rf_spatial = cross_validate_rf_spatial(X, y, coords, n_splits=5)\n",
    "    ok_loo = loo_validate_ok(coords, y, variogram_params, model=variogram_model)\n",
    "    hybrid_loo = loo_validate_rf_ok(X, y, coords, variogram_params)\n",
    "\n",
    "    calibration_results.append({'subset': i, 'model': 'RF_SpatialKFold', **rf_spatial})\n",
    "    calibration_results.append({'subset': i, 'model': 'OK_LOO', **ok_loo})\n",
    "    calibration_results.append({'subset': i, 'model': 'RF+OK_LOO', **hybrid_loo})\n",
    "\n",
    "# --- Save calibration results ---\n",
    "calib_path = os.path.join(output_dir, \"calibration_results_spatial.csv\")\n",
    "pd.DataFrame(calibration_results).to_csv(calib_path, index=False)\n",
    "\n",
    "print(f\"\\nğŸ“ Calibration results saved to: {calib_path}\")\n",
    "print(\"âœ… Spatial K-Fold + LOO calibration complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Running OK and RF+OK (LOO) for 5 declustered subsets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calibration progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [1:55:39<00:00, 1387.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ Calibration results saved to: /Users/inesschwartz/Desktop/model/results_calibration_ok/ok_rfok_calibration_results.csv\n",
      "âœ… Calibration complete.\n",
      "\n",
      "Summary (mean across 5 subsets):\n",
      "              R2   RMSE    MAE\n",
      "model                         \n",
      "OK_LOO     0.085  0.514  0.392\n",
      "RF+OK_LOO  0.332  0.439  0.315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ## ok rf-ok trial\n",
    "\n",
    "#  # =========================================================\n",
    "# # STEP â€” Calibration test for OK and RF+OK (5 declusters)\n",
    "# # =========================================================\n",
    "\n",
    "# import os\n",
    "# import glob\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "# from pykrige.ok import OrdinaryKriging\n",
    "# from tqdm import tqdm\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# # =========================================================\n",
    "# # PATHS AND PARAMETERS\n",
    "# # =========================================================\n",
    "# decluster_dir = \"/Users/inesschwartz/Desktop/model/decluster_runs\"\n",
    "# output_dir = \"/Users/inesschwartz/Desktop/model/results_calibration_ok\"\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# # Variogram parameters (from your calibration step)\n",
    "# variogram_model = 'exponential'\n",
    "# variogram_params = {'nugget': 0.0022, 'sill': 0.22, 'range': 15000}\n",
    "\n",
    "# # Random Forest tuned parameters\n",
    "# rf_params = {\n",
    "#     'n_estimators': 1500,\n",
    "#     'min_samples_leaf': 3,\n",
    "#     'max_features': 0.5,\n",
    "#     'max_depth': None,\n",
    "#     'random_state': 42,\n",
    "#     'n_jobs': -1\n",
    "# }\n",
    "\n",
    "# # =========================================================\n",
    "# # HELPER FUNCTIONS\n",
    "# # =========================================================\n",
    "# def compute_metrics(y_true, y_pred):\n",
    "#     \"\"\"Compute regression metrics.\"\"\"\n",
    "#     return {\n",
    "#         'R2': r2_score(y_true, y_pred),\n",
    "#         'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "#         'MAE': mean_absolute_error(y_true, y_pred)\n",
    "#     }\n",
    "\n",
    "\n",
    "# def loo_validate_ok(coords, values, variogram_params, model='exponential'):\n",
    "#     \"\"\"Leave-One-Out Cross-Validation for Ordinary Kriging.\"\"\"\n",
    "#     preds = np.zeros(len(values))\n",
    "#     for i in range(len(values)):\n",
    "#         mask = np.ones(len(values), dtype=bool)\n",
    "#         mask[i] = False\n",
    "\n",
    "#         ok = OrdinaryKriging(\n",
    "#             x=coords[mask, 0],\n",
    "#             y=coords[mask, 1],\n",
    "#             z=values[mask],\n",
    "#             variogram_model=model,\n",
    "#             variogram_parameters=[\n",
    "#                 variogram_params['sill'],\n",
    "#                 variogram_params['range'],\n",
    "#                 variogram_params['nugget']\n",
    "#             ],\n",
    "#             enable_plotting=False,\n",
    "#             verbose=False\n",
    "#         )\n",
    "\n",
    "#         zhat, _ = ok.execute('points',\n",
    "#                              np.array([coords[i, 0]]),\n",
    "#                              np.array([coords[i, 1]]))\n",
    "#         preds[i] = zhat.data[0]\n",
    "\n",
    "#     return compute_metrics(values, preds)\n",
    "\n",
    "\n",
    "# def loo_validate_rf_ok(X, y, coords, variogram_params):\n",
    "#     \"\"\"Leave-One-Out validation for hybrid RF+OK (residual kriging).\"\"\"\n",
    "#     preds = np.zeros(len(y))\n",
    "#     for i in range(len(y)):\n",
    "#         mask = np.ones(len(y), dtype=bool)\n",
    "#         mask[i] = False\n",
    "\n",
    "#         rf = RandomForestRegressor(**rf_params)\n",
    "#         rf.fit(X.iloc[mask], y[mask])\n",
    "#         y_pred_rf = rf.predict(X.iloc[mask])\n",
    "#         residuals = y[mask] - y_pred_rf\n",
    "\n",
    "#         ok = OrdinaryKriging(\n",
    "#             x=coords[mask, 0],\n",
    "#             y=coords[mask, 1],\n",
    "#             z=residuals,\n",
    "#             variogram_model='exponential',\n",
    "#             variogram_parameters=[\n",
    "#                 variogram_params['sill'],\n",
    "#                 variogram_params['range'],\n",
    "#                 variogram_params['nugget']\n",
    "#             ],\n",
    "#             enable_plotting=False,\n",
    "#             verbose=False\n",
    "#         )\n",
    "\n",
    "#         zhat, _ = ok.execute('points',\n",
    "#                              np.array([coords[i, 0]]),\n",
    "#                              np.array([coords[i, 1]]))\n",
    "#         yhat_hybrid = rf.predict(X.iloc[[i]])[0] + zhat.data[0]\n",
    "#         preds[i] = yhat_hybrid\n",
    "\n",
    "#     return compute_metrics(y, preds)\n",
    "\n",
    "# # =========================================================\n",
    "# # MAIN CALIBRATION LOOP\n",
    "# # =========================================================\n",
    "# files = sorted(glob.glob(os.path.join(decluster_dir, \"decluster_run_*.csv\")))[:5]\n",
    "# results = []\n",
    "\n",
    "# print(f\"ğŸ” Running OK and RF+OK (LOO) for {len(files)} declustered subsets...\")\n",
    "\n",
    "# for i, file in enumerate(tqdm(files, desc=\"Calibration progress\", ncols=100), start=1):\n",
    "#     df = pd.read_csv(file)\n",
    "#     target = 'log_soc_stock'\n",
    "#     X = df.drop(columns=[target, 'X_coord', 'Y_coord', 'site_info_id'], errors='ignore')\n",
    "#     y = df[target].values\n",
    "#     coords = df[['X_coord', 'Y_coord']].values\n",
    "\n",
    "#     ok_metrics = loo_validate_ok(coords, y, variogram_params, model=variogram_model)\n",
    "#     hybrid_metrics = loo_validate_rf_ok(X, y, coords, variogram_params)\n",
    "\n",
    "#     results.append({'subset': i, 'model': 'OK_LOO', **ok_metrics})\n",
    "#     results.append({'subset': i, 'model': 'RF+OK_LOO', **hybrid_metrics})\n",
    "\n",
    "# # =========================================================\n",
    "# # SAVE & DISPLAY RESULTS\n",
    "# # =========================================================\n",
    "# results_df = pd.DataFrame(results)\n",
    "# out_path = os.path.join(output_dir, \"ok_rfok_calibration_results.csv\")\n",
    "# results_df.to_csv(out_path, index=False)\n",
    "\n",
    "# print(f\"\\nğŸ“ Calibration results saved to: {out_path}\")\n",
    "# print(\"âœ… Calibration complete.\\n\")\n",
    "\n",
    "# print(\"Summary (mean across 5 subsets):\")\n",
    "# print(results_df.groupby(\"model\")[[\"R2\", \"RMSE\", \"MAE\"]].mean().round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## full dc runs\n",
    "\n",
    "# =========================================================\n",
    "# STEP â€” Decluster modeling loop with Spatial K-Fold & LOO\n",
    "# =========================================================\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import KFold\n",
    "from pykrige.ok import OrdinaryKriging\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# =========================================================\n",
    "# PATHS AND PARAMETERS\n",
    "# =========================================================\n",
    "decluster_dir = \"/Users/inesschwartz/Desktop/model/decluster_runs\"\n",
    "output_dir = \"/Users/inesschwartz/Desktop/model/results_final\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Random Forest tuned parameters\n",
    "rf_params = {\n",
    "    'n_estimators': 1500,\n",
    "    'min_samples_leaf': 3,\n",
    "    'max_features': 0.5,\n",
    "    'max_depth': None,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "# Variogram parameters (from your calibration step)\n",
    "variogram_model = 'exponential'\n",
    "variogram_params = {'nugget': 0.0022, 'sill': 0.22, 'range': 15000}\n",
    "\n",
    "# =========================================================\n",
    "# HELPER FUNCTIONS\n",
    "# =========================================================\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    \"\"\"Compute standard regression metrics.\"\"\"\n",
    "    return {\n",
    "        'R2': r2_score(y_true, y_pred),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        'MAE': mean_absolute_error(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "\n",
    "def spatial_kfold(coords, n_splits=5):\n",
    "    \"\"\"\n",
    "    Custom spatial K-Fold generator.\n",
    "    Splits data into roughly spatially distinct clusters\n",
    "    by sorting coordinates and splitting sequentially.\n",
    "    \"\"\"\n",
    "    # Sort by X + Y coordinate to ensure spatial grouping\n",
    "    idx = np.argsort(coords[:, 0] + coords[:, 1])\n",
    "    fold_sizes = np.full(n_splits, len(coords) // n_splits, dtype=int)\n",
    "    fold_sizes[:len(coords) % n_splits] += 1\n",
    "    current = 0\n",
    "    folds = []\n",
    "    for fold_size in fold_sizes:\n",
    "        start, stop = current, current + fold_size\n",
    "        test_idx = idx[start:stop]\n",
    "        train_idx = np.setdiff1d(np.arange(len(coords)), test_idx)\n",
    "        folds.append((train_idx, test_idx))\n",
    "        current = stop\n",
    "    return folds\n",
    "\n",
    "\n",
    "def cross_validate_rf_spatial(X, y, coords, n_splits=5):\n",
    "    \"\"\"Spatial K-Fold cross-validation for Random Forest.\"\"\"\n",
    "    folds = spatial_kfold(coords, n_splits)\n",
    "    metrics = []\n",
    "    for train_idx, test_idx in folds:\n",
    "        rf = RandomForestRegressor(**rf_params)\n",
    "        rf.fit(X.iloc[train_idx], y[train_idx])\n",
    "        y_pred = rf.predict(X.iloc[test_idx])\n",
    "        metrics.append(compute_metrics(y[test_idx], y_pred))\n",
    "    return pd.DataFrame(metrics).mean().to_dict()\n",
    "\n",
    "\n",
    "def loo_validate_ok(coords, values, variogram_params, model='exponential'):\n",
    "    \"\"\"Leave-One-Out Cross-Validation for Ordinary Kriging.\"\"\"\n",
    "    preds = np.zeros(len(values))\n",
    "    for i in range(len(values)):\n",
    "        mask = np.ones(len(values), dtype=bool)\n",
    "        mask[i] = False\n",
    "\n",
    "        ok = OrdinaryKriging(\n",
    "            x=coords[mask, 0],\n",
    "            y=coords[mask, 1],\n",
    "            z=values[mask],\n",
    "            variogram_model=model,\n",
    "            variogram_parameters=[\n",
    "                variogram_params['sill'],\n",
    "                variogram_params['range'],\n",
    "                variogram_params['nugget']\n",
    "            ],\n",
    "            enable_plotting=False,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        zhat, _ = ok.execute('points',\n",
    "                             np.array([coords[i, 0]]),\n",
    "                             np.array([coords[i, 1]]))\n",
    "        preds[i] = zhat.data[0]\n",
    "\n",
    "    return compute_metrics(values, preds)\n",
    "\n",
    "\n",
    "def loo_validate_rf_ok(X, y, coords, variogram_params):\n",
    "    \"\"\"Leave-One-Out validation for hybrid RF+OK (residual kriging).\"\"\"\n",
    "    preds = np.zeros(len(y))\n",
    "    for i in range(len(y)):\n",
    "        mask = np.ones(len(y), dtype=bool)\n",
    "        mask[i] = False\n",
    "\n",
    "        rf = RandomForestRegressor(**rf_params)\n",
    "        rf.fit(X.iloc[mask], y[mask])\n",
    "        y_pred_rf = rf.predict(X.iloc[mask])\n",
    "        residuals = y[mask] - y_pred_rf\n",
    "\n",
    "        ok = OrdinaryKriging(\n",
    "            x=coords[mask, 0],\n",
    "            y=coords[mask, 1],\n",
    "            z=residuals,\n",
    "            variogram_model='exponential',\n",
    "            variogram_parameters=[\n",
    "                variogram_params['sill'],\n",
    "                variogram_params['range'],\n",
    "                variogram_params['nugget']\n",
    "            ],\n",
    "            enable_plotting=False,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        zhat, _ = ok.execute('points',\n",
    "                             np.array([coords[i, 0]]),\n",
    "                             np.array([coords[i, 1]]))\n",
    "        yhat_hybrid = rf.predict(X.iloc[[i]])[0] + zhat.data[0]\n",
    "        preds[i] = yhat_hybrid\n",
    "\n",
    "    return compute_metrics(y, preds)\n",
    "\n",
    "# =========================================================\n",
    "# MAIN CALIBRATION LOOP # can take out now that I ran and liked the results?\n",
    "# =========================================================\n",
    "files = sorted(glob.glob(os.path.join(decluster_dir, \"decluster_run_*.csv\")))[:5]\n",
    "results = []\n",
    "\n",
    "print(f\"ğŸ” Running OK and RF+OK (LOO) for {len(files)} declustered subsets...\")\n",
    "\n",
    "for i, file in enumerate(tqdm(files, desc=\"Calibration progress\", ncols=100), start=1):\n",
    "    df = pd.read_csv(file)\n",
    "    target = 'log_soc_stock'\n",
    "    X = df.drop(columns=[target, 'X_coord', 'Y_coord', 'site_info_id'], errors='ignore')\n",
    "    y = df[target].values\n",
    "    coords = df[['X_coord', 'Y_coord']].values\n",
    "\n",
    "    ok_metrics = loo_validate_ok(coords, y, variogram_params, model=variogram_model)\n",
    "    hybrid_metrics = loo_validate_rf_ok(X, y, coords, variogram_params)\n",
    "\n",
    "    results.append({'subset': i, 'model': 'OK_LOO', **ok_metrics})\n",
    "    results.append({'subset': i, 'model': 'RF+OK_LOO', **hybrid_metrics})\n",
    "\n",
    "# =========================================================\n",
    "# SAVE & DISPLAY RESULTS\n",
    "# =========================================================\n",
    "results_df = pd.DataFrame(results)\n",
    "out_path = os.path.join(output_dir, \"ok_rfok_calibration_results.csv\")\n",
    "results_df.to_csv(out_path, index=False)\n",
    "\n",
    "print(f\"\\nğŸ“ Calibration results saved to: {out_path}\")\n",
    "print(\"âœ… Calibration complete.\\n\")\n",
    "\n",
    "print(\"Summary (mean across 5 subsets):\")\n",
    "print(results_df.groupby(\"model\")[[\"R2\", \"RMSE\", \"MAE\"]].mean().round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final map prediction all 3 algorithms over declusters 1-50 (in batches to handle memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #1st try, working but results not great and no performance metrics \n",
    "# # =========================================================\n",
    "# # Usage examples:\n",
    "# #   python SOC_ensemble_main.py 1 10\n",
    "# #   python SOC_ensemble_main.py 11 20\n",
    "# #   python SOC_ensemble_main.py 21 30\n",
    "# # =========================================================\n",
    "\n",
    "# import os, sys, glob, gc\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import rasterio\n",
    "# from rasterio.transform import rowcol\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from pykrige.ok import OrdinaryKriging\n",
    "\n",
    "# # =========================================================\n",
    "# # USER PARAMETERS\n",
    "# # =========================================================\n",
    "# decluster_dir = \"/Users/inesschwartz/Desktop/model/decluster_runs_aligned\"\n",
    "# pred_grid_csv = \"/Users/inesschwartz/Desktop/model/covariates_stack_1km_utm33s_fixed.csv\"\n",
    "# ref_raster = \"/Volumes/One_Touch/angola_soils_thesis/GIS_Angola/data_processed/covariates_rasters/terraincovs/slope_height.tif\"\n",
    "# output_dir = \"/Users/inesschwartz/Desktop/model/ensemble_preds\"\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# target = \"log_soc_stock\"\n",
    "\n",
    "# rf_params = {\n",
    "#     \"n_estimators\": 500,\n",
    "#     \"min_samples_leaf\": 3,\n",
    "#     \"max_features\": 0.5,\n",
    "#     \"max_depth\": 20,\n",
    "#     \"random_state\": 42,\n",
    "#     \"n_jobs\": 4  # limit to avoid overload\n",
    "# }\n",
    "\n",
    "# variogram_params = {\n",
    "#     \"model\": \"gaussian\",\n",
    "#     \"variogram_parameters\": {\"nugget\": 0.0, \"sill\": 0.18, \"range\": 14000}\n",
    "# }\n",
    "\n",
    "# features = [\n",
    "#     \"MRRTF\", \"MRVBF\", \"annual_precip\", \"grazing_1950\", \"cropland_1950\",\n",
    "#     \"precip_wettest_month\", \"relief_TRI\", \"standardized_height\",\n",
    "#     \"temp_annual_range\", \"terrain_surf_convexity\", \"terrain_surf_texture\",\n",
    "#     \"tmax_mean\", \"valley_depth\", \"faosoil_id\", \"slope_height\"\n",
    "# ]\n",
    "\n",
    "# # =========================================================\n",
    "# # OPTIONAL: command line batch arguments\n",
    "# # =========================================================\n",
    "# if len(sys.argv) >= 3:\n",
    "#     start_idx = int(sys.argv[1])\n",
    "#     end_idx = int(sys.argv[2])\n",
    "# else:\n",
    "#     start_idx, end_idx = 1, 10  # default batch (1â€“10)\n",
    "\n",
    "# print(f\"\\nğŸš€ Running SOC ensemble for declusters {start_idx}â€“{end_idx}...\")\n",
    "\n",
    "# # =========================================================\n",
    "# # LOAD PREDICTION GRID (same for all declusters)\n",
    "# # =========================================================\n",
    "# df_pred = pd.read_csv(pred_grid_csv)\n",
    "# X_pred = df_pred[features].astype(\"float32\").copy()\n",
    "# coords_pred = df_pred[[\"X_coord\", \"Y_coord\"]].astype(\"float32\").values\n",
    "\n",
    "# # Reference raster geometry\n",
    "# with rasterio.open(ref_raster) as ref:\n",
    "#     profile = ref.profile\n",
    "#     transform = ref.transform\n",
    "#     width, height = ref.width, ref.height\n",
    "#     crs = ref.crs\n",
    "\n",
    "# # Precompute row/col mapping (outside loop)\n",
    "# rows, cols = rowcol(transform, df_pred[\"X_coord\"], df_pred[\"Y_coord\"])\n",
    "# rows, cols = np.array(rows), np.array(cols)\n",
    "# valid_mask = (\n",
    "#     (rows >= 0) & (rows < height) &\n",
    "#     (cols >= 0) & (cols < width)\n",
    "# )\n",
    "\n",
    "# # =========================================================\n",
    "# # MEMORY-SAFE KRIGING FUNCTION\n",
    "# # =========================================================\n",
    "# def krige_in_blocks(ok_model, coords_pred, block_size=10000):\n",
    "#     preds = []\n",
    "#     for start in range(0, len(coords_pred), block_size):\n",
    "#         end = start + block_size\n",
    "#         subset = coords_pred[start:end]\n",
    "#         pred_block, _ = ok_model.execute(\"points\", subset[:, 0], subset[:, 1])\n",
    "#         preds.append(pred_block)\n",
    "#     return np.concatenate(preds)\n",
    "\n",
    "# # =========================================================\n",
    "# # LOOP THROUGH DECLUSTERS (BATCH RANGE)\n",
    "# # =========================================================\n",
    "# decluster_files = sorted(glob.glob(os.path.join(decluster_dir, \"decluster_run_*.csv\")))\n",
    "# subset_files = decluster_files[start_idx-1:end_idx]\n",
    "\n",
    "# print(f\"ğŸ“‚ Running 3 models Ã— {len(subset_files)} declusters in this batch...\")\n",
    "\n",
    "# for i, file in enumerate(subset_files, start=start_idx):\n",
    "#     print(f\"\\n--- Decluster {i:02d} ---\")\n",
    "#     df_train = pd.read_csv(file)\n",
    "#     X_train = df_train[features].astype(\"float32\").copy()\n",
    "#     y_train = df_train[target].astype(\"float32\").copy()\n",
    "#     coords_train = df_train[[\"X_coord\", \"Y_coord\"]].astype(\"float32\").values\n",
    "\n",
    "#     # -----------------------------------------------------\n",
    "#     # 1ï¸âƒ£ RANDOM FOREST (RF)\n",
    "#     # -----------------------------------------------------\n",
    "#     rf = RandomForestRegressor(**rf_params)\n",
    "#     rf.fit(X_train, y_train)\n",
    "#     pred_rf = rf.predict(X_pred)\n",
    "\n",
    "#     # -----------------------------------------------------\n",
    "#     # 2ï¸âƒ£ ORDINARY KRIGING (OK)\n",
    "#     # -----------------------------------------------------\n",
    "#     ok = OrdinaryKriging(\n",
    "#         x=coords_train[:, 0],\n",
    "#         y=coords_train[:, 1],\n",
    "#         z=y_train,\n",
    "#         variogram_model=variogram_params[\"model\"],\n",
    "#         variogram_parameters=variogram_params[\"variogram_parameters\"],\n",
    "#         enable_plotting=False,\n",
    "#         verbose=False\n",
    "#     )\n",
    "#     pred_ok = krige_in_blocks(ok, coords_pred)\n",
    "\n",
    "#     # -----------------------------------------------------\n",
    "#     # 3ï¸âƒ£ HYBRID RF + OK (Residual Kriging)\n",
    "#     # -----------------------------------------------------\n",
    "#     residuals = y_train - rf.predict(X_train)\n",
    "#     ok_resid = OrdinaryKriging(\n",
    "#         x=coords_train[:, 0],\n",
    "#         y=coords_train[:, 1],\n",
    "#         z=residuals,\n",
    "#         variogram_model=variogram_params[\"model\"],\n",
    "#         variogram_parameters=variogram_params[\"variogram_parameters\"],\n",
    "#         enable_plotting=False,\n",
    "#         verbose=False\n",
    "#     )\n",
    "#     pred_resid = krige_in_blocks(ok_resid, coords_pred)\n",
    "#     pred_rfok = pred_rf + pred_resid\n",
    "\n",
    "#     # -----------------------------------------------------\n",
    "#     # BACK-TRANSFORM (log â†’ SOC) AND SAVE RASTERS\n",
    "#     # -----------------------------------------------------\n",
    "#     model_preds = {\n",
    "#         \"RF\": np.expm1(pred_rf),\n",
    "#         \"OK\": np.expm1(pred_ok),\n",
    "#         \"RF_OK\": np.expm1(pred_rfok)\n",
    "#     }\n",
    "\n",
    "#     for model_name, values in model_preds.items():\n",
    "#         arr = np.full((height, width), np.nan, dtype=\"float32\")\n",
    "#         arr[rows[valid_mask], cols[valid_mask]] = values[valid_mask]\n",
    "#         out_tif = os.path.join(output_dir, f\"{model_name}_decluster_{i:03d}.tif\")\n",
    "\n",
    "#         profile.update(dtype=\"float32\", count=1, compress=\"lzw\", nodata=np.nan)\n",
    "#         with rasterio.open(out_tif, \"w\", **profile) as dst:\n",
    "#             dst.write(arr, 1)\n",
    "\n",
    "#     print(f\"âœ… Decluster {i:02d} complete â†’ RF, OK, RF+OK rasters saved.\")\n",
    "\n",
    "#     # Clean up memory before next iteration\n",
    "#     del rf, ok, ok_resid, X_train, y_train, coords_train, pred_rf, pred_ok, pred_resid, pred_rfok, model_preds, arr\n",
    "#     gc.collect()\n",
    "\n",
    "# print(f\"\\nğŸ¯ Batch {start_idx}â€“{end_idx} complete. Rasters saved to:\\n{output_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## declusters--> models --> perfomance metrics and tifs --> aggregated ensemble for final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Running spatial CV for declusters 1â€“10\n",
      "\n",
      "ğŸ§© Decluster 001\n",
      "\n",
      "ğŸ§© Decluster 002\n",
      "\n",
      "ğŸ§© Decluster 003\n",
      "\n",
      "ğŸ§© Decluster 004\n",
      "\n",
      "ğŸ§© Decluster 005\n",
      "\n",
      "ğŸ§© Decluster 006\n",
      "\n",
      "ğŸ§© Decluster 007\n",
      "\n",
      "ğŸ§© Decluster 008\n",
      "\n",
      "ğŸ§© Decluster 009\n",
      "\n",
      "ğŸ§© Decluster 010\n",
      "\n",
      "âœ… Spatial CV done for 10 declusters.\n",
      "ğŸ“ Metrics saved to /Users/inesschwartz/Desktop/model/results_spatialCV/spatialCV_metrics_001_010.csv\n",
      "ğŸ“ Summary saved to /Users/inesschwartz/Desktop/model/results_spatialCV/spatialCV_summary_001_010.csv\n"
     ]
    }
   ],
   "source": [
    "#1 cross validation metrics \n",
    "\n",
    "# =========================================================\n",
    "# SOC_spatialCV_metrics.py\n",
    "# =========================================================\n",
    "# Runs 5-fold spatial CV (10 km GroupKFold) for RF, OK, RF+OK.\n",
    "# Saves per-fold and per-decluster metrics.\n",
    "# =========================================================\n",
    "\n",
    "import os, sys, glob, gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from pykrige.ok import OrdinaryKriging\n",
    "\n",
    "# ---------- User parameters ----------\n",
    "decluster_dir = \"/Users/inesschwartz/Desktop/model/decluster_runs_aligned\"\n",
    "metrics_dir   = \"/Users/inesschwartz/Desktop/model/results_spatialCV\"\n",
    "os.makedirs(metrics_dir, exist_ok=True)\n",
    "\n",
    "target = \"log_soc_stock\"\n",
    "features = [\n",
    "    \"MRRTF\", \"MRVBF\", \"annual_precip\", \"grazing_1950\", \"cropland_1950\",\n",
    "    \"precip_wettest_month\", \"relief_TRI\", \"standardized_height\",\n",
    "    \"temp_annual_range\", \"terrain_surf_convexity\", \"terrain_surf_texture\",\n",
    "    \"tmax_mean\", \"valley_depth\", \"faosoil_id\", \"slope_height\"\n",
    "]\n",
    "\n",
    "rf_params = dict(\n",
    "    n_estimators=500, min_samples_leaf=3, max_features=0.5,\n",
    "    max_depth=20, random_state=42, n_jobs=4\n",
    ")\n",
    "vmodel = \"gaussian\"\n",
    "vparams = {\"nugget\": 0.0, \"sill\": 0.18, \"range\": 14000}\n",
    "\n",
    "# ---------- Batch arguments ----------\n",
    "if len(sys.argv) >= 3:\n",
    "    start_idx, end_idx = int(sys.argv[1]), int(sys.argv[2])\n",
    "else:\n",
    "    start_idx, end_idx = 1, 10\n",
    "\n",
    "print(f\"\\nğŸš€ Running spatial CV for declusters {start_idx}â€“{end_idx}\")\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "def block_groups(df, block_m=10000):\n",
    "    gx = (df[\"X_coord\"] // block_m).astype(int)\n",
    "    gy = (df[\"Y_coord\"] // block_m).astype(int)\n",
    "    return (gx.astype(str) + \"_\" + gy.astype(str)).values\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def krige_predict(xy_train, z_train, xy_test):\n",
    "    ok = OrdinaryKriging(\n",
    "        x=xy_train[:,0], y=xy_train[:,1], z=z_train,\n",
    "        variogram_model=vmodel, variogram_parameters=vparams,\n",
    "        enable_plotting=False, verbose=False\n",
    "    )\n",
    "    pred, _ = ok.execute(\"points\", xy_test[:,0], xy_test[:,1])\n",
    "    return np.asarray(pred)\n",
    "\n",
    "# ---------- Main loop ----------\n",
    "decluster_files = sorted(glob.glob(os.path.join(decluster_dir, \"decluster_run_*.csv\")))\n",
    "subset = decluster_files[start_idx-1:end_idx]\n",
    "all_rows = []\n",
    "\n",
    "for path in subset:\n",
    "    name = os.path.basename(path)\n",
    "    it = int(name.split(\"_\")[-1].split(\".\")[0])\n",
    "    print(f\"\\nğŸ§© Decluster {it:03d}\")\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.dropna(subset=[target]+features+[\"X_coord\",\"Y_coord\"])\n",
    "\n",
    "    X = df[features].astype(\"float32\").values\n",
    "    y = df[target].astype(\"float32\").values\n",
    "    XY = df[[\"X_coord\",\"Y_coord\"]].astype(\"float32\").values\n",
    "    groups = block_groups(df, block_m=10000)\n",
    "    cv = GroupKFold(n_splits=5)\n",
    "\n",
    "    fold = 0\n",
    "    for train_idx, test_idx in cv.split(X, y, groups=groups):\n",
    "        fold += 1\n",
    "        Xtr, Xte = X[train_idx], X[test_idx]\n",
    "        ytr, yte = y[train_idx], y[test_idx]\n",
    "        XYtr, XYte = XY[train_idx], XY[test_idx]\n",
    "\n",
    "        # RF\n",
    "        rf = RandomForestRegressor(**rf_params)\n",
    "        rf.fit(Xtr, ytr)\n",
    "        rf_te = rf.predict(Xte)\n",
    "\n",
    "        # OK\n",
    "        ok_te = krige_predict(XYtr, ytr, XYte)\n",
    "\n",
    "        # RF+OK\n",
    "        resid_tr = ytr - rf.predict(Xtr)\n",
    "        rk_te = rf_te + krige_predict(XYtr, resid_tr, XYte)\n",
    "\n",
    "        for model_name, preds in ((\"RF\", rf_te), (\"OK\", ok_te), (\"RF_OK\", rk_te)):\n",
    "            all_rows.append({\n",
    "                \"decluster\": it, \"fold\": fold, \"model\": model_name,\n",
    "                \"R2\": r2_score(yte, preds),\n",
    "                \"RMSE\": rmse(yte, preds),\n",
    "                \"MAE\": mean_absolute_error(yte, preds)\n",
    "            })\n",
    "        gc.collect()\n",
    "\n",
    "# ---------- Save metrics ----------\n",
    "metrics_df = pd.DataFrame(all_rows)\n",
    "out_metrics = os.path.join(metrics_dir, f\"spatialCV_metrics_{start_idx:03d}_{end_idx:03d}.csv\")\n",
    "metrics_df.to_csv(out_metrics, index=False)\n",
    "\n",
    "summary = (\n",
    "    metrics_df.groupby([\"decluster\",\"model\"])\n",
    "    .agg(R2_mean=(\"R2\",\"mean\"), RMSE_mean=(\"RMSE\",\"mean\"), MAE_mean=(\"MAE\",\"mean\"))\n",
    "    .reset_index()\n",
    ")\n",
    "out_summary = os.path.join(metrics_dir, f\"spatialCV_summary_{start_idx:03d}_{end_idx:03d}.csv\")\n",
    "summary.to_csv(out_summary, index=False)\n",
    "\n",
    "print(f\"\\nâœ… Spatial CV done for {len(subset)} declusters.\")\n",
    "print(f\"ğŸ“ Metrics saved to {out_metrics}\")\n",
    "print(f\"ğŸ“ Summary saved to {out_summary}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Running declusters 1â€“5\n",
      "\n",
      "ğŸ§© Decluster 001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/utils/validation.py:2742: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 108\u001b[0m\n\u001b[1;32m    105\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# ---- OK ----\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m pred_ok \u001b[38;5;241m=\u001b[39m \u001b[43mkrige_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoords_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m# ---- RF+OK ----\u001b[39;00m\n\u001b[1;32m    111\u001b[0m rf_tmp \u001b[38;5;241m=\u001b[39m RandomForestRegressor(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrf_params)\u001b[38;5;241m.\u001b[39mfit(X, y)\n",
      "Cell \u001b[0;32mIn[2], line 57\u001b[0m, in \u001b[0;36mkrige_predict\u001b[0;34m(xy_train, z_train, xy_test)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mkrige_predict\u001b[39m(xy_train, z_train, xy_test):\n\u001b[1;32m     52\u001b[0m     ok \u001b[38;5;241m=\u001b[39m OrdinaryKriging(\n\u001b[1;32m     53\u001b[0m         x\u001b[38;5;241m=\u001b[39mxy_train[:,\u001b[38;5;241m0\u001b[39m], y\u001b[38;5;241m=\u001b[39mxy_train[:,\u001b[38;5;241m1\u001b[39m], z\u001b[38;5;241m=\u001b[39mz_train,\n\u001b[1;32m     54\u001b[0m         variogram_model\u001b[38;5;241m=\u001b[39mvmodel, variogram_parameters\u001b[38;5;241m=\u001b[39mvparams,\n\u001b[1;32m     55\u001b[0m         enable_plotting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     56\u001b[0m     )\n\u001b[0;32m---> 57\u001b[0m     pred, _ \u001b[38;5;241m=\u001b[39m \u001b[43mok\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpoints\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxy_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxy_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(pred)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pykrige/ok.py:999\u001b[0m, in \u001b[0;36mOrdinaryKriging.execute\u001b[0;34m(self, style, xpoints, ypoints, mask, backend, n_closest_points)\u001b[0m\n\u001b[1;32m    991\u001b[0m     bd \u001b[38;5;241m=\u001b[39m core\u001b[38;5;241m.\u001b[39mgreat_circle_distance(\n\u001b[1;32m    992\u001b[0m         xpts[:, np\u001b[38;5;241m.\u001b[39mnewaxis],\n\u001b[1;32m    993\u001b[0m         ypts[:, np\u001b[38;5;241m.\u001b[39mnewaxis],\n\u001b[1;32m    994\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_ADJUSTED,\n\u001b[1;32m    995\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mY_ADJUSTED,\n\u001b[1;32m    996\u001b[0m     )\n\u001b[1;32m    998\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvectorized\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 999\u001b[0m     zvalues, sigmasq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exec_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m backend \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloop\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1001\u001b[0m     zvalues, sigmasq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exec_loop(a, bd, mask)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pykrige/ok.py:670\u001b[0m, in \u001b[0;36mOrdinaryKriging._exec_vector\u001b[0;34m(self, a, bd, mask)\u001b[0m\n\u001b[1;32m    667\u001b[0m     zero_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(np\u001b[38;5;241m.\u001b[39mabsolute(bd) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps)\n\u001b[1;32m    669\u001b[0m b \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((npt, n \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m--> 670\u001b[0m b[:, :n, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariogram_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariogram_model_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m zero_value \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexact_values:\n\u001b[1;32m    672\u001b[0m     b[zero_index[\u001b[38;5;241m0\u001b[39m], zero_index[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pykrige/variogram_models.py:45\u001b[0m, in \u001b[0;36mgaussian_variogram_model\u001b[0;34m(m, d)\u001b[0m\n\u001b[1;32m     43\u001b[0m range_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(m[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     44\u001b[0m nugget \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(m[\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m psill \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2.0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mrange_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m7.0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2.0\u001b[39;49m\u001b[43m)\u001b[49m) \u001b[38;5;241m+\u001b[39m nugget\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# SOC_predict_national_small_batches.py\n",
    "# =========================================================\n",
    "# Run RF, OK, RF+OK national predictions in very small batches\n",
    "# for stability on limited memory systems.\n",
    "# =========================================================\n",
    "\n",
    "import os, glob, gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio.transform import rowcol\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from pykrige.ok import OrdinaryKriging\n",
    "\n",
    "# ---------- Paths ----------\n",
    "decluster_dir = \"/Users/inesschwartz/Desktop/model/decluster_runs_aligned\"\n",
    "pred_grid_csv = \"/Users/inesschwartz/Desktop/model/covariates_stack_1km_utm33s_fixed.csv\"\n",
    "ref_raster    = \"/Volumes/One_Touch/angola_soils_thesis/GIS_Angola/data_processed/covariates_rasters/terraincovs/slope_height.tif\"\n",
    "out_dir       = \"/Users/inesschwartz/Desktop/model/ensemble_preds\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# ---------- Model settings ----------\n",
    "target = \"log_soc_stock\"\n",
    "features = [\n",
    "    \"MRRTF\", \"MRVBF\", \"annual_precip\", \"grazing_1950\", \"cropland_1950\",\n",
    "    \"precip_wettest_month\", \"relief_TRI\", \"standardized_height\",\n",
    "    \"temp_annual_range\", \"terrain_surf_convexity\", \"terrain_surf_texture\",\n",
    "    \"tmax_mean\", \"valley_depth\", \"faosoil_id\", \"slope_height\"\n",
    "]\n",
    "rf_params = dict(n_estimators=500, min_samples_leaf=3, max_features=0.5,\n",
    "                 max_depth=20, random_state=42, n_jobs=2)  # use fewer jobs to reduce memory\n",
    "vmodel = \"gaussian\"\n",
    "vparams = {\"nugget\": 0.0, \"sill\": 0.18, \"range\": 14000}\n",
    "\n",
    "# ---------- Load prediction grid ----------\n",
    "df_pred = pd.read_csv(pred_grid_csv)\n",
    "X_pred = df_pred[features].astype(\"float32\").copy()\n",
    "coords_pred = df_pred[[\"X_coord\", \"Y_coord\"]].astype(\"float32\").values\n",
    "\n",
    "with rasterio.open(ref_raster) as ref:\n",
    "    profile = ref.profile\n",
    "    transform = ref.transform\n",
    "    width, height = ref.width, ref.height\n",
    "\n",
    "rows, cols = rowcol(transform, df_pred[\"X_coord\"], df_pred[\"Y_coord\"])\n",
    "rows, cols = np.array(rows), np.array(cols)\n",
    "valid_mask = ((rows >= 0) & (rows < height) & (cols >= 0) & (cols < width))\n",
    "\n",
    "# ---------- Helper functions ----------\n",
    "def krige_predict(xy_train, z_train, xy_test):\n",
    "    ok = OrdinaryKriging(\n",
    "        x=xy_train[:,0], y=xy_train[:,1], z=z_train,\n",
    "        variogram_model=vmodel, variogram_parameters=vparams,\n",
    "        enable_plotting=False, verbose=False\n",
    "    )\n",
    "    pred, _ = ok.execute(\"points\", xy_test[:,0], xy_test[:,1])\n",
    "    return np.asarray(pred)\n",
    "\n",
    "def save_raster(values_bt, out_path):\n",
    "    arr = np.full((height, width), np.nan, dtype=\"float32\")\n",
    "    arr[rows[valid_mask], cols[valid_mask]] = values_bt[valid_mask].astype(\"float32\")\n",
    "    pf = profile.copy()\n",
    "    pf.update(dtype=\"float32\", count=1, compress=\"lzw\", nodata=np.nan)\n",
    "    with rasterio.open(out_path, \"w\", **pf) as dst:\n",
    "        dst.write(arr, 1)\n",
    "\n",
    "# ---------- Define decluster batches ----------\n",
    "decluster_files = sorted(glob.glob(os.path.join(decluster_dir, \"decluster_run_*.csv\")))\n",
    "\n",
    "# ğŸ’¡ Adjust this for how many to run per batch\n",
    "batch_ranges = [(1,5)]  # run 1â€“5 declusters at a time\n",
    "# batch_ranges = [(6,10)]\n",
    "# batch_ranges = [(11,15)], etc.\n",
    "\n",
    "# ---------- Run loop ----------\n",
    "for (start_idx, end_idx) in batch_ranges:\n",
    "    print(f\"\\nğŸš€ Running declusters {start_idx}â€“{end_idx}\")\n",
    "    subset = decluster_files[start_idx - 1:end_idx]\n",
    "\n",
    "    for path in subset:\n",
    "        it = int(os.path.basename(path).split(\"_\")[-1].split(\".\")[0])\n",
    "        print(f\"\\nğŸ§© Decluster {it:03d}\")\n",
    "\n",
    "        # Skip already done\n",
    "        all_exist = all(\n",
    "            os.path.exists(os.path.join(out_dir, f\"{mdl}_decluster_{it:03d}.tif\"))\n",
    "            for mdl in [\"RF\", \"OK\", \"RF_OK\"]\n",
    "        )\n",
    "        if all_exist:\n",
    "            print(f\"âš ï¸ Skipping decluster {it:03d} (rasters exist).\")\n",
    "            continue\n",
    "\n",
    "        df = pd.read_csv(path)\n",
    "        df = df.dropna(subset=[target] + features + [\"X_coord\", \"Y_coord\"])\n",
    "\n",
    "        X = df[features].astype(\"float32\").values\n",
    "        y = df[target].astype(\"float32\").values\n",
    "        XY = df[[\"X_coord\", \"Y_coord\"]].astype(\"float32\").values\n",
    "\n",
    "        # ---- RF ----\n",
    "        rf = RandomForestRegressor(**rf_params).fit(X, y)\n",
    "        pred_rf = rf.predict(X_pred)\n",
    "        del rf\n",
    "        gc.collect()\n",
    "\n",
    "        # ---- OK ----\n",
    "        pred_ok = krige_predict(XY, y, coords_pred)\n",
    "\n",
    "        # ---- RF+OK ----\n",
    "        rf_tmp = RandomForestRegressor(**rf_params).fit(X, y)\n",
    "        resid = y - rf_tmp.predict(X)\n",
    "        del rf_tmp\n",
    "        gc.collect()\n",
    "\n",
    "        pred_resid = krige_predict(XY, resid, coords_pred)\n",
    "        pred_rfok = pred_rf + pred_resid\n",
    "        del pred_resid\n",
    "        gc.collect()\n",
    "\n",
    "        # ---- Save ----\n",
    "        preds_bt = {\n",
    "            \"RF\": np.expm1(pred_rf),\n",
    "            \"OK\": np.expm1(pred_ok),\n",
    "            \"RF_OK\": np.expm1(pred_rfok)\n",
    "        }\n",
    "        for mdl, vals in preds_bt.items():\n",
    "            out_tif = os.path.join(out_dir, f\"{mdl}_decluster_{it:03d}.tif\")\n",
    "            save_raster(vals, out_tif)\n",
    "            print(f\"ğŸ’¾ Saved {mdl}_decluster_{it:03d}.tif\")\n",
    "\n",
    "        del pred_rf, pred_ok, pred_rfok, preds_bt, X, y, XY\n",
    "        gc.collect()\n",
    "\n",
    "    print(f\"\\nâœ… Finished declusters {start_idx}â€“{end_idx}\\n{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make the final ensemble rasters (once both metrics and per cluster predictions are completed)\n",
    "## run inverse variance aggregation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Aggregating ensemble for model: RF\n",
      "   âœ”ï¸ Added RF_decluster_001.tif\n",
      "   âœ”ï¸ Added RF_decluster_002.tif\n",
      "   âœ”ï¸ Added RF_decluster_003.tif\n",
      "   âœ”ï¸ Added RF_decluster_004.tif\n",
      "   âœ”ï¸ Added RF_decluster_005.tif\n",
      "   âœ”ï¸ Added RF_decluster_006.tif\n",
      "   âœ”ï¸ Added RF_decluster_007.tif\n",
      "   âœ”ï¸ Added RF_decluster_008.tif\n",
      "   âœ”ï¸ Added RF_decluster_009.tif\n",
      "   âœ”ï¸ Added RF_decluster_010.tif\n",
      "ğŸ’¾ Saved mean raster: /Users/inesschwartz/Desktop/model/ensemble_preds/ensemble_mean_RF.tif\n",
      "ğŸ’¾ Saved std raster: /Users/inesschwartz/Desktop/model/ensemble_preds/ensemble_std_RF.tif\n",
      "\n",
      "ğŸ“Š Aggregating ensemble for model: OK\n",
      "   âœ”ï¸ Added OK_decluster_001.tif\n",
      "   âœ”ï¸ Added OK_decluster_002.tif\n",
      "   âœ”ï¸ Added OK_decluster_003.tif\n",
      "   âœ”ï¸ Added OK_decluster_004.tif\n",
      "   âœ”ï¸ Added OK_decluster_005.tif\n",
      "   âœ”ï¸ Added OK_decluster_006.tif\n",
      "   âœ”ï¸ Added OK_decluster_007.tif\n",
      "   âœ”ï¸ Added OK_decluster_008.tif\n",
      "   âœ”ï¸ Added OK_decluster_009.tif\n",
      "   âœ”ï¸ Added OK_decluster_010.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tp/79mdnyy56_xc3g1jvp9wf4_80000gn/T/ipykernel_1499/745305238.py:101: RuntimeWarning: overflow encountered in cast\n",
      "  dst.write(mean_arr.astype(\"float32\"), 1)\n",
      "/var/folders/tp/79mdnyy56_xc3g1jvp9wf4_80000gn/T/ipykernel_1499/745305238.py:107: RuntimeWarning: overflow encountered in cast\n",
      "  dst.write(std_arr.astype(\"float32\"), 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ Saved mean raster: /Users/inesschwartz/Desktop/model/ensemble_preds/ensemble_mean_OK.tif\n",
      "ğŸ’¾ Saved std raster: /Users/inesschwartz/Desktop/model/ensemble_preds/ensemble_std_OK.tif\n",
      "\n",
      "ğŸ“Š Aggregating ensemble for model: RF_OK\n",
      "   âœ”ï¸ Added RF_OK_decluster_001.tif\n",
      "   âœ”ï¸ Added RF_OK_decluster_002.tif\n",
      "   âœ”ï¸ Added RF_OK_decluster_003.tif\n",
      "   âœ”ï¸ Added RF_OK_decluster_004.tif\n",
      "   âœ”ï¸ Added RF_OK_decluster_005.tif\n",
      "   âœ”ï¸ Added RF_OK_decluster_006.tif\n",
      "   âœ”ï¸ Added RF_OK_decluster_007.tif\n",
      "   âœ”ï¸ Added RF_OK_decluster_008.tif\n",
      "   âœ”ï¸ Added RF_OK_decluster_009.tif\n",
      "   âœ”ï¸ Added RF_OK_decluster_010.tif\n",
      "ğŸ’¾ Saved mean raster: /Users/inesschwartz/Desktop/model/ensemble_preds/ensemble_mean_RF_OK.tif\n",
      "ğŸ’¾ Saved std raster: /Users/inesschwartz/Desktop/model/ensemble_preds/ensemble_std_RF_OK.tif\n",
      "\n",
      "ğŸ¯ Ensemble aggregation complete for all models (in SOC stock units).\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# ENSEMBLE AGGREGATION SCRIPT â€” Mean & Std Rasters (with back-transform)\n",
    "# =========================================================\n",
    "# Purpose:\n",
    "#   Aggregate 50 decluster prediction rasters (RF, OK, RF_OK)\n",
    "#   into ensemble mean and std rasters (in SOC stock units).\n",
    "#\n",
    "# Expected input:\n",
    "#   /Users/inesschwartz/Desktop/model/ensemble_preds/\n",
    "#   containing e.g.:\n",
    "#       RF_decluster_001.tif ... RF_decluster_050.tif\n",
    "#       OK_decluster_001.tif ... OK_decluster_050.tif\n",
    "#       RF_OK_decluster_001.tif ... RF_OK_decluster_050.tif\n",
    "#\n",
    "# Output:\n",
    "#   ensemble_mean_RF.tif\n",
    "#   ensemble_std_RF.tif\n",
    "#   ensemble_mean_OK.tif\n",
    "#   ensemble_std_OK.tif\n",
    "#   ensemble_mean_RF_OK.tif\n",
    "#   ensemble_std_RF_OK.tif\n",
    "# =========================================================\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import rasterio\n",
    "\n",
    "# =========================================================\n",
    "# PATHS\n",
    "# =========================================================\n",
    "input_dir = \"/Users/inesschwartz/Desktop/model/ensemble_preds\"\n",
    "output_dir = input_dir  # save to same folder\n",
    "\n",
    "# =========================================================\n",
    "# MODELS TO AGGREGATE\n",
    "# =========================================================\n",
    "models = [\"RF\", \"OK\", \"RF_OK\"]\n",
    "\n",
    "# =========================================================\n",
    "# FUNCTION TO AGGREGATE ENSEMBLE\n",
    "# =========================================================\n",
    "def aggregate_ensemble(model_name):\n",
    "    print(f\"\\nğŸ“Š Aggregating ensemble for model: {model_name}\")\n",
    "\n",
    "    # List of rasters for this model\n",
    "    raster_files = sorted(glob.glob(os.path.join(input_dir, f\"{model_name}_decluster_*.tif\")))\n",
    "    if len(raster_files) == 0:\n",
    "        print(f\"âš ï¸ No rasters found for {model_name}. Skipping.\")\n",
    "        return\n",
    "\n",
    "    # Read first raster to get metadata\n",
    "    with rasterio.open(raster_files[0]) as src:\n",
    "        profile = src.profile\n",
    "        height, width = src.height, src.width\n",
    "        crs = src.crs\n",
    "        transform = src.transform\n",
    "\n",
    "    # Initialize accumulators\n",
    "    sum_arr = np.zeros((height, width), dtype=\"float64\")\n",
    "    sumsq_arr = np.zeros((height, width), dtype=\"float64\")\n",
    "    count_arr = np.zeros((height, width), dtype=\"int32\")\n",
    "\n",
    "    # Loop through decluster rasters\n",
    "    for idx, file in enumerate(raster_files, start=1):\n",
    "        with rasterio.open(file) as src:\n",
    "            data = src.read(1).astype(\"float64\")\n",
    "\n",
    "            # Skip all-NaN or empty rasters\n",
    "            if np.all(np.isnan(data)):\n",
    "                print(f\"   âš ï¸ Skipping empty raster: {file}\")\n",
    "                continue\n",
    "\n",
    "            # --- Back-transform from log-space to SOC (Mg C haâ»Â¹) ---\n",
    "            data_bt = np.expm1(data)\n",
    "            mask = ~np.isnan(data_bt)\n",
    "\n",
    "            sum_arr[mask] += data_bt[mask]\n",
    "            sumsq_arr[mask] += data_bt[mask] ** 2\n",
    "            count_arr[mask] += 1\n",
    "\n",
    "        print(f\"   âœ”ï¸ Added {model_name}_decluster_{idx:03d}.tif\")\n",
    "\n",
    "    # Avoid division by zero\n",
    "    valid_mask = count_arr > 0\n",
    "\n",
    "    # Compute mean and standard deviation\n",
    "    mean_arr = np.full((height, width), np.nan, dtype=\"float64\")\n",
    "    std_arr = np.full((height, width), np.nan, dtype=\"float64\")\n",
    "\n",
    "    mean_arr[valid_mask] = sum_arr[valid_mask] / count_arr[valid_mask]\n",
    "    var_arr = (sumsq_arr[valid_mask] / count_arr[valid_mask]) - mean_arr[valid_mask] ** 2\n",
    "    std_arr[valid_mask] = np.sqrt(np.maximum(var_arr, 0))  # handle rounding negatives\n",
    "\n",
    "    # Update profile for float32 output\n",
    "    profile.update(dtype=\"float32\", count=1, compress=\"lzw\", nodata=np.nan)\n",
    "\n",
    "    # Write mean raster\n",
    "    out_mean = os.path.join(output_dir, f\"ensemble_mean_{model_name}.tif\")\n",
    "    with rasterio.open(out_mean, \"w\", **profile) as dst:\n",
    "        dst.write(mean_arr.astype(\"float32\"), 1)\n",
    "    print(f\"ğŸ’¾ Saved mean raster: {out_mean}\")\n",
    "\n",
    "    # Write std raster\n",
    "    out_std = os.path.join(output_dir, f\"ensemble_std_{model_name}.tif\")\n",
    "    with rasterio.open(out_std, \"w\", **profile) as dst:\n",
    "        dst.write(std_arr.astype(\"float32\"), 1)\n",
    "    print(f\"ğŸ’¾ Saved std raster: {out_std}\")\n",
    "\n",
    "# =========================================================\n",
    "# RUN FOR ALL MODELS\n",
    "# =========================================================\n",
    "for model in models:\n",
    "    aggregate_ensemble(model)\n",
    "\n",
    "print(\"\\nğŸ¯ Ensemble aggregation complete for all models (in SOC stock units).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean RÂ²: 0.32153962074743575\n",
      "Mean RMSE: 0.4383426137430786\n",
      "Mean MAE: 0.3219464170521836\n",
      "Std RÂ²: 0.011843891828476399\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"/Users/inesschwartz/Desktop/model/results_final/rf_model_performance_tuned.csv\")\n",
    "print(\"Mean RÂ²:\", df[\"R2\"].mean())\n",
    "print(\"Mean RMSE:\", df[\"RMSE\"].mean())\n",
    "print(\"Mean MAE:\", df[\"MAE\"].mean())\n",
    "print(\"Std RÂ²:\", df[\"R2\"].std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## something didn't work above. need to check grid alignment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Training samples: 725\n",
      "âœ… Prediction grid points: 1252955\n",
      "ğŸ¯ Final Random Forest model trained on full dataset.\n",
      "ğŸ“ˆ Predictions completed â€” generating raster...\n",
      "âœ… Final SOC stock map saved to:\n",
      "/Users/inesschwartz/Desktop/model/SOC_RF_final.tif\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# FINAL SOC MAP â€” Random Forest (full model)\n",
    "# =========================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import os\n",
    "\n",
    "# =========================================================\n",
    "# PATHS\n",
    "# =========================================================\n",
    "train_csv = \"/Users/inesschwartz/Desktop/model/train_final.csv\"  # Final training dataset (15 covariates)\n",
    "pred_grid_csv = \"/Users/inesschwartz/Desktop/model/covariates_stack_1km_utm33s.csv\"  # Aligned prediction grid\n",
    "output_raster = \"/Users/inesschwartz/Desktop/model/SOC_RF_final.tif\"\n",
    "\n",
    "# =========================================================\n",
    "# RANDOM FOREST PARAMETERS (from tuning)\n",
    "# =========================================================\n",
    "rf_params = {\n",
    "    \"n_estimators\": 1500,\n",
    "    \"min_samples_leaf\": 3,\n",
    "    \"max_features\": 0.5,\n",
    "    \"max_depth\": None,\n",
    "    \"random_state\": 42,\n",
    "    \"n_jobs\": -1\n",
    "}\n",
    "\n",
    "# =========================================================\n",
    "# 1ï¸âƒ£ LOAD DATA\n",
    "# =========================================================\n",
    "df_train = pd.read_csv(train_csv)\n",
    "df_pred = pd.read_csv(pred_grid_csv)\n",
    "\n",
    "target = \"log_soc_stock\"\n",
    "\n",
    "# Define same feature order as used during training\n",
    "features = [\n",
    "    \"MRRTF\", \"MRVBF\", \"annual_precip\", \"grazing_1950\", \"cropland_1950\",\n",
    "    \"precip_wettest_month\", \"relief_TRI\", \"standardized_height\", \"temp_annual_range\",\n",
    "    \"terrain_surf_convexity\", \"terrain_surf_texture\", \"tmax_mean\", \"valley_depth\",\n",
    "    \"faosoil_id\", \"slope_height\"\n",
    "]\n",
    "\n",
    "# Make sure both datasets have same columns and order\n",
    "X_train = df_train[features].copy()\n",
    "y_train = df_train[target].copy()\n",
    "X_pred = df_pred[features].copy()\n",
    "\n",
    "print(f\"âœ… Training samples: {len(df_train)}\")\n",
    "print(f\"âœ… Prediction grid points: {len(df_pred)}\")\n",
    "\n",
    "# =========================================================\n",
    "# 2ï¸âƒ£ TRAIN FINAL RF MODEL\n",
    "# =========================================================\n",
    "rf = RandomForestRegressor(**rf_params)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"ğŸ¯ Final Random Forest model trained on full dataset.\")\n",
    "\n",
    "# =========================================================\n",
    "# 3ï¸âƒ£ PREDICT OVER 1 KM GRID\n",
    "# =========================================================\n",
    "df_pred[\"pred_log_soc\"] = rf.predict(X_pred)\n",
    "df_pred[\"pred_soc\"] = np.exp(df_pred[\"pred_log_soc\"])  # back-transform log SOC if applicable\n",
    "\n",
    "print(\"ğŸ“ˆ Predictions completed â€” generating raster...\")\n",
    "\n",
    "# =========================================================\n",
    "# 4ï¸âƒ£ CREATE OUTPUT RASTER\n",
    "# =========================================================\n",
    "# Load any aligned reference raster for transform and shape\n",
    "ref_raster = \"/Volumes/One_Touch/angola_soils_thesis/GIS_Angola/data_processed/covariates_rasters/terraincovs/slope_height.tif\"\n",
    "\n",
    "with rasterio.open(ref_raster) as ref:\n",
    "    profile = ref.profile\n",
    "    transform = ref.transform\n",
    "    width = ref.width\n",
    "    height = ref.height\n",
    "    crs = ref.crs\n",
    "\n",
    "# Create an empty raster grid and fill values\n",
    "soc_pred_raster = np.full((height, width), np.nan, dtype=\"float32\")\n",
    "\n",
    "# Convert coordinates to row/col\n",
    "rows, cols = rasterio.transform.rowcol(transform, df_pred[\"X_coord\"], df_pred[\"Y_coord\"])\n",
    "valid_mask = (np.array(rows) >= 0) & (np.array(rows) < height) & (np.array(cols) >= 0) & (np.array(cols) < width)\n",
    "\n",
    "soc_pred_raster[rows[valid_mask], cols[valid_mask]] = df_pred.loc[valid_mask, \"pred_soc\"]\n",
    "\n",
    "# Update raster metadata\n",
    "profile.update(dtype=\"float32\", count=1, compress=\"lzw\", nodata=np.nan)\n",
    "\n",
    "# Write raster\n",
    "with rasterio.open(output_raster, \"w\", **profile) as dst:\n",
    "    dst.write(soc_pred_raster, 1)\n",
    "\n",
    "print(f\"âœ… Final SOC stock map saved to:\\n{output_raster}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Reference grid: 1379 Ã— 1532 | CRS: EPSG:32733\n",
      "ğŸ“‚ Found 50 prediction files.\n",
      "âœ… Loaded iteration 01: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_001.csv\n",
      "âœ… Loaded iteration 02: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_002.csv\n",
      "âœ… Loaded iteration 03: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_003.csv\n",
      "âœ… Loaded iteration 04: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_004.csv\n",
      "âœ… Loaded iteration 05: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_005.csv\n",
      "âœ… Loaded iteration 06: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_006.csv\n",
      "âœ… Loaded iteration 07: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_007.csv\n",
      "âœ… Loaded iteration 08: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_008.csv\n",
      "âœ… Loaded iteration 09: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_009.csv\n",
      "âœ… Loaded iteration 10: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_010.csv\n",
      "âœ… Loaded iteration 11: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_011.csv\n",
      "âœ… Loaded iteration 12: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_012.csv\n",
      "âœ… Loaded iteration 13: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_013.csv\n",
      "âœ… Loaded iteration 14: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_014.csv\n",
      "âœ… Loaded iteration 15: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_015.csv\n",
      "âœ… Loaded iteration 16: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_016.csv\n",
      "âœ… Loaded iteration 17: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_017.csv\n",
      "âœ… Loaded iteration 18: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_018.csv\n",
      "âœ… Loaded iteration 19: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_019.csv\n",
      "âœ… Loaded iteration 20: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_020.csv\n",
      "âœ… Loaded iteration 21: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_021.csv\n",
      "âœ… Loaded iteration 22: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_022.csv\n",
      "âœ… Loaded iteration 23: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_023.csv\n",
      "âœ… Loaded iteration 24: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_024.csv\n",
      "âœ… Loaded iteration 25: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_025.csv\n",
      "âœ… Loaded iteration 26: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_026.csv\n",
      "âœ… Loaded iteration 27: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_027.csv\n",
      "âœ… Loaded iteration 28: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_028.csv\n",
      "âœ… Loaded iteration 29: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_029.csv\n",
      "âœ… Loaded iteration 30: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_030.csv\n",
      "âœ… Loaded iteration 31: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_031.csv\n",
      "âœ… Loaded iteration 32: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_032.csv\n",
      "âœ… Loaded iteration 33: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_033.csv\n",
      "âœ… Loaded iteration 34: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_034.csv\n",
      "âœ… Loaded iteration 35: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_035.csv\n",
      "âœ… Loaded iteration 36: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_036.csv\n",
      "âœ… Loaded iteration 37: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_037.csv\n",
      "âœ… Loaded iteration 38: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_038.csv\n",
      "âœ… Loaded iteration 39: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_039.csv\n",
      "âœ… Loaded iteration 40: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_040.csv\n",
      "âœ… Loaded iteration 41: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_041.csv\n",
      "âœ… Loaded iteration 42: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_042.csv\n",
      "âœ… Loaded iteration 43: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_043.csv\n",
      "âœ… Loaded iteration 44: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_044.csv\n",
      "âœ… Loaded iteration 45: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_045.csv\n",
      "âœ… Loaded iteration 46: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_046.csv\n",
      "âœ… Loaded iteration 47: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_047.csv\n",
      "âœ… Loaded iteration 48: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_048.csv\n",
      "âœ… Loaded iteration 49: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_049.csv\n",
      "âœ… Loaded iteration 50: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_050.csv\n",
      "âœ… Saved SOC_RF_mean raster â†’ /Users/inesschwartz/Desktop/model/ensemble_maps/SOC_RF_mean.tif\n",
      "âœ… Saved SOC_RF_std raster â†’ /Users/inesschwartz/Desktop/model/ensemble_maps/SOC_RF_std.tif\n",
      "âœ… Saved SOC_RFOK_mean raster â†’ /Users/inesschwartz/Desktop/model/ensemble_maps/SOC_RFOK_mean.tif\n",
      "âœ… Saved SOC_RFOK_std raster â†’ /Users/inesschwartz/Desktop/model/ensemble_maps/SOC_RFOK_std.tif\n",
      "\n",
      "ğŸ‰ Ensemble mean and uncertainty rasters created successfully!\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# SOC Ensemble Uncertainty Map (RF and RF+OK)\n",
    "# =========================================================\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio.transform import rowcol\n",
    "\n",
    "# --- Paths ---\n",
    "pred_dir = \"/Users/inesschwartz/Desktop/model/predictions\"\n",
    "ref_raster = \"/Volumes/One_Touch/angola_soils_thesis/GIS_Angola/data_processed/covariates_rasters/terraincovs/slope_height.tif\"\n",
    "out_dir = \"/Users/inesschwartz/Desktop/model/ensemble_maps\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# --- Load reference raster for spatial alignment ---\n",
    "with rasterio.open(ref_raster) as ref:\n",
    "    profile = ref.profile\n",
    "    transform = ref.transform\n",
    "    width, height = ref.width, ref.height\n",
    "    crs = ref.crs\n",
    "\n",
    "print(f\"ğŸ“ Reference grid: {width} Ã— {height} | CRS: {crs}\")\n",
    "\n",
    "# --- Collect all prediction CSVs ---\n",
    "csv_files = sorted(glob.glob(os.path.join(pred_dir, \"predictions_iter_*.csv\")))\n",
    "print(f\"ğŸ“‚ Found {len(csv_files)} prediction files.\")\n",
    "\n",
    "# --- Containers ---\n",
    "rf_preds, rfok_preds = [], []\n",
    "coords_ref = None\n",
    "\n",
    "# --- Read each decluster prediction ---\n",
    "for i, f in enumerate(csv_files, start=1):\n",
    "    df = pd.read_csv(f)\n",
    "    if coords_ref is None:\n",
    "        coords_ref = df[['X_coord', 'Y_coord']].copy()\n",
    "    rf_preds.append(df['pred_RF'].values)\n",
    "    rfok_preds.append(df['pred_RF_OK'].values)\n",
    "    print(f\"âœ… Loaded iteration {i:02d}: {f}\")\n",
    "\n",
    "# --- Stack predictions ---\n",
    "rf_stack = np.column_stack(rf_preds)\n",
    "rfok_stack = np.column_stack(rfok_preds)\n",
    "\n",
    "# --- Compute ensemble statistics ---\n",
    "rf_mean = np.nanmean(rf_stack, axis=1)\n",
    "rf_std = np.nanstd(rf_stack, axis=1)\n",
    "rfok_mean = np.nanmean(rfok_stack, axis=1)\n",
    "rfok_std = np.nanstd(rfok_stack, axis=1)\n",
    "\n",
    "# --- Create raster arrays ---\n",
    "rf_mean_raster = np.full((height, width), np.nan, dtype=\"float32\")\n",
    "rf_std_raster = np.full((height, width), np.nan, dtype=\"float32\")\n",
    "rfok_mean_raster = np.full((height, width), np.nan, dtype=\"float32\")\n",
    "rfok_std_raster = np.full((height, width), np.nan, dtype=\"float32\")\n",
    "\n",
    "# --- Convert coordinates to row/col positions ---\n",
    "rows, cols = rasterio.transform.rowcol(transform, coords_ref[\"X_coord\"], coords_ref[\"Y_coord\"])\n",
    "valid_mask = (\n",
    "    (np.array(rows) >= 0)\n",
    "    & (np.array(rows) < height)\n",
    "    & (np.array(cols) >= 0)\n",
    "    & (np.array(cols) < width)\n",
    ")\n",
    "\n",
    "rf_mean_raster[rows[valid_mask], cols[valid_mask]] = rf_mean[valid_mask]\n",
    "rf_std_raster[rows[valid_mask], cols[valid_mask]] = rf_std[valid_mask]\n",
    "rfok_mean_raster[rows[valid_mask], cols[valid_mask]] = rfok_mean[valid_mask]\n",
    "rfok_std_raster[rows[valid_mask], cols[valid_mask]] = rfok_std[valid_mask]\n",
    "\n",
    "# --- Update profile ---\n",
    "profile.update(dtype=\"float32\", count=1, compress=\"lzw\", nodata=np.nan)\n",
    "\n",
    "# --- Save rasters ---\n",
    "out_paths = {\n",
    "    \"SOC_RF_mean\": rf_mean_raster,\n",
    "    \"SOC_RF_std\": rf_std_raster,\n",
    "    \"SOC_RFOK_mean\": rfok_mean_raster,\n",
    "    \"SOC_RFOK_std\": rfok_std_raster,\n",
    "}\n",
    "\n",
    "for name, arr in out_paths.items():\n",
    "    out_path = os.path.join(out_dir, f\"{name}.tif\")\n",
    "    with rasterio.open(out_path, \"w\", **profile) as dst:\n",
    "        dst.write(arr, 1)\n",
    "    print(f\"âœ… Saved {name} raster â†’ {out_path}\")\n",
    "\n",
    "print(\"\\nğŸ‰ Ensemble mean and uncertainty rasters created successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REsuls still very poor...checking 1 decluster at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/utils/validation.py:2742: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ Saved RF raster â†’ /Users/inesschwartz/Desktop/model/ensemble_preds/RF_decluster_001.tif\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# SOC_RF_declu001.py\n",
    "# =========================================================\n",
    "# Random Forest: 5-fold spatial CV + full prediction\n",
    "# =========================================================\n",
    "\n",
    "import os, gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio.transform import rowcol\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# ---------- Paths ----------\n",
    "decluster_csv = \"/Users/inesschwartz/Desktop/model/decluster_runs_aligned/decluster_run_001.csv\"\n",
    "pred_grid_csv = \"/Users/inesschwartz/Desktop/model/covariates_stack_1km_utm33s_fixed.csv\"\n",
    "ref_raster    = \"/Volumes/One_Touch/angola_soils_thesis/GIS_Angola/data_processed/covariates_rasters/terraincovs/slope_height.tif\"\n",
    "out_dir       = \"/Users/inesschwartz/Desktop/model/ensemble_preds\"\n",
    "metrics_dir   = \"/Users/inesschwartz/Desktop/model/results_spatialCV\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "os.makedirs(metrics_dir, exist_ok=True)\n",
    "\n",
    "target = \"log_soc_stock\"\n",
    "features = [\n",
    "    \"MRRTF\", \"MRVBF\", \"annual_precip\", \"grazing_1950\", \"cropland_1950\",\n",
    "    \"precip_wettest_month\", \"relief_TRI\", \"standardized_height\",\n",
    "    \"temp_annual_range\", \"terrain_surf_convexity\", \"terrain_surf_texture\",\n",
    "    \"tmax_mean\", \"valley_depth\", \"faosoil_id\", \"slope_height\"\n",
    "]\n",
    "rf_params = dict(n_estimators=1000, min_samples_leaf=3, max_features=None,\n",
    "                 max_depth=30, random_state=42, n_jobs=4)\n",
    "\n",
    "# ---------- Load data ----------\n",
    "df = pd.read_csv(decluster_csv)\n",
    "df = df.dropna(subset=[target]+features+[\"X_coord\",\"Y_coord\"])\n",
    "\n",
    "X = df[features].astype(\"float32\").values\n",
    "y = df[target].astype(\"float32\").values\n",
    "XY = df[[\"X_coord\",\"Y_coord\"]].astype(\"float32\").values\n",
    "\n",
    "# ---------- Spatial CV ----------\n",
    "def block_groups(df, block_m=10000):\n",
    "    gx = (df[\"X_coord\"] // block_m).astype(int)\n",
    "    gy = (df[\"Y_coord\"] // block_m).astype(int)\n",
    "    return (gx.astype(str) + \"_\" + gy.astype(str)).values\n",
    "\n",
    "groups = block_groups(df)\n",
    "cv = GroupKFold(n_splits=5)\n",
    "\n",
    "metrics = []\n",
    "for fold, (tr, te) in enumerate(cv.split(X, y, groups=groups), 1):\n",
    "    rf = RandomForestRegressor(**rf_params).fit(X[tr], y[tr])\n",
    "    y_pred = rf.predict(X[te])\n",
    "    metrics.append(dict(\n",
    "        fold=fold,\n",
    "        R2=r2_score(y[te], y_pred),\n",
    "        RMSE=np.sqrt(mean_squared_error(y[te], y_pred)),\n",
    "        MAE=np.mean(np.abs(y[te]-y_pred))\n",
    "    ))\n",
    "pd.DataFrame(metrics).to_csv(f\"{metrics_dir}/spatialCV_RF_001.csv\", index=False)\n",
    "\n",
    "# ---------- Full training + prediction ----------\n",
    "rf_full = RandomForestRegressor(**rf_params).fit(X, y)\n",
    "\n",
    "df_pred = pd.read_csv(pred_grid_csv)\n",
    "X_pred = df_pred[features].astype(\"float32\").copy()\n",
    "coords_pred = df_pred[[\"X_coord\",\"Y_coord\"]].astype(\"float32\").values\n",
    "\n",
    "with rasterio.open(ref_raster) as ref:\n",
    "    profile = ref.profile\n",
    "    transform = ref.transform\n",
    "    width, height = ref.width, ref.height\n",
    "rows, cols = rowcol(transform, df_pred[\"X_coord\"], df_pred[\"Y_coord\"])\n",
    "rows, cols = np.array(rows), np.array(cols)\n",
    "valid_mask = ((rows>=0)&(rows<height)&(cols>=0)&(cols<width))\n",
    "\n",
    "pred_rf = np.expm1(rf_full.predict(X_pred))  # back-transform\n",
    "arr = np.full((height, width), np.nan, dtype=\"float32\")\n",
    "arr[rows[valid_mask], cols[valid_mask]] = pred_rf[valid_mask].astype(\"float32\")\n",
    "profile.update(dtype=\"float32\", count=1, compress=\"lzw\", nodata=np.nan)\n",
    "out_tif = os.path.join(out_dir, \"RF_decluster_001.tif\")\n",
    "with rasterio.open(out_tif, \"w\", **profile) as dst:\n",
    "    dst.write(arr, 1)\n",
    "print(f\"ğŸ’¾ Saved RF raster â†’ {out_tif}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved fold 1 points â†’ fold1_points.gpkg  (n=126)\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "# Load the same decluster dataset\n",
    "df = pd.read_csv(\"/Users/inesschwartz/Desktop/model/decluster_runs_aligned/decluster_run_001.csv\")\n",
    "\n",
    "# Same grouping rule as in your model\n",
    "def block_groups(df, block_m=10000):\n",
    "    gx = (df[\"X_coord\"] // block_m).astype(int)\n",
    "    gy = (df[\"Y_coord\"] // block_m).astype(int)\n",
    "    return (gx.astype(str) + \"_\" + gy.astype(str)).values\n",
    "\n",
    "groups = block_groups(df)\n",
    "cv = GroupKFold(n_splits=5)\n",
    "\n",
    "# Get indices for each fold\n",
    "folds = list(cv.split(df, df[\"log_soc_stock\"], groups=groups))\n",
    "\n",
    "# Get fold 1 test indices (the evaluation subset)\n",
    "train_idx, test_idx = folds[0]\n",
    "fold1 = df.iloc[test_idx].copy()\n",
    "\n",
    "# Convert to GeoDataFrame for visualization\n",
    "gdf_fold1 = gpd.GeoDataFrame(\n",
    "    fold1,\n",
    "    geometry=gpd.points_from_xy(fold1.X_coord, fold1.Y_coord),\n",
    "    crs=\"EPSG:32733\"   # UTM 33S (Angola)\n",
    ")\n",
    "\n",
    "gdf_fold1.to_file(\"/Users/inesschwartz/Desktop/model/results_spatialCV/fold1_points.gpkg\", driver=\"GPKG\")\n",
    "print(f\"âœ… Saved fold 1 points â†’ fold1_points.gpkg  (n={len(gdf_fold1)})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 sample count: 126\n",
      "Mean SOC (log): 1.1582292436903145\n",
      "SOC variance: 0.25384484504037236\n"
     ]
    }
   ],
   "source": [
    "print(\"Fold 1 sample count:\", len(fold1))\n",
    "print(\"Mean SOC (log):\", fold1[target].mean())\n",
    "print(\"SOC variance:\", fold1[target].var())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ Saved OK raster â†’ /Users/inesschwartz/Desktop/model/ensemble_preds/OK_decluster_001.tif\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# SOC_OK_declu001.py\n",
    "# =========================================================\n",
    "# Ordinary Kriging: spatial CV + full prediction (blocked)\n",
    "# =========================================================\n",
    "\n",
    "import os, gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio.transform import rowcol\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from pykrige.ok import OrdinaryKriging\n",
    "\n",
    "decluster_csv = \"/Users/inesschwartz/Desktop/model/decluster_runs_aligned/decluster_run_001.csv\"\n",
    "pred_grid_csv = \"/Users/inesschwartz/Desktop/model/covariates_stack_1km_utm33s_fixed.csv\"\n",
    "ref_raster    = \"/Volumes/One_Touch/angola_soils_thesis/GIS_Angola/data_processed/covariates_rasters/terraincovs/slope_height.tif\"\n",
    "out_dir       = \"/Users/inesschwartz/Desktop/model/ensemble_preds\"\n",
    "metrics_dir   = \"/Users/inesschwartz/Desktop/model/results_spatialCV\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "os.makedirs(metrics_dir, exist_ok=True)\n",
    "\n",
    "target = \"log_soc_stock\"\n",
    "variogram_model = \"gaussian\"\n",
    "variogram_params = {\"nugget\": 0.000, \"sill\": 0.181, \"range\": 14206}\n",
    "BLOCK_SIZE = 10000\n",
    "\n",
    "# ---------- Load data ----------\n",
    "df = pd.read_csv(decluster_csv).dropna(subset=[target,\"X_coord\",\"Y_coord\"])\n",
    "y = df[target].astype(\"float32\").values\n",
    "XY = df[[\"X_coord\",\"Y_coord\"]].astype(\"float32\").values\n",
    "\n",
    "# ---------- Spatial CV ----------\n",
    "def block_groups(df, block_m=10000):\n",
    "    gx = (df[\"X_coord\"] // block_m).astype(int)\n",
    "    gy = (df[\"Y_coord\"] // block_m).astype(int)\n",
    "    return (gx.astype(str) + \"_\" + gy.astype(str)).values\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def krige_predict(xy_train, z_train, xy_test):\n",
    "    ok = OrdinaryKriging(\n",
    "        x=xy_train[:,0], y=xy_train[:,1], z=z_train,\n",
    "        variogram_model=variogram_model,\n",
    "        variogram_parameters=variogram_params,\n",
    "        enable_plotting=False, verbose=False\n",
    "    )\n",
    "    pred, _ = ok.execute(\"points\", xy_test[:,0], xy_test[:,1])\n",
    "    return np.asarray(pred)\n",
    "\n",
    "groups = block_groups(df)\n",
    "cv = GroupKFold(n_splits=5)\n",
    "metrics = []\n",
    "for fold, (tr, te) in enumerate(cv.split(XY, y, groups=groups), 1):\n",
    "    preds = krige_predict(XY[tr], y[tr], XY[te])\n",
    "    metrics.append(dict(fold=fold, R2=r2_score(y[te], preds),\n",
    "                        RMSE=rmse(y[te], preds), MAE=np.mean(np.abs(y[te]-preds))))\n",
    "pd.DataFrame(metrics).to_csv(f\"{metrics_dir}/spatialCV_OK_001.csv\", index=False)\n",
    "\n",
    "# ---------- National prediction (blocked) ----------\n",
    "df_pred = pd.read_csv(pred_grid_csv)\n",
    "coords_pred = df_pred[[\"X_coord\",\"Y_coord\"]].astype(\"float32\").values\n",
    "with rasterio.open(ref_raster) as ref:\n",
    "    profile = ref.profile\n",
    "    transform = ref.transform\n",
    "    width, height = ref.width, ref.height\n",
    "rows, cols = rowcol(transform, df_pred[\"X_coord\"], df_pred[\"Y_coord\"])\n",
    "rows, cols = np.array(rows), np.array(cols)\n",
    "valid_mask = ((rows>=0)&(rows<height)&(cols>=0)&(cols<width))\n",
    "\n",
    "ok_full = OrdinaryKriging(\n",
    "    x=XY[:,0], y=XY[:,1], z=y,\n",
    "    variogram_model=variogram_model,\n",
    "    variogram_parameters=variogram_params,\n",
    "    enable_plotting=False, verbose=False\n",
    ")\n",
    "preds = []\n",
    "for i in range(0, len(coords_pred), BLOCK_SIZE):\n",
    "    sub = coords_pred[i:i+BLOCK_SIZE]\n",
    "    pred_block, _ = ok_full.execute(\"points\", sub[:,0], sub[:,1])\n",
    "    preds.append(pred_block)\n",
    "pred_ok = np.concatenate(preds)\n",
    "\n",
    "# Back-transform and save\n",
    "soc_ok = np.expm1(pred_ok)\n",
    "arr = np.full((height, width), np.nan, dtype=\"float32\")\n",
    "arr[rows[valid_mask], cols[valid_mask]] = soc_ok[valid_mask].astype(\"float32\")\n",
    "profile.update(dtype=\"float32\", count=1, compress=\"lzw\", nodata=np.nan)\n",
    "out_tif = os.path.join(out_dir, \"OK_decluster_001.tif\")\n",
    "with rasterio.open(out_tif, \"w\", **profile) as dst:\n",
    "    dst.write(arr, 1)\n",
    "print(f\"ğŸ’¾ Saved OK raster â†’ {out_tif}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK log-space min/max: -0.10891051699397367 3.5822206650881334\n"
     ]
    }
   ],
   "source": [
    "ok_pred_log = pred_ok  # before np.expm1()\n",
    "print(\"OK log-space min/max:\", np.nanmin(ok_pred_log), np.nanmax(ok_pred_log))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SOC (Mg C haâ»Â¹) min/max: 0.0 35.253143\n"
     ]
    }
   ],
   "source": [
    "print(\"Training SOC (Mg C haâ»Â¹) min/max:\",\n",
    "      np.expm1(y.min()), np.expm1(y.max()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
