{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dateutil.parser import parse\n",
    "\n",
    "#import and read data\n",
    "samples = pd.read_excel(\"/Users/inesschwartz/Desktop/Thesis/tables_soil_database/AmostrasAngolaTerrario.xlsx\")\n",
    "analyses = pd.read_excel(\"/Users/inesschwartz/Desktop/Thesis/tables_soil_database/Horizontes Analises.xlsx\")\n",
    "morphology = pd.read_excel(\"/Users/inesschwartz/Desktop/Thesis/tables_soil_database/Horizontes_Morfologia.xlsx\")\n",
    "profile_loc = pd.read_excel(\"/Users/inesschwartz/Desktop/Thesis/tables_soil_database/Perfis_local.xlsx\")\n",
    "soil_profile = pd.read_excel(\"/Users/inesschwartz/Desktop/Thesis/tables_soil_database/Perfis_solo.xlsx\")\n",
    "elemental_analyses = pd.read_excel(\"/Users/inesschwartz/Desktop/Thesis/tables_soil_database/Data XRF Angola_inicial.xlsx\")\n",
    "#soil_type = pd.read_excel(\"/Users/inesschwartz/Desktop/Thesis/tables_soil_database/Perfis_solo.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Samples table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>site_info_id</th>\n",
       "      <th>profile_id</th>\n",
       "      <th>horizon_id</th>\n",
       "      <th>shelf</th>\n",
       "      <th>Room</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>630</td>\n",
       "      <td>172</td>\n",
       "      <td>139</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1946.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>631</td>\n",
       "      <td>173</td>\n",
       "      <td>139</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1946.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>632</td>\n",
       "      <td>174</td>\n",
       "      <td>139</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1946.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>633</td>\n",
       "      <td>175</td>\n",
       "      <td>139</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1946.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>687</td>\n",
       "      <td>1034</td>\n",
       "      <td>208</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1946.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sample_id site_info_id profile_id horizon_id shelf Room    year\n",
       "0       630          172        139       <NA>     1   22  1946.0\n",
       "1       631          173        139       <NA>     1   22  1946.0\n",
       "2       632          174        139       <NA>     1   22  1946.0\n",
       "3       633          175        139       <NA>     1   22  1946.0\n",
       "4       687         1034        208       <NA>     1   22  1946.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = pd.read_excel(\"/Users/inesschwartz/Desktop/Thesis/tables_soil_database/AmostrasAngolaTerrario.xlsx\")\n",
    "\n",
    "# Rename columns in the DataFrame\n",
    "samples.rename(columns={\n",
    "    'Registo': 'sample_id',\n",
    "    'Nº Campo': 'site_info_id',\n",
    "    'Ano': 'year',\n",
    "    'Perfil': 'profile_id',\n",
    "    'Campanha': 'campaign',\n",
    "    'Colónia_Pais': 'country',\n",
    "    'Distrito': 'district',\n",
    "    'AmostraCrivada': 'sample_sifted',\n",
    "    'AmostraNaoCrivada': 'sample_not_sifted',\n",
    "    'Prateleira': 'shelf',\n",
    "    'Sala': 'room'\n",
    "}, inplace=True)\n",
    "\n",
    "# Replace nulls with the string 'null'\n",
    "samples_filled = samples.fillna('null')\n",
    "\n",
    "# analyse duplicated sample_id (PK)\n",
    "duplicated_values = samples['sample_id'][samples['sample_id'].duplicated()].unique()\n",
    "print(duplicated_values)\n",
    "\n",
    "# Change PK (sample_id) to a consistent datatype: Converted to string and truncate to 20 characters (similar to VARCHAR(20))\n",
    "samples_filled['sample_id'] = samples_filled['sample_id'].astype(str).str.strip().str[:20]\n",
    "\n",
    "## make sure profile column is a string/varchar\n",
    "samples_filled['profile_id'] = samples_filled['profile_id'].astype(str).str.strip().str[:20]\n",
    "\n",
    "# Drop unnecessary columns\n",
    "samples_clean = samples_filled.drop(columns=[\n",
    "    'campaign', 'country', 'Província', 'sample_not_sifted', 'sample_sifted', 'Obs'\n",
    "])\n",
    "\n",
    "samples_clean = samples_filled\n",
    "\n",
    "## add empty FK columns to populate later\n",
    "samples_clean['lab_info_id'] = pd.NA\n",
    "samples_clean['horizon_id'] = pd.NA\n",
    "\n",
    "# Rename for consistent schema (only if needed)\n",
    "samples_clean = samples_clean.rename(columns={\n",
    "    'profile': 'profile',\n",
    "    'shelf': 'shelf',\n",
    "    'room': 'Room',\n",
    "    'year': 'year'\n",
    "})\n",
    "\n",
    "samples_clean['shelf'] = samples_clean['shelf'].astype(\"string\")\n",
    "\n",
    "\n",
    "# Reorder columns to match SAMPLES schema\n",
    "samples_check = samples_clean[[\n",
    "    'sample_id',\n",
    "    'site_info_id',\n",
    "    'profile_id',\n",
    "    'horizon_id',\n",
    "    'shelf',\n",
    "    'Room',\n",
    "    'year'\n",
    "]]\n",
    "\n",
    "## Preview results:\n",
    "samples_check.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyses table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10337.    nan 11608.  3497.  3498.  2923.  2924.  2925.  2926.  2927.\n",
      "  2928.  2929.  2930. 16355. 16356.   419.   420. 15682. 13817. 13965.\n",
      "  3418.  9230.  8639.  3529.]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lab_sample_id</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>minerology_id</th>\n",
       "      <th>EG</th>\n",
       "      <th>thick_clay</th>\n",
       "      <th>fine_clay</th>\n",
       "      <th>silt</th>\n",
       "      <th>clay</th>\n",
       "      <th>Eq_Hum</th>\n",
       "      <th>atm_1/3</th>\n",
       "      <th>atm_15</th>\n",
       "      <th>CACO3</th>\n",
       "      <th>gypsum</th>\n",
       "      <th>free_iron</th>\n",
       "      <th>organic_carbon</th>\n",
       "      <th>total_N</th>\n",
       "      <th>P205</th>\n",
       "      <th>organic_material</th>\n",
       "      <th>pH_H2O</th>\n",
       "      <th>pH_KCL</th>\n",
       "      <th>Ca++</th>\n",
       "      <th>Mg++</th>\n",
       "      <th>Na+</th>\n",
       "      <th>K+</th>\n",
       "      <th>exchangable_bases_sum</th>\n",
       "      <th>CEC</th>\n",
       "      <th>V</th>\n",
       "      <th>conductivity</th>\n",
       "      <th>soluble_sodium</th>\n",
       "      <th>Min_&lt;0,002</th>\n",
       "      <th>Min_0,05-0,02</th>\n",
       "      <th>Min_0,2-0,05</th>\n",
       "      <th>Min_2-0,2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10999.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.700001</td>\n",
       "      <td>32.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.3</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.9</td>\n",
       "      <td>5.4</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.83</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.799999</td>\n",
       "      <td>35.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>11.4</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.6</td>\n",
       "      <td>5.1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.98</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>11001.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.500000</td>\n",
       "      <td>46.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>11.1</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5.1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.62</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>11002.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.599998</td>\n",
       "      <td>41.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>15.4</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.91</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>11003.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.799999</td>\n",
       "      <td>47.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>14.5</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.04</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>11004.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.099998</td>\n",
       "      <td>41.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>11.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>11011.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.300000</td>\n",
       "      <td>48.5</td>\n",
       "      <td>17.6</td>\n",
       "      <td>18.5</td>\n",
       "      <td>19.700001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.45</td>\n",
       "      <td>1.11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.9</td>\n",
       "      <td>5.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.49</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>11012.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.600000</td>\n",
       "      <td>42.3</td>\n",
       "      <td>17.8</td>\n",
       "      <td>21.3</td>\n",
       "      <td>19.600000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.56</td>\n",
       "      <td>0.57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.96</td>\n",
       "      <td>20.600000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>11013.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>36.8</td>\n",
       "      <td>22.1</td>\n",
       "      <td>29.1</td>\n",
       "      <td>21.700001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.34</td>\n",
       "      <td>0.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5.3</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.02</td>\n",
       "      <td>16.900000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>11014.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>21.0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>34.8</td>\n",
       "      <td>21.6</td>\n",
       "      <td>32.6</td>\n",
       "      <td>21.600000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.4</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.11</td>\n",
       "      <td>19.299999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lab_sample_id  sample_id minerology_id    EG  thick_clay  fine_clay  silt  \\\n",
       "0              1    10999.0          <NA>   NaN   61.700001       32.8   0.2   \n",
       "1              2    11000.0          <NA>   NaN   52.799999       35.1   0.7   \n",
       "2              3    11001.0          <NA>   NaN   42.500000       46.2   0.2   \n",
       "3              4    11002.0          <NA>   NaN   42.599998       41.8   0.2   \n",
       "4              5    11003.0          <NA>   NaN   36.799999       47.5   1.2   \n",
       "5              6    11004.0          <NA>   NaN   45.099998       41.8   1.4   \n",
       "6              7    11011.0          <NA>   1.0   15.300000       48.5  17.6   \n",
       "7              8    11012.0          <NA>   3.0   18.600000       42.3  17.8   \n",
       "8              9    11013.0          <NA>   7.0   12.000000       36.8  22.1   \n",
       "9             10    11014.0          <NA>  21.0   11.000000       34.8  21.6   \n",
       "\n",
       "   clay     Eq_Hum  atm_1/3  atm_15  CACO3  gypsum  free_iron  organic_carbon  \\\n",
       "0   5.3   4.600000      NaN     NaN    NaN     NaN        NaN            0.55   \n",
       "1  11.4   6.400000      NaN     NaN    NaN     NaN        NaN            0.33   \n",
       "2  11.1   6.300000      NaN     NaN    NaN     NaN        NaN            0.21   \n",
       "3  15.4   5.200000      NaN     NaN    NaN     NaN        NaN            0.10   \n",
       "4  14.5   7.300000      NaN     NaN    NaN     NaN        NaN             NaN   \n",
       "5  11.7   0.000000      NaN     NaN    NaN     NaN        NaN             NaN   \n",
       "6  18.5  19.700001      NaN     3.0    NaN     NaN       1.45            1.11   \n",
       "7  21.3  19.600000      NaN     7.1    NaN     NaN       1.56            0.57   \n",
       "8  29.1  21.700001      NaN    10.0    NaN     NaN       2.34            0.26   \n",
       "9  32.6  21.600000      NaN    11.1    NaN     NaN       2.68            0.15   \n",
       "\n",
       "   total_N  P205  organic_material  pH_H2O  pH_KCL  Ca++  Mg++   Na+    K+  \\\n",
       "0      NaN  0.04               0.9     5.4     4.2  0.23  0.14  0.02  0.03   \n",
       "1      NaN  0.05               0.6     5.1     4.2  0.04  0.10  0.04  0.03   \n",
       "2      NaN  0.05               0.4     5.1     4.2  0.02  0.03  0.03  0.01   \n",
       "3      NaN  0.05               0.2     5.1     4.2  0.02  0.02  0.03  0.01   \n",
       "4      NaN   NaN               NaN     5.0     4.2  0.03  0.03  0.03  0.01   \n",
       "5      NaN   NaN               NaN     4.9     4.5   NaN   NaN   NaN   NaN   \n",
       "6      NaN  0.05               1.9     5.9     4.5  0.51  0.75  0.02  0.18   \n",
       "7      NaN  0.04               1.0     5.5     4.2  0.07  0.42  0.05  0.07   \n",
       "8      NaN  0.04               0.4     5.3     4.2  0.07  0.38  0.02  0.04   \n",
       "9      NaN  0.04               0.3     5.4     4.3  0.07  0.45  0.05  0.03   \n",
       "\n",
       "   exchangable_bases_sum   CEC          V  conductivity  soluble_sodium  \\\n",
       "0                    NaN  1.83  23.000000           NaN             0.0   \n",
       "1                    NaN  1.98  10.600000           NaN             0.0   \n",
       "2                    NaN  1.62   5.600000           NaN             0.0   \n",
       "3                    NaN  0.91   8.800000           NaN             0.0   \n",
       "4                    NaN  1.04   7.700000           NaN             0.0   \n",
       "5                    NaN   NaN        NaN           NaN             0.0   \n",
       "6                    NaN  4.49  32.500000           NaN             0.0   \n",
       "7                    NaN  2.96  20.600000           NaN             0.0   \n",
       "8                    NaN  3.02  16.900000           NaN             0.0   \n",
       "9                    NaN  3.11  19.299999           NaN             0.0   \n",
       "\n",
       "  Min_<0,002 Min_0,05-0,02 Min_0,2-0,05 Min_2-0,2  \n",
       "0        NaN           NaN          NaN       NaN  \n",
       "1        NaN           NaN          NaN       NaN  \n",
       "2        NaN           NaN          NaN       NaN  \n",
       "3        NaN           NaN          NaN       NaN  \n",
       "4        NaN           NaN          NaN       NaN  \n",
       "5        NaN           NaN          NaN       NaN  \n",
       "6        NaN           NaN          NaN       NaN  \n",
       "7        NaN           NaN          NaN       NaN  \n",
       "8        NaN           NaN          NaN       NaN  \n",
       "9        NaN           NaN          NaN       NaN  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyses.rename(columns={\n",
    "    'Amostra': 'sample_id',\n",
    "    'Morfo_id': 'horizon_id',\n",
    "    'Analise-id': 'analysis_id',\n",
    "    'PERFIL': 'profile_id',\n",
    "    'LS': 'upper_limit',\n",
    "    'LI': 'lower_limit',\n",
    "    'EG': 'EG',\n",
    "    'AG': 'thick_clay',\n",
    "    'AF': 'fine_clay',\n",
    "    'Argila': 'clay',\n",
    "    'L': 'silt',\n",
    "    'Gesso': 'gypsum',\n",
    "    'Fe livre': 'free_iron',\n",
    "    'CO':'organic_carbon',\n",
    "    'N total': 'total_N',\n",
    "    'MO': 'OM',\n",
    "    'Soma de bases': 'exchangable_bases_sum',\n",
    "    'CTC': 'CEC',\n",
    "    'Cloretos':'chlorides',\n",
    "    'Sulfatos':'sulfates',\n",
    "    'Condutividade':'conductivity',\n",
    "    'Sódio solúvel':'soluble_sodium',\n",
    "    'P205 total': 'P205',\n",
    "    'pH (H2O)':'pH_H2O',\n",
    "    'pH(KCL)':'pH_KCL',\n",
    "    'MO': 'organic_material'\n",
    "}, inplace=True)\n",
    "\n",
    "# Replace nulls with the string 'null'\n",
    "analyses_filled = analyses.fillna('null')\n",
    "\n",
    "## make sure profile column is a string/varchar\n",
    "analyses_filled['profile_id'] = analyses_filled['profile_id'].astype(str).str.strip().str[:20]\n",
    "\n",
    "# Filter out and print duplicated samples (including the first occurrence)\n",
    "duplicated_values = analyses['sample_id'][analyses['sample_id'].duplicated()].unique()\n",
    "print(duplicated_values)\n",
    "\n",
    "# Drop columns not needed\n",
    "analyses_drop = analyses.drop([\n",
    "    'EqMol (SiO2)', 'EqMol(Al2O3)', 'EqMol(Fe2O3)', 'SiO2/Al2O3', \n",
    "    'SiO2/Fe2O3', 'SiO2/R2O3', 'Fe2O3/Al2O3', 'FE2O3_TARG', \n",
    "    'FE2O3_LARG', 'CEC_ARG', 'GR', 'ID', 'COD_PROV'\n",
    "], axis=1)\n",
    "\n",
    "# Add a new Primary Key ID column starting from 1\n",
    "analyses_drop.insert(0, 'lab_sample_id', range(1, len(analyses_drop) + 1))\n",
    "\n",
    "# Final cleaned dataframe\n",
    "analyses2 = analyses_drop\n",
    "\n",
    "# Define the desired final column order\n",
    "final_columns = [\n",
    "    'lab_sample_id',\n",
    "    'sample_id',\n",
    "    'minerology_id',\n",
    "    'EG',\n",
    "    'thick_clay',\n",
    "    'fine_clay',\n",
    "    'silt',\n",
    "    'clay',\n",
    "    'Eq_Hum',\n",
    "    'atm_1/3',\n",
    "    'atm_15',\n",
    "    'CACO3',\n",
    "    'gypsum',\n",
    "    'free_iron',\n",
    "    'organic_carbon',\n",
    "    'total_N',\n",
    "    'P205',\n",
    "    'organic_material',\n",
    "    'pH_H2O',\n",
    "    'pH_KCL',\n",
    "    'Ca++',\n",
    "    'Mg++',\n",
    "    'Na+',\n",
    "    'K+',\n",
    "    'exchangable_bases_sum',\n",
    "    'CEC',\n",
    "    'V',\n",
    "    'conductivity',\n",
    "    'soluble_sodium',\n",
    "    'Min_<0,002',\n",
    "    'Min_0,05-0,02',\n",
    "    'Min_0,2-0,05',\n",
    "    'Min_2-0,2',\n",
    "]\n",
    "\n",
    "\n",
    "# Add missing columns with NaN values\n",
    "for col in final_columns:\n",
    "    if col not in analyses2.columns:\n",
    "        analyses2[col] = pd.NA  # or np.nan if you prefer\n",
    "\n",
    "# Reorder columns\n",
    "analyses_ready = analyses2[final_columns]\n",
    "\n",
    "# Preview first 10 rows\n",
    "analyses_ready.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## joining elemental analyses to analyses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename 'Lab. Code' to 'sample_id'\n",
    "elemental_analyses.rename(columns={'Lab. Code': 'sample_id'}, inplace=True)\n",
    "\n",
    "# Temporarily convert to string to do the replacements\n",
    "sample_id_cleaned = elemental_analyses['sample_id'].astype(str)\n",
    "sample_id_cleaned = sample_id_cleaned.str.replace('C-', '', regex=False)\n",
    "sample_id_cleaned = sample_id_cleaned.str.replace(' MNL', '', regex=False)\n",
    "\n",
    "# Then convert to numeric (int or float, depending on your data)\n",
    "elemental_analyses['sample_id'] = pd.to_numeric(sample_id_cleaned, errors='coerce')\n",
    "\n",
    "#rename to field_sample_code\n",
    "elemental_analyses.rename(columns={\n",
    "    'Code': 'field_sample_code'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "print (analyses_ready['sample_id'].dtype)\n",
    "print (elemental_analyses['sample_id'].dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "elemental_analyses['sample_id'] = elemental_analyses['sample_id'].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample IDs in elemental_analyses not found in analyses_ready:\n",
      "[16105. 16217. 16033. 16231. 16208. 16274. 16225. 15731. 16078. 15786.\n",
      " 15693. 15678. 15959. 16372. 16418. 16459. 16477. 15498. 15437. 12749.\n",
      " 13109. 14337. 14319. 15484. 15508. 15614. 15580. 15582. 15606. 15463.\n",
      " 14496. 11343. 17892. 16976. 17269. 18248. 16946. 17686. 17728. 17415.\n",
      " 17642. 18212. 17016. 17282. 18429. 17340. 18824. 18448.  8721.  7313.\n",
      "  5502.  5392.  7317.  8626.  7193.  7254.  7293.  8240. 15397. 14403.\n",
      " 14983. 16126. 15059. 15322. 15268. 14808. 15106.]\n"
     ]
    }
   ],
   "source": [
    "# Check which sample_ids in elemental_analyses are NOT in analyses_ready\n",
    "missing_ids = elemental_analyses[~elemental_analyses['sample_id'].isin(analyses_ready['sample_id'])]\n",
    "\n",
    "# Display them\n",
    "print(\"Sample IDs in elemental_analyses not found in analyses_ready:\")\n",
    "print(missing_ids['sample_id'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEFT JOIN ELEMENTAL ANALYSE TO ANALYSE TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lab_sample_id</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>minerology_id</th>\n",
       "      <th>EG</th>\n",
       "      <th>thick_clay</th>\n",
       "      <th>fine_clay</th>\n",
       "      <th>silt</th>\n",
       "      <th>clay</th>\n",
       "      <th>Eq_Hum</th>\n",
       "      <th>atm_1/3</th>\n",
       "      <th>...</th>\n",
       "      <th>Ta</th>\n",
       "      <th>W</th>\n",
       "      <th>Pt</th>\n",
       "      <th>Au</th>\n",
       "      <th>Hg</th>\n",
       "      <th>Tl</th>\n",
       "      <th>Pb</th>\n",
       "      <th>Bi</th>\n",
       "      <th>Th</th>\n",
       "      <th>U</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10999.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.700001</td>\n",
       "      <td>32.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.799999</td>\n",
       "      <td>35.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>11.4</td>\n",
       "      <td>6.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>11001.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.500000</td>\n",
       "      <td>46.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>11.1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>11002.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.599998</td>\n",
       "      <td>41.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>15.4</td>\n",
       "      <td>5.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>11003.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.799999</td>\n",
       "      <td>47.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>14.5</td>\n",
       "      <td>7.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   lab_sample_id  sample_id minerology_id  EG  thick_clay  fine_clay  silt  \\\n",
       "0              1    10999.0          <NA> NaN   61.700001       32.8   0.2   \n",
       "1              2    11000.0          <NA> NaN   52.799999       35.1   0.7   \n",
       "2              3    11001.0          <NA> NaN   42.500000       46.2   0.2   \n",
       "3              4    11002.0          <NA> NaN   42.599998       41.8   0.2   \n",
       "4              5    11003.0          <NA> NaN   36.799999       47.5   1.2   \n",
       "\n",
       "   clay  Eq_Hum  atm_1/3  ...  Ta   W  Pt  Au  Hg  Tl  Pb  Bi  Th   U  \n",
       "0   5.3     4.6      NaN  ... NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "1  11.4     6.4      NaN  ... NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "2  11.1     6.3      NaN  ... NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "3  15.4     5.2      NaN  ... NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "4  14.5     7.3      NaN  ... NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged1= analyses_ready.merge(elemental_analyses, on='sample_id', how='left')\n",
    "merged1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      lab_sample_id  sample_id minerology_id  EG  thick_clay  fine_clay  silt  \\\n",
      "1361           1362     6940.0          <NA> NaN        31.1       43.8   2.7   \n",
      "\n",
      "      clay  Eq_Hum  atm_1/3  ...  K+  exchangable_bases_sum  CEC   V  \\\n",
      "1361  22.7    18.9      NaN  ... NaN                    NaN  NaN NaN   \n",
      "\n",
      "      conductivity  soluble_sodium  Min_<0,002  Min_0,05-0,02  Min_0,2-0,05  \\\n",
      "1361           NaN             0.0         NaN            NaN           NaN   \n",
      "\n",
      "      Min_2-0,2  \n",
      "1361        NaN  \n",
      "\n",
      "[1 rows x 33 columns]\n",
      "    sample_id Soil Profile field_sample_code Code.1      Depht Sampling Date  \\\n",
      "80     6940.0      P134/59          A-320/59  S-492  1.30-1.70    1954-08-06   \n",
      "\n",
      "             Mg             Al             Si      P  ...    Ta   W  Pt  Au  \\\n",
      "80  1457.666667  106266.333333  308859.666667  468.0  ...  26.0 NaN NaN NaN   \n",
      "\n",
      "           Hg   Tl         Pb  Bi         Th   U  \n",
      "80  10.666667  4.0  25.333333 NaN  12.333333 NaN  \n",
      "\n",
      "[1 rows x 44 columns]\n"
     ]
    }
   ],
   "source": [
    "print(analyses_ready[analyses_ready['sample_id'] == 6940])\n",
    "print(elemental_analyses[elemental_analyses['sample_id'] == 6940])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types of each column in merged1:\n",
      "\n",
      "lab_sample_id      int64\n",
      "sample_id        float64\n",
      "EG               float64\n",
      "thick_clay       float64\n",
      "fine_clay        float64\n",
      "                  ...   \n",
      "Tl               float64\n",
      "Pb               float64\n",
      "Bi               float64\n",
      "Th               float64\n",
      "U                float64\n",
      "Length: 68, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Define final column list\n",
    "final_columns = [\n",
    "    'lab_sample_id', 'sample_id', 'EG', 'thick_clay', 'fine_clay', 'silt', 'clay', 'Eq_Hum', 'atm_1/3', 'atm_15',\n",
    "    'CACO3', 'gypsum', 'free_iron', 'organic_carbon', 'total_N', 'P205', 'organic_material', 'pH_H2O', 'pH_KCL',\n",
    "    'Ca++', 'Mg++', 'Na+', 'K+', 'exchangable_bases_sum', 'CEC', 'V', 'conductivity', 'soluble_sodium', 'Min_<0,002',\n",
    "    'Min_0,05-0,02', 'Min_0,2-0,05', 'Min_2-0,2', \n",
    "    'field_sample_code', 'Depth', 'Al', 'Si', 'P', 'S', 'Cl', 'Ti', 'Cr', 'Mn', 'Fe', 'Co', 'Ni', 'Cu', 'Zn',\n",
    "    'As', 'Se', 'Rb', 'Sr', 'Zr', 'Nb', 'Mo', 'Cd', 'Sn', 'Sb', 'Ba', 'Ta', 'W', 'Pt', 'Au', 'Hg', 'Tl', 'Pb', 'Bi',\n",
    "    'Th', 'U',\n",
    "]\n",
    "\n",
    "# Ensure all columns exist in the DataFrame\n",
    "for col in final_columns:\n",
    "    if col not in merged1.columns:\n",
    "        merged1[col] = pd.NA  # or np.nan if preferred\n",
    "\n",
    "# Reorder DataFrame columns\n",
    "merged1 = merged1[final_columns]\n",
    "\n",
    "# Check and print the datatypes of each column\n",
    "print(\"Data types of each column in merged1:\\n\")\n",
    "print(merged1.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check/Change datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lab_sample_id     object\n",
      "sample_id         object\n",
      "EG               float64\n",
      "thick_clay       float64\n",
      "fine_clay        float64\n",
      "                  ...   \n",
      "Tl               float64\n",
      "Pb               float64\n",
      "Bi               float64\n",
      "Th               float64\n",
      "U                float64\n",
      "Length: 68, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Change PK (sample_id) to a consistent datatype: Converted to string and truncate to 20 characters (similar to VARCHAR(20))\n",
    "merged1['sample_id'] = merged1['sample_id'].astype(str).str.strip().str[:20]\n",
    "merged1['lab_sample_id'] = merged1['lab_sample_id'].astype(str).str.strip().str[:20]\n",
    "\n",
    "print(merged1.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check and/or add FK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lab_sample_id</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>EG</th>\n",
       "      <th>thick_clay</th>\n",
       "      <th>fine_clay</th>\n",
       "      <th>silt</th>\n",
       "      <th>clay</th>\n",
       "      <th>Eq_Hum</th>\n",
       "      <th>atm_1/3</th>\n",
       "      <th>atm_15</th>\n",
       "      <th>...</th>\n",
       "      <th>Ta</th>\n",
       "      <th>W</th>\n",
       "      <th>Pt</th>\n",
       "      <th>Au</th>\n",
       "      <th>Hg</th>\n",
       "      <th>Tl</th>\n",
       "      <th>Pb</th>\n",
       "      <th>Bi</th>\n",
       "      <th>Th</th>\n",
       "      <th>U</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10999.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.700001</td>\n",
       "      <td>32.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.799999</td>\n",
       "      <td>35.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>11.4</td>\n",
       "      <td>6.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>11001.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.500000</td>\n",
       "      <td>46.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>11.1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>11002.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.599998</td>\n",
       "      <td>41.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>15.4</td>\n",
       "      <td>5.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>11003.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.799999</td>\n",
       "      <td>47.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>14.5</td>\n",
       "      <td>7.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  lab_sample_id sample_id  EG  thick_clay  fine_clay  silt  clay  Eq_Hum  \\\n",
       "0             1   10999.0 NaN   61.700001       32.8   0.2   5.3     4.6   \n",
       "1             2   11000.0 NaN   52.799999       35.1   0.7  11.4     6.4   \n",
       "2             3   11001.0 NaN   42.500000       46.2   0.2  11.1     6.3   \n",
       "3             4   11002.0 NaN   42.599998       41.8   0.2  15.4     5.2   \n",
       "4             5   11003.0 NaN   36.799999       47.5   1.2  14.5     7.3   \n",
       "\n",
       "   atm_1/3  atm_15  ...  Ta   W  Pt  Au  Hg  Tl  Pb  Bi  Th   U  \n",
       "0      NaN     NaN  ... NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "1      NaN     NaN  ... NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "2      NaN     NaN  ... NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "3      NaN     NaN  ... NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "4      NaN     NaN  ... NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged1.to_csv(\"/Users/inesschwartz/Desktop/Thesis/tables_clean/analyses_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soil Profile Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>profile_id</th>\n",
       "      <th>site_info_id</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>soil_type_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/51</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/57</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/59</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/63</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/54</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  profile_id site_info_id sample_id soil_type_id\n",
       "0       1/51         <NA>      <NA>         <NA>\n",
       "1       1/57         <NA>      <NA>         <NA>\n",
       "2       1/59         <NA>      <NA>         <NA>\n",
       "3       1/63         <NA>      <NA>         <NA>\n",
       "4      10/54         <NA>      <NA>         <NA>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## rename columns\n",
    "soil_profile = pd.read_excel(\"/Users/inesschwartz/Desktop/Thesis/tables_soil_database/Perfis_solo.xlsx\")\n",
    "\n",
    "#rename columns\n",
    "soil_profile.rename(columns={\n",
    "    'Perfil': 'profile_id',\n",
    "    'Agrupamento': 'grouping',\n",
    "    'Pro': 'province',\n",
    "    'País': 'country',\n",
    "    'Local': 'location',\n",
    "    'DATA': 'date',\n",
    "    'CEP_NOME': 'CEP_NAME',\n",
    "}, inplace=True)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "soil_profile_cleaning1 = soil_profile.drop(columns=[\n",
    "    'grouping', 'REF', 'province', 'country', 'LOCAL', 'DESCRITOR1', 'DESCRITOR2', 'DESCRITOR3', 'CEP_GR'\n",
    "])\n",
    "\n",
    "soil_profile_cleaning2 = soil_profile.drop(columns=[\n",
    "    'grouping', 'REF', 'province', 'country', 'LOCAL', 'DESCRITOR1', 'DESCRITOR2', 'DESCRITOR3', 'date', 'CEP_GR'\n",
    "])\n",
    "\n",
    "## make sure profile_id column is a string/varchar\n",
    "soil_profile_cleaning1['profile_id'] = soil_profile_cleaning1['profile_id'].astype(str).str.strip().str[:20]\n",
    "\n",
    "# Add missing columns\n",
    "soil_profile_cleaning2['site_info_id'] = pd.NA\n",
    "soil_profile_cleaning2['sample_id'] = pd.NA \n",
    "soil_profile_cleaning2['soil_type_id'] = pd.NA  \n",
    "soil_profile_cleaning2['site_info_id'] = soil_profile_cleaning2['site_info_id'].astype(str)\n",
    "\n",
    "\n",
    "# Reorder columns to match SAMPLES schema\n",
    "profile_clean = soil_profile_cleaning2[[\n",
    "    'profile_id',\n",
    "    'site_info_id',\n",
    "    'sample_id',\n",
    "    'soil_type_id'\n",
    "]]\n",
    "\n",
    "# Preview the result\n",
    "profile_clean.head()\n",
    "#profile_clean.to_csv(\"/Users/inesschwartz/Desktop/Thesis/tables_clean/profile_clean.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>profile_id</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/51</td>\n",
       "      <td>1951-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/57</td>\n",
       "      <td>1957-06-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/59</td>\n",
       "      <td>1959-07-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/63</td>\n",
       "      <td>1963-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/54</td>\n",
       "      <td>1954-07-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  profile_id       date\n",
       "0       1/51 1951-08-14\n",
       "1       1/57 1957-06-26\n",
       "2       1/59 1959-07-07\n",
       "3       1/63 1963-06-25\n",
       "4      10/54 1954-07-22"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soil_profile_cleaning1 = soil_profile_cleaning1[[\n",
    "    'profile_id',\n",
    "    'date'\n",
    "]]\n",
    "\n",
    "soil_profile_cleaning1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Morphology Horizon Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horizon_id</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>profile_id</th>\n",
       "      <th>horizon_layer</th>\n",
       "      <th>upper_depth</th>\n",
       "      <th>lower_depth</th>\n",
       "      <th>moisture_degree</th>\n",
       "      <th>root_quantity</th>\n",
       "      <th>root_diameter</th>\n",
       "      <th>texture</th>\n",
       "      <th>structure_type</th>\n",
       "      <th>structure_class</th>\n",
       "      <th>structure_degree</th>\n",
       "      <th>pore_diameter</th>\n",
       "      <th>pore_quantity</th>\n",
       "      <th>pore_shape</th>\n",
       "      <th>dry_color_name</th>\n",
       "      <th>dry_hue</th>\n",
       "      <th>dry_value</th>\n",
       "      <th>dry_chroma</th>\n",
       "      <th>moist_color_name</th>\n",
       "      <th>moist_hue</th>\n",
       "      <th>moist_value</th>\n",
       "      <th>moist_chroma</th>\n",
       "      <th>compaction</th>\n",
       "      <th>durability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B_101/62_1_1</td>\n",
       "      <td>10999.0</td>\n",
       "      <td>101/62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Seco</td>\n",
       "      <td>Muitas finas e bastantes medias</td>\n",
       "      <td>null</td>\n",
       "      <td>Arenoso</td>\n",
       "      <td>Granulosa</td>\n",
       "      <td>Fina (1 a  2 mm)</td>\n",
       "      <td>Fraco</td>\n",
       "      <td>Muito finos</td>\n",
       "      <td>Pouco poroso</td>\n",
       "      <td>null</td>\n",
       "      <td>Pardo-acinzentado a pardo</td>\n",
       "      <td>10YR</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Pardo-acinzentado-escuro</td>\n",
       "      <td>10YR</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Pequena a minima</td>\n",
       "      <td>Brando</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B_101/62_2_1</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>101/62</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Seco</td>\n",
       "      <td>Bastantes finas e medias e raras grossas</td>\n",
       "      <td>null</td>\n",
       "      <td>Arenoso-franco</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>Sem agregacao</td>\n",
       "      <td>Muito finos</td>\n",
       "      <td>Pouco poroso</td>\n",
       "      <td>null</td>\n",
       "      <td>Pardo</td>\n",
       "      <td>10YR</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Pardo-amarelado-escuro</td>\n",
       "      <td>10YR</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Pequena</td>\n",
       "      <td>Brando</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B_101/62_3_1</td>\n",
       "      <td>11001.0</td>\n",
       "      <td>101/62</td>\n",
       "      <td>3.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>Seco</td>\n",
       "      <td>Algumas finas e medias e raras grossas</td>\n",
       "      <td>null</td>\n",
       "      <td>Arenoso-franco</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>Sem agregacao</td>\n",
       "      <td>Muito finos</td>\n",
       "      <td>Pouco poroso</td>\n",
       "      <td>null</td>\n",
       "      <td>Pardo-amarelado-claro</td>\n",
       "      <td>10YR</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Pardo-amarelado-escuro</td>\n",
       "      <td>10YR</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Pequena a minima</td>\n",
       "      <td>Brando</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B_101/62_4_1</td>\n",
       "      <td>11002.0</td>\n",
       "      <td>101/62</td>\n",
       "      <td>4.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Seco</td>\n",
       "      <td>Poucas finas, algumas medias e raras grossas</td>\n",
       "      <td>null</td>\n",
       "      <td>Franco-arenoso a arenoso-franco</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>Sem agregacao</td>\n",
       "      <td>Muito finos</td>\n",
       "      <td>Pouco a medianamente poroso</td>\n",
       "      <td>null</td>\n",
       "      <td>Amarelo a amarelo-avermelhado</td>\n",
       "      <td>8,75YR</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Pardo-forte</td>\n",
       "      <td>7,5YR</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Pequena a minima</td>\n",
       "      <td>Brando</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B_101/62_5_2</td>\n",
       "      <td>11003.2</td>\n",
       "      <td>101/62</td>\n",
       "      <td>5.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>Seco a humido</td>\n",
       "      <td>Raras</td>\n",
       "      <td>Medias e grossas</td>\n",
       "      <td>Arenoso-franco</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>Sem agregacao</td>\n",
       "      <td>Muito finos</td>\n",
       "      <td>Pouco a medianamente poroso</td>\n",
       "      <td>null</td>\n",
       "      <td>Pardo-avermelhado</td>\n",
       "      <td>7,5YR</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Pardo-forte</td>\n",
       "      <td>7,5YR</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Pequena</td>\n",
       "      <td>Brando</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     horizon_id sample_id profile_id horizon_layer upper_depth lower_depth  \\\n",
       "0  B_101/62_1_1   10999.0     101/62           1.0         0.0        11.0   \n",
       "1  B_101/62_2_1   11000.0     101/62           2.0        11.0        28.0   \n",
       "2  B_101/62_3_1   11001.0     101/62           3.0        28.0        54.0   \n",
       "3  B_101/62_4_1   11002.0     101/62           4.0        54.0        90.0   \n",
       "4  B_101/62_5_2   11003.2     101/62           5.0        90.0       160.0   \n",
       "\n",
       "  moisture_degree                                 root_quantity  \\\n",
       "0            Seco               Muitas finas e bastantes medias   \n",
       "1            Seco      Bastantes finas e medias e raras grossas   \n",
       "2            Seco        Algumas finas e medias e raras grossas   \n",
       "3            Seco  Poucas finas, algumas medias e raras grossas   \n",
       "4   Seco a humido                                         Raras   \n",
       "\n",
       "      root_diameter                          texture structure_type  \\\n",
       "0              null                          Arenoso      Granulosa   \n",
       "1              null                   Arenoso-franco           null   \n",
       "2              null                   Arenoso-franco           null   \n",
       "3              null  Franco-arenoso a arenoso-franco           null   \n",
       "4  Medias e grossas                   Arenoso-franco           null   \n",
       "\n",
       "    structure_class structure_degree pore_diameter  \\\n",
       "0  Fina (1 a  2 mm)            Fraco   Muito finos   \n",
       "1              null    Sem agregacao   Muito finos   \n",
       "2              null    Sem agregacao   Muito finos   \n",
       "3              null    Sem agregacao   Muito finos   \n",
       "4              null    Sem agregacao   Muito finos   \n",
       "\n",
       "                 pore_quantity pore_shape                 dry_color_name  \\\n",
       "0                 Pouco poroso       null      Pardo-acinzentado a pardo   \n",
       "1                 Pouco poroso       null                          Pardo   \n",
       "2                 Pouco poroso       null          Pardo-amarelado-claro   \n",
       "3  Pouco a medianamente poroso       null  Amarelo a amarelo-avermelhado   \n",
       "4  Pouco a medianamente poroso       null              Pardo-avermelhado   \n",
       "\n",
       "  dry_hue dry_value dry_chroma          moist_color_name moist_hue  \\\n",
       "0    10YR       5.0        2.5  Pardo-acinzentado-escuro      10YR   \n",
       "1    10YR       5.0        3.0    Pardo-amarelado-escuro      10YR   \n",
       "2    10YR       6.0        4.0    Pardo-amarelado-escuro      10YR   \n",
       "3  8,75YR       7.0        6.0               Pardo-forte     7,5YR   \n",
       "4   7,5YR       7.0        6.0               Pardo-forte     7,5YR   \n",
       "\n",
       "  moist_value moist_chroma        compaction durability  \n",
       "0         4.0          2.0  Pequena a minima     Brando  \n",
       "1         3.0          4.0           Pequena     Brando  \n",
       "2         4.0          4.0  Pequena a minima     Brando  \n",
       "3         5.0          6.0  Pequena a minima     Brando  \n",
       "4         5.0          6.0           Pequena     Brando  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rename columns\n",
    "morphology.rename(columns={\n",
    "    'Morfo_id':'horizon_id',\n",
    "    'Amostra': 'sample_id',\n",
    "    'Perfil': 'profile_id',\n",
    "    'CM':'horizon_layer',\n",
    "    'Limite Superior': 'upper_depth',\n",
    "    'Limite inferior': 'lower_depth',\n",
    "    'Grau de humidade': 'moisture_degree',\n",
    "    'Quantidade de raízes': 'root_quantity',\n",
    "    'Diâmetro de raízes': 'root_diameter',\n",
    "    'Textura': 'texture',\n",
    "    'Tipo de estrutura': 'structure_type',\n",
    "    'Classes de estrutura': 'structure_class',\n",
    "    'Grau de estrutura': 'structure_degree',\n",
    "    'Diâmetro de poros': 'pore_diameter',\n",
    "    'Quantidade de poros': 'pore_quantity',\n",
    "    'Forma de poros': 'pore_shape',\n",
    "    'Cor (s)': 'dry_color_name',\n",
    "    'Matiz (s)': 'dry_hue',\n",
    "    'Valor (s)':'dry_value',\n",
    "    'Croma (s)': 'dry_chroma',\n",
    "    'Cor (h)': 'moist_color_name',\n",
    "    'Matiz (h)': 'moist_hue',\n",
    "    'Valor (h)': 'moist_value',\n",
    "    'Croma (h)': 'moist_chroma',\n",
    "    'Compacidade':'compaction',\n",
    "    'Dureza': 'durability'\n",
    "}, inplace=True)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "morphology_cleaning = morphology.drop(columns=[\n",
    "    'ID1', 'Agrupamento', 'REF', 'Pro', 'Observaçoes', 'Horizonte de diagnóstico', 'Propriedade de diagnóstico', 'Nitidez do limite', 'Designação do horizonte', 'Observaçoes', 'Confirmar', 'Adesividade', 'Plasticidade', 'Efervescência com HCl', 'Friabilidade', 'Orientação das Fendas', 'Largura das fendas', 'Quantidade de fendas'\n",
    "])\n",
    "\n",
    "## make sure profile_id column is a string/varchar\n",
    "morphology_cleaning['profile_id'] = morphology_cleaning['profile_id'].astype(str).str.strip().str[:20]\n",
    "\n",
    "\n",
    "#drop accents\n",
    "import unicodedata\n",
    "def remove_accents(text):\n",
    "    if isinstance(text, str):\n",
    "        # Normalize and remove diacritics\n",
    "        text = unicodedata.normalize('NFKD', text)\n",
    "        text = ''.join(c for c in text if not unicodedata.combining(c))\n",
    "        return text\n",
    "    return text\n",
    "\n",
    "# Apply to all cells in the DataFrame\n",
    "morphology_cleaning = morphology_cleaning.applymap(remove_accents)\n",
    "\n",
    "morphology_cleaning = morphology_cleaning.fillna('null')\n",
    "\n",
    "\n",
    "# Reorder columns to match SAMPLES schema\n",
    "morphology_clean = morphology_cleaning[[\n",
    "    'horizon_id',\n",
    "    'sample_id',\n",
    "    'profile_id',\n",
    "    'horizon_layer',\n",
    "    'upper_depth',\n",
    "    'lower_depth',\n",
    "    'moisture_degree',\n",
    "    'root_quantity',\n",
    "    'root_diameter',\n",
    "    'texture',\n",
    "    'structure_type',\n",
    "    'structure_class',\n",
    "    'structure_degree',\n",
    "    'pore_diameter',\n",
    "    'pore_quantity',\n",
    "    'pore_shape',\n",
    "    'dry_color_name',\n",
    "    'dry_hue',\n",
    "    'dry_value',\n",
    "    'dry_chroma',\n",
    "    'moist_color_name',\n",
    "    'moist_hue',\n",
    "    'moist_value',\n",
    "    'moist_chroma',\n",
    "    'compaction',\n",
    "    'durability'\n",
    "]]\n",
    "\n",
    "# Show first few rows\n",
    "morphology_clean.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soil Type Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>soil_type_id</th>\n",
       "      <th>profile_id</th>\n",
       "      <th>grouping</th>\n",
       "      <th>CEP_GR</th>\n",
       "      <th>CEP_NAME</th>\n",
       "      <th>FAO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1/51</td>\n",
       "      <td>H 62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1/57</td>\n",
       "      <td>M 9</td>\n",
       "      <td>Aridicos</td>\n",
       "      <td>Aridicos com calcario Pardo-cinzentos</td>\n",
       "      <td>CLha</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   soil_type_id profile_id grouping    CEP_GR  \\\n",
       "0             1       1/51     H 62       NaN   \n",
       "1             2       1/57      M 9  Aridicos   \n",
       "\n",
       "                                CEP_NAME   FAO  \n",
       "0                                    NaN   NaN  \n",
       "1  Aridicos com calcario Pardo-cinzentos  CLha  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rename columns\n",
    "soil_type = soil_profile\n",
    "\n",
    "soil_type.rename(columns={\n",
    "    'Perfil': 'profile_id',\n",
    "    'Agrupamento': 'grouping',\n",
    "    'Pro': 'province',\n",
    "    'País': 'country',\n",
    "    'Local': 'location',\n",
    "    'DATA': 'date',\n",
    "    'CEP_NOME': 'CEP_NAME',\n",
    "}, inplace=True)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "soil_type_cleaning = soil_type.drop(columns=[\n",
    "    'REF', 'province', 'country', 'LOCAL', 'DESCRITOR1', 'DESCRITOR2', 'DESCRITOR3', 'date', 'Fase', 'D_INSERÇAO', 'Publicação', 'WRB_old', 'Missão'\n",
    "])\n",
    "# Add a new Primary Key ID column starting from 1\n",
    "soil_type_cleaning.insert(0, 'soil_type_id', range(1, len(soil_type_cleaning) + 1))\n",
    "\n",
    "## make sure profile_id column is a string/varchar\n",
    "soil_type_cleaning['profile_id'] = soil_type_cleaning['profile_id'].astype(str).str.strip().str[:20]\n",
    "\n",
    "#drop accents\n",
    "import unicodedata\n",
    "def remove_accents(text):\n",
    "    if isinstance(text, str):\n",
    "        # Normalize and remove diacritics\n",
    "        text = unicodedata.normalize('NFKD', text)\n",
    "        text = ''.join(c for c in text if not unicodedata.combining(c))\n",
    "        return text\n",
    "    return text\n",
    "\n",
    "# Apply to all cells in the DataFrame\n",
    "soil_type_cleaning = soil_type_cleaning.applymap(remove_accents)\n",
    "\n",
    "soil_type_clean = soil_type_cleaning\n",
    "\n",
    "soil_type_clean.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Site info table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_info_cleaning = profile_loc\n",
    "\n",
    "site_info_cleaning.rename(columns={\n",
    "    'PERFIL': 'profile_id',\n",
    "    'X_COORD': 'X_coord',\n",
    "    'Y_COORD': 'Y_coord'\n",
    "}, inplace=True)\n",
    "\n",
    "# Add a new Primary Key ID column starting from 1\n",
    "site_info_cleaning.insert(0, 'site_info_id', range(1, len(site_info_cleaning) + 1))\n",
    "\n",
    "## make sure profile_id column is a string/varchar\n",
    "site_info_cleaning['profile_id'] = site_info_cleaning['profile_id'].astype(str).str.strip().str[:20]\n",
    "\n",
    "\n",
    "# Add missing columns\n",
    "site_info_cleaning['land_cover_id'] = pd.NA\n",
    "site_info_cleaning['climate_id'] = pd.NA  \n",
    "site_info_cleaning['geology_id'] = pd.NA\n",
    "site_info_cleaning['topo_feature_id'] = pd.NA  \n",
    "site_info_cleaning['sampling_date'] = pd.NA\n",
    "site_info_cleaning['districts_id'] = pd.NA  \n",
    "\n",
    "\n",
    "site_info_clean = site_info_cleaning[[\n",
    "    'site_info_id',\n",
    "    'profile_id', ##do I add profile ID here to then try to merge date info from soil Perfis_solo table? or is this too complicated?\n",
    "    'X_coord',\n",
    "    'Y_coord',\n",
    "    'land_cover_id',\n",
    "    'climate_id',\n",
    "    'geology_id',\n",
    "    'topo_feature_id',\n",
    "    'sampling_date',\n",
    "    'districts_id'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>profile_id</th>\n",
       "      <th>date</th>\n",
       "      <th>site_info_id</th>\n",
       "      <th>X_coord</th>\n",
       "      <th>Y_coord</th>\n",
       "      <th>land_cover_id</th>\n",
       "      <th>climate_id</th>\n",
       "      <th>geology_id</th>\n",
       "      <th>topo_feature_id</th>\n",
       "      <th>sampling_date</th>\n",
       "      <th>districts_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/51</td>\n",
       "      <td>1951-08-14</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/57</td>\n",
       "      <td>1957-06-26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.161278</td>\n",
       "      <td>-15.222598</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/59</td>\n",
       "      <td>1959-07-07</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.575775</td>\n",
       "      <td>-4.866986</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/63</td>\n",
       "      <td>1963-06-25</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.081955</td>\n",
       "      <td>-9.274587</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/54</td>\n",
       "      <td>1954-07-22</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.445188</td>\n",
       "      <td>-14.922688</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  profile_id       date site_info_id    X_coord    Y_coord land_cover_id  \\\n",
       "0       1/51 1951-08-14          nan        NaN        NaN           NaN   \n",
       "1       1/57 1957-06-26          1.0  12.161278 -15.222598          <NA>   \n",
       "2       1/59 1959-07-07          2.0  12.575775  -4.866986          <NA>   \n",
       "3       1/63 1963-06-25          4.0  17.081955  -9.274587          <NA>   \n",
       "4      10/54 1954-07-22          9.0  14.445188 -14.922688          <NA>   \n",
       "\n",
       "  climate_id geology_id topo_feature_id sampling_date districts_id  \n",
       "0        NaN        NaN             NaN           NaN          NaN  \n",
       "1       <NA>       <NA>            <NA>          <NA>         <NA>  \n",
       "2       <NA>       <NA>            <NA>          <NA>         <NA>  \n",
       "3       <NA>       <NA>            <NA>          <NA>         <NA>  \n",
       "4       <NA>       <NA>            <NA>          <NA>         <NA>  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging date info from perfis_solo to site_info table\n",
    "\n",
    "merged = soil_profile_cleaning1.merge(site_info_clean, on='profile_id', how='left')\n",
    "\n",
    "merged['site_info_id'] = merged['site_info_id'].astype(str)\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "soil_profile_clean = merged\n",
    "soil_profile_clean.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save clean table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Climate table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>climate_id</th>\n",
       "      <th>profile_id</th>\n",
       "      <th>mean_annual_temp</th>\n",
       "      <th>mean_annual_precip</th>\n",
       "      <th>koppen_climate</th>\n",
       "      <th>thornthwaite_climate</th>\n",
       "      <th>hydric_regime</th>\n",
       "      <th>thermal_regime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1/57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arido</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1/59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Humido</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1/61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1/63</td>\n",
       "      <td>21.5</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>Tropical chuvoso com estacao seca no Inverno, ...</td>\n",
       "      <td>Humido</td>\n",
       "      <td>Tropustico udico</td>\n",
       "      <td>Iso-Hipertermico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1/64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   climate_id profile_id  mean_annual_temp  mean_annual_precip  \\\n",
       "0           1       1/57               NaN                 NaN   \n",
       "1           2       1/59               NaN                 NaN   \n",
       "2           3       1/61               NaN                 NaN   \n",
       "3           4       1/63              21.5              1500.0   \n",
       "4           5       1/64               NaN                 NaN   \n",
       "\n",
       "                                      koppen_climate thornthwaite_climate  \\\n",
       "0                                                NaN                Arido   \n",
       "1                                                NaN               Humido   \n",
       "2                                                NaN                  NaN   \n",
       "3  Tropical chuvoso com estacao seca no Inverno, ...               Humido   \n",
       "4                                                NaN                  NaN   \n",
       "\n",
       "      hydric_regime    thermal_regime  \n",
       "0               NaN               NaN  \n",
       "1               NaN               NaN  \n",
       "2               NaN               NaN  \n",
       "3  Tropustico udico  Iso-Hipertermico  \n",
       "4               NaN               NaN  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import unicodedata\n",
    "\n",
    "# Load original Excel data\n",
    "profile_loc = pd.read_excel(\"/Users/inesschwartz/Desktop/Thesis/tables_soil_database/Perfis_local.xlsx\")\n",
    "\n",
    "# Create a copy for cleaning\n",
    "climate_features_cleaning = profile_loc.copy()\n",
    "\n",
    "# Mapping from climate codes to descriptions\n",
    "code_to_description = {\n",
    "    \"B1\": \"Húmido\", \"B2\": \"Húmido\", \"B3\": \"Húmido\", \"B4\": \"Húmido\",\n",
    "    \"C1\": \"Sub-húmido seco\", \"C2\": \"Sub-húmido chuvoso\",\n",
    "    \"D\": \"Semi-árido\", \"E\": \"Árido\", \"Aw\": \"Tropical chuvoso com estação seca no Inverno, de savana\",\n",
    "    \"BSw\": \"Seco de estepe, com chuva predominante no Verão\",\n",
    "    \"BWw\": \"Seco de deserto, com chuva predominante no Verão\",\n",
    "    \"Cw\": \"Mesotérmico húmido com estação seca no Inverno\",\n",
    "    \"ARe\": \"Arídico extremo\", \"ARf\": \"Arídico fraco\", \"ARt\": \"Arídico típico\",\n",
    "    \"tUDs\": \"Tempúdico seco\", \"tUSh\": \"Tempústico húmido\", \"tUSt\": \"Tempústico típico\",\n",
    "    \"TUDs\": \"Tropúdico seco\", \"TUSa\": \"Tropústico arídico\", \"TUSu\": \"Tropústico údico\", \"TUSt\": \"Tropustico típico\",\n",
    "    \"H\": \"Hipertérmico\", \"iH\": \"Iso-Hipertérmico\", \"iT\": \"Iso-Térmico\", \"T\": \"Térmico\"\n",
    "}\n",
    "\n",
    "# Replace climate codes with descriptions\n",
    "for col in [\"CL_THORNTH\", \"CL_KOPPEN\", \"REG_HÍDRIC\", \"REG_TÉRMIC\"]:\n",
    "    climate_features_cleaning[col] = climate_features_cleaning[col].replace(code_to_description)\n",
    "\n",
    "# Function to average values like \"21-22\" -> 21.5\n",
    "def average_range(value):\n",
    "    if isinstance(value, str) and '-' in value:\n",
    "        try:\n",
    "            nums = [float(x.strip()) for x in value.split('-')]\n",
    "            return sum(nums) / len(nums)\n",
    "        except:\n",
    "            return None\n",
    "    try:\n",
    "        return float(value)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Apply to TMA and PMA columns\n",
    "climate_features_cleaning[\"TMA\"] = climate_features_cleaning[\"TMA\"].apply(average_range)\n",
    "climate_features_cleaning[\"PMA\"] = climate_features_cleaning[\"PMA\"].apply(average_range)\n",
    "\n",
    "# Rename columns\n",
    "climate_features_cleaning.rename(columns={\n",
    "    'PERFIL': 'profile_id',\n",
    "    'CL_THORNTH': 'thornthwaite_climate',\n",
    "    'CL_KOPPEN': 'koppen_climate',\n",
    "    'TMA': 'mean_annual_temp',\n",
    "    'PMA': 'mean_annual_precip',\n",
    "    'REG_HÍDRIC': 'hydric_regime',\n",
    "    'REG_TÉRMIC': 'thermal_regime'\n",
    "}, inplace=True)\n",
    "\n",
    "## make sure profile_id column is a string/varchar\n",
    "climate_features_cleaning['profile_id'] = climate_features_cleaning['profile_id'].astype(str).str.strip().str[:20]\n",
    "\n",
    "# Drop accents from text values\n",
    "def remove_accents(text):\n",
    "    if isinstance(text, str):\n",
    "        text = unicodedata.normalize('NFKD', text)\n",
    "        return ''.join(c for c in text if not unicodedata.combining(c))\n",
    "    return text\n",
    "\n",
    "climate_features_cleaning = climate_features_cleaning.applymap(remove_accents)\n",
    "\n",
    "# Add primary key\n",
    "climate_features_cleaning.insert(0, 'climate_id', range(1, len(climate_features_cleaning) + 1))\n",
    "\n",
    "# Select final columns\n",
    "climate_features_clean = climate_features_cleaning[[\n",
    "    'climate_id',\n",
    "    'profile_id',\n",
    "    'mean_annual_temp',\n",
    "    'mean_annual_precip',\n",
    "    'koppen_climate',\n",
    "    'thornthwaite_climate',\n",
    "    'hydric_regime',\n",
    "    'thermal_regime'\n",
    "]]\n",
    "\n",
    "# Preview\n",
    "climate_features_clean.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check FK relationships and datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types of each column in profile_clean:\n",
      "\n",
      "climate_id                int64\n",
      "profile_id               object\n",
      "mean_annual_temp        float64\n",
      "mean_annual_precip      float64\n",
      "koppen_climate           object\n",
      "thornthwaite_climate     object\n",
      "hydric_regime            object\n",
      "thermal_regime           object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check and print the datatypes of each column\n",
    "print(\"Data types of each column in profile_clean:\\n\")\n",
    "print(climate_features_clean.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topo features table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topo_features_id</th>\n",
       "      <th>profile_id</th>\n",
       "      <th>slope_code</th>\n",
       "      <th>altitude</th>\n",
       "      <th>aspect</th>\n",
       "      <th>land_surface_temp</th>\n",
       "      <th>dem_elevation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1/57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1/59</td>\n",
       "      <td>D5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1/61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1/63</td>\n",
       "      <td>D1</td>\n",
       "      <td>1210.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1/64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topo_features_id profile_id slope_code  altitude aspect land_surface_temp  \\\n",
       "0                 1       1/57        NaN      32.0   <NA>              <NA>   \n",
       "1                 2       1/59         D5       NaN   <NA>              <NA>   \n",
       "2                 3       1/61        NaN       NaN   <NA>              <NA>   \n",
       "3                 4       1/63         D1    1210.0   <NA>              <NA>   \n",
       "4                 5       1/64        NaN       NaN   <NA>              <NA>   \n",
       "\n",
       "  dem_elevation  \n",
       "0          <NA>  \n",
       "1          <NA>  \n",
       "2          <NA>  \n",
       "3          <NA>  \n",
       "4          <NA>  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a copy for cleaning\n",
    "topo_features_cleaning = profile_loc.copy()\n",
    "\n",
    "# Rename columns for clarity\n",
    "topo_features_cleaning.rename(columns={\n",
    "    'PERFIL': 'profile_id',\n",
    "    'TOPOGRAFIA': 'slope_code',\n",
    "    'ALTITUDE': 'altitude',\n",
    "}, inplace=True)\n",
    "\n",
    "# Add missing columns\n",
    "topo_features_cleaning['aspect'] = pd.NA  \n",
    "topo_features_cleaning['land_surface_temp'] = pd.NA\n",
    "topo_features_cleaning['dem_elevation'] = pd.NA  \n",
    "\n",
    "# Add primary key column\n",
    "topo_features_cleaning.insert(0, 'topo_features_id', range(1, len(topo_features_cleaning) + 1))\n",
    "\n",
    "## make sure profile_id column is a string/varchar\n",
    "topo_features_cleaning['profile_id'] = topo_features_cleaning['profile_id'].astype(str).str.strip().str[:20]\n",
    "\n",
    "# Create slope class mapping dictionary\n",
    "slope_code_to_description = {\n",
    "    \"D1\": \"Plano (Declives < 2%)\",\n",
    "    \"D2\": \"Ondulado muito suave (Declives > 2% e < 3%)\",\n",
    "    \"D3\": \"Ondulado suave (Declives > 3% e < 5%)\",\n",
    "    \"D4\": \"Ondulado (Declives > 5% e < 8%)\",\n",
    "    \"D5\": \"Acidentado (Declives > 8% e < 15%)\",\n",
    "    \"D6\": \"Escarpado (Declives >15% e < 30%)\",\n",
    "    \"D7\": \"Montanhoso (Declives > 30%)\"\n",
    "}\n",
    "\n",
    "# Create a mapping DataFrame for slope classes\n",
    "slope_classes_df = pd.DataFrame([\n",
    "    {\"slope_code\": code, \"slope_description\": desc}\n",
    "    for code, desc in slope_code_to_description.items()\n",
    "])\n",
    "\n",
    "#drop accents\n",
    "import unicodedata\n",
    "def remove_accents(text):\n",
    "    if isinstance(text, str):\n",
    "        # Normalize and remove diacritics\n",
    "        text = unicodedata.normalize('NFKD', text)\n",
    "        text = ''.join(c for c in text if not unicodedata.combining(c))\n",
    "        return text\n",
    "    return text\n",
    "\n",
    "# Apply to all cells in the DataFrame\n",
    "topo_features_cleaning = topo_features_cleaning.applymap(remove_accents)\n",
    "\n",
    "# Final cleaned topo features table (referencing slope_code, not description)\n",
    "topo_features_clean = topo_features_cleaning[[\n",
    "    'topo_features_id',\n",
    "    'profile_id', \n",
    "    'slope_code',\n",
    "    'altitude',\n",
    "    'aspect',\n",
    "    'land_surface_temp',\n",
    "    'dem_elevation'\n",
    "]]\n",
    "\n",
    "# Preview\n",
    "topo_features_clean.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geological features table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_features_id</th>\n",
       "      <th>profile_id</th>\n",
       "      <th>geology_id</th>\n",
       "      <th>lithology_id</th>\n",
       "      <th>lithology_1954_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1/57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1/59</td>\n",
       "      <td>Oendolongo</td>\n",
       "      <td>pp</td>\n",
       "      <td>Sistema do Maiombe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1/61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1/63</td>\n",
       "      <td>Karroo</td>\n",
       "      <td>Cs/Cal</td>\n",
       "      <td>Serie de Cassanje - T2'T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1/64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   geo_features_id profile_id  geology_id lithology_id  \\\n",
       "0                1       1/57         NaN            d   \n",
       "1                2       1/59  Oendolongo           pp   \n",
       "2                3       1/61         NaN          NaN   \n",
       "3                4       1/63      Karroo       Cs/Cal   \n",
       "4                5       1/64         NaN          NaN   \n",
       "\n",
       "           lithology_1954_id  \n",
       "0                        NaN  \n",
       "1         Sistema do Maiombe  \n",
       "2                        NaN  \n",
       "3  Serie de Cassanje - T2'T1  \n",
       "4                        NaN  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load cleaned geo features data\n",
    "geo_features_cleaning = pd.read_excel(\"/Users/inesschwartz/Desktop/Thesis/tables_soil_database/Perfis_local.xlsx\")\n",
    "\n",
    "# Rename columns\n",
    "geo_features_cleaning.rename(columns={\n",
    "    'PERFIL': 'profile_id',\n",
    "    'GEOLOGIA': 'geology_id',\n",
    "    'LITOLOGIA': 'lithology_id',\n",
    "    'LITOLOGIA_1954': 'lithology_1954_id',\n",
    "}, inplace=True)\n",
    "\n",
    "# Add primary key column\n",
    "geo_features_cleaning.insert(0, 'geo_features_id', range(1, len(geo_features_cleaning) + 1))\n",
    "\n",
    "# make sure profile_id column is a string/varchar\n",
    "geo_features_cleaning['profile_id'] = geo_features_cleaning['profile_id'].astype(str).str.strip().str[:20]\n",
    "\n",
    "\n",
    "# Final normalized geo_features table (with codes as foreign keys)\n",
    "geo_features_clean = geo_features_cleaning[[\n",
    "    'geo_features_id',\n",
    "    'profile_id',\n",
    "    'geology_id',\n",
    "    'lithology_id',\n",
    "    'lithology_1954_id'\n",
    "]]\n",
    "\n",
    "#drop accents\n",
    "import unicodedata\n",
    "def remove_accents(text):\n",
    "    if isinstance(text, str):\n",
    "        # Normalize and remove diacritics\n",
    "        text = unicodedata.normalize('NFKD', text)\n",
    "        text = ''.join(c for c in text if not unicodedata.combining(c))\n",
    "        return text\n",
    "    return text\n",
    "\n",
    "# Apply to all cells in the DataFrame\n",
    "geo_features_clean = geo_features_clean.applymap(remove_accents)\n",
    "\n",
    "#preview\n",
    "geo_features_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## mapping tables\n",
    "# Mappings for geology\n",
    "geology_mapping = {\n",
    "    \"Kalahari\": \"Sistema do Kalahari\",\n",
    "    \"Superficiais\": \"Formações Superficiais\",\n",
    "    \"Karroo\": \"Sistema do Karroo\",\n",
    "    \"Bembe\": \"Sistema do Bembe\",\n",
    "    \"Oendolongo\": \"Sistema do Oendolongo\",\n",
    "    \"Base\": \"Complexo de base\",\n",
    "    \"Proterozóico\": \"Proterozóico\",\n",
    "    \"Pleistocénico\": \"Pleistocénico\",\n",
    "    \"Terciário\": \"Terciário (médio e inferior)\",\n",
    "    \"TQ\": \"Quaternário e Terciário superior\",\n",
    "    \"Cretácio\": \"\",  # no description provided\n",
    "    \"RPKS\": \"Recente Plistocénico e Kalahari Superior\"\n",
    "}\n",
    "\n",
    "# Mappings for lithology_1954\n",
    "lithology_1954_mapping = {\n",
    "    \"γ\": \"Granitos, Granodioritos e Quartzodioritos\",\n",
    "    \"PL\": \"Xistos, metaquartzitos, conglomerados, arcoses, ect.\",\n",
    "    \"λ\": \"Rochas eruptivas indeterminadas\",\n",
    "    \"δp\": \"Doleritos, doleritos pigeoníticos\",\n",
    "    \"δab\": \"Diabases, diabases albito-cloriticas\",\n",
    "    \"ε\": \"Noritos, gabros e peridotitos\",\n",
    "    \"JK\": \"Composto de conglomerados, areias, cascalhos do Kalahari\",\n",
    "    \"C\": \"Série Xisto - calcária\",\n",
    "    \"Cal\": \"Sedimentos arenosos não consolidados\",\n",
    "    \"K\": \"Série xisto - gresosa\",\n",
    "    \"RT\": \"Não diferenciado\",\n",
    "    \"σ\": \"Sienitos, sienitos nefelínicos\",\n",
    "    \"Q\": \"Depósitos fossilíferos\",\n",
    "    \"CS\": \"Grande conglomerado e série de Mwashya\"\n",
    "}\n",
    "\n",
    "# Mappings for lithology\n",
    "lithology_mapping = {\n",
    "    \"a\": \"Rochas arenáceas consolidadas\",\n",
    "    \"aq\": \"Grés quartzíticos do Oendolongo\",\n",
    "    \"b\": \"Rochas eruptivas básicas\",\n",
    "    \"c\": \"Rochas sedimentares consolidadas calcárias\",\n",
    "    \"c'\": \"Rochas sedimentares não consolidadas calcárias\",\n",
    "    \"cg\": \"Rochas cristalofílicas argiláceas\",\n",
    "    \"d\": \"Sedimentos não consolidados de origem marinha\",\n",
    "    \"dc\": \"Depósitos coluvionares\",\n",
    "    \"dr\": \"Diorítos\",\n",
    "    \"e\": \"Rochas sedimentares consolidadas não calcárias\",\n",
    "    \"g\": \"Rochas argiláceas consolidadas não calcárias\",\n",
    "    \"g'\": \"Rochas argiláceas não consolidadas não calcárias\",\n",
    "    \"g''\": \"Rochas cristalinas pouco micas em quartzo\",\n",
    "    \"gp\": \"Rochas do  complexo gabro-plagioclastíco\",\n",
    "    \"k\": \"Sedimentos não consolidados grosseiros do Kalahari\",\n",
    "    \"m\": \"Rochas sedimentares não consolidadas calco-gipsíferas\",\n",
    "    \"m'\": \"Depósitos coluvionares margosos\",\n",
    "    \"mm\": \"Materiais mistos\",\n",
    "    \"n\": \"Sedimentos não consolidados de origem continental\",\n",
    "    \"nd\": \"não descrito\",\n",
    "    \"pp\": \"Sedimentos não consolidados grosseiros plio-plistocénicos\",\n",
    "    \"q\": \"Rochas cristalinas quartzíferas\",\n",
    "    \"q'\": \"Materiais redistribuídos provenientes de desagregação rochas crist. quartzíferas\",\n",
    "    \"qf\": \"Quartzitos ferruginosos do Oendolongo\",\n",
    "    \"r\": \"Sedimentos grosseiros não especificados\",\n",
    "    \"s\": \"Sienitos\",\n",
    "    \"sx\": \"Formações (ou rochas) sedimentares não especificadas\",\n",
    "    \"sx1\": \"Rochas sedimentares consolidadas com e sem calcário\",\n",
    "    \"sx2\": \"Rochas sedimentares consolidadas\",\n",
    "    \"v\": \"Materiais vulcânicos\",\n",
    "    \"v'\": \"Rochas do complexo alcalino e/ou carboatítico\",\n",
    "    \"x\": \"Rochas consolidadas não especificadas\",\n",
    "    \"xm\": \"Xistos metamórficos\",\n",
    "    \"xq\": \"Rochas cristalinas não especificadas\",\n",
    "    \"z\": \"Rochas metassedimentares\"\n",
    "}\n",
    "\n",
    "# Save each mapping as a DataFrame\n",
    "pd.DataFrame([\n",
    "    {\"geology_code\": k, \"geology_description\": v}\n",
    "    for k, v in geology_mapping.items()\n",
    "]).to_csv(\"/Users/inesschwartz/Desktop/Thesis/tables_clean/geology_mapping.csv\", index=False)\n",
    "\n",
    "pd.DataFrame([\n",
    "    {\"lithology_code\": k, \"lithology_description\": v}\n",
    "    for k, v in lithology_mapping.items()\n",
    "]).to_csv(\"/Users/inesschwartz/Desktop/Thesis/tables_clean/lithology_mapping.csv\", index=False)\n",
    "\n",
    "pd.DataFrame([\n",
    "    {\"lithology_1954_code\": k, \"lithology_1954_description\": v}\n",
    "    for k, v in lithology_1954_mapping.items()\n",
    "]).to_csv(\"/Users/inesschwartz/Desktop/Thesis/tables_clean/lithology1954_mapping.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# District table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>district_id</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>profile_id</th>\n",
       "      <th>district</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>630</td>\n",
       "      <td>139</td>\n",
       "      <td>Huambo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>631</td>\n",
       "      <td>139</td>\n",
       "      <td>Huambo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>632</td>\n",
       "      <td>139</td>\n",
       "      <td>Huambo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>633</td>\n",
       "      <td>139</td>\n",
       "      <td>Huambo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>687</td>\n",
       "      <td>208</td>\n",
       "      <td>Huambo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   district_id sample_id profile_id district\n",
       "0            1       630        139   Huambo\n",
       "1            2       631        139   Huambo\n",
       "2            3       632        139   Huambo\n",
       "3            4       633        139   Huambo\n",
       "4            5       687        208   Huambo"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import unicodedata\n",
    "\n",
    "# Sample dataframe to illustrate\n",
    "# samples = pd.read_csv(...)  # Uncomment and load your data if needed\n",
    "\n",
    "# Final normalized districts table (with codes as foreign keys)\n",
    "district_cleaning = samples.copy()\n",
    "\n",
    "# Add primary key column\n",
    "district_cleaning.insert(0, 'district_id', range(1, len(district_cleaning) + 1))\n",
    "\n",
    "# Select relevant columns\n",
    "district_clean = district_cleaning[[\n",
    "    'district_id',\n",
    "    'sample_id',\n",
    "    'profile_id',\n",
    "    'district'\n",
    "]].copy()\n",
    "\n",
    "# Strip whitespace from sample_id\n",
    "district_clean.loc[:, 'sample_id'] = district_clean['sample_id'].astype(str).str.strip()\n",
    "\n",
    "# make sure profile_id column is a string/varchar\n",
    "district_clean['profile_id'] = district_clean['profile_id'].astype(str).str.strip().str[:20]\n",
    "\n",
    "# Function to remove accents\n",
    "def remove_accents(text):\n",
    "    if isinstance(text, str):\n",
    "        text = unicodedata.normalize('NFKD', text)\n",
    "        return ''.join(c for c in text if not unicodedata.combining(c))\n",
    "    return text\n",
    "\n",
    "# Apply to all object (string) columns only\n",
    "for col in district_clean.select_dtypes(include='object').columns:\n",
    "    district_clean[col] = district_clean[col].apply(remove_accents)\n",
    "\n",
    "# Preview\n",
    "district_clean.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minerology info table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biology Info table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking CSV Datatypes before DB export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📄 File: district_clean.csv\n",
      "district_id     int64\n",
      "sample_id       int64\n",
      "profile_id     object\n",
      "district       object\n",
      "dtype: object\n",
      "\n",
      "📄 File: soil_type_clean.csv\n",
      "soil_type_id     int64\n",
      "profile_id      object\n",
      "grouping        object\n",
      "CEP_GR          object\n",
      "CEP_NAME        object\n",
      "FAO             object\n",
      "dtype: object\n",
      "\n",
      "📄 File: analyses_clean.csv\n",
      "lab_sample_id      int64\n",
      "sample_id        float64\n",
      "EG               float64\n",
      "thick_clay       float64\n",
      "fine_clay        float64\n",
      "                  ...   \n",
      "Tl               float64\n",
      "Pb               float64\n",
      "Bi               float64\n",
      "Th               float64\n",
      "U                float64\n",
      "Length: 68, dtype: object\n",
      "\n",
      "📄 File: climate_features_clean.csv\n",
      "climate_id                int64\n",
      "profile_id               object\n",
      "mean_annual_temp        float64\n",
      "mean_annual_precip      float64\n",
      "koppen_climate           object\n",
      "thornthwaite_climate     object\n",
      "hydric_regime            object\n",
      "thermal_regime           object\n",
      "dtype: object\n",
      "\n",
      "📄 File: analyses_clean_check2.csv\n",
      "lab_sample_id      int64\n",
      "sample_id        float64\n",
      "EG               float64\n",
      "thick_clay       float64\n",
      "fine_clay        float64\n",
      "                  ...   \n",
      "Tl               float64\n",
      "Pb               float64\n",
      "Bi               float64\n",
      "Th               float64\n",
      "U                float64\n",
      "Length: 71, dtype: object\n",
      "\n",
      "📄 File: slope_classes_mapping.csv\n",
      "slope_code           object\n",
      "slope_description    object\n",
      "dtype: object\n",
      "\n",
      "📄 File: analyses_clean_check1.csv\n",
      "sample_id        int64\n",
      "sample_id.1    float64\n",
      "EG             float64\n",
      "thick_clay     float64\n",
      "fine_clay      float64\n",
      "                ...   \n",
      "Tl             float64\n",
      "Pb             float64\n",
      "Bi             float64\n",
      "Th             float64\n",
      "U              float64\n",
      "Length: 61, dtype: object\n",
      "\n",
      "📄 File: geology_mapping.csv\n",
      "geology_code           object\n",
      "geology_description    object\n",
      "dtype: object\n",
      "\n",
      "📄 File: lithology1954_mapping.csv\n",
      "lithology_1954_code           object\n",
      "lithology_1954_description    object\n",
      "dtype: object\n",
      "\n",
      "📄 File: geo_features_clean.csv\n",
      "geo_features_id       int64\n",
      "profile_id           object\n",
      "geology_id           object\n",
      "lithology_id         object\n",
      "lithology_1954_id    object\n",
      "dtype: object\n",
      "\n",
      "📄 File: profile_clean.csv\n",
      "profile_record_id      int64\n",
      "profile_id            object\n",
      "site_info_id         float64\n",
      "sample_id            float64\n",
      "soil_type_id           int64\n",
      "dtype: object\n",
      "\n",
      "📄 File: morphology_horizon_clean.csv\n",
      "horizon_id           object\n",
      "sample_id           float64\n",
      "profile_id           object\n",
      "horizon_layer       float64\n",
      "upper_depth         float64\n",
      "lower_depth         float64\n",
      "moisture_degree      object\n",
      "root_quantity        object\n",
      "root_diameter        object\n",
      "texture              object\n",
      "structure_type       object\n",
      "structure_class      object\n",
      "structure_degree     object\n",
      "pore_diameter        object\n",
      "pore_quantity        object\n",
      "pore_shape           object\n",
      "dry_color_name       object\n",
      "dry_hue              object\n",
      "dry_value           float64\n",
      "dry_chroma          float64\n",
      "moist_color_name     object\n",
      "moist_hue            object\n",
      "moist_value         float64\n",
      "moist_chroma        float64\n",
      "compaction           object\n",
      "durability           object\n",
      "dtype: object\n",
      "\n",
      "📄 File: topo_features_clean.csv\n",
      "topo_features_id       int64\n",
      "profile_id            object\n",
      "slope_code            object\n",
      "altitude             float64\n",
      "aspect               float64\n",
      "land_surface_temp    float64\n",
      "dem_elevation        float64\n",
      "dtype: object\n",
      "\n",
      "📄 File: lithology_mapping.csv\n",
      "lithology_code           object\n",
      "lithology_description    object\n",
      "dtype: object\n",
      "\n",
      "📄 File: site_info_clean.csv\n",
      "site_info_id          int64\n",
      "profile_id           object\n",
      "X_coord             float64\n",
      "Y_coord             float64\n",
      "sampling_date       float64\n",
      "districts_id        float64\n",
      "climate_id            int64\n",
      "topo_features_id      int64\n",
      "district_id         float64\n",
      "geo_features_id       int64\n",
      "dtype: object\n",
      "\n",
      "📄 File: samples_clean.csv\n",
      "sample_id         int64\n",
      "site_info_id     object\n",
      "profile_id       object\n",
      "shelf            object\n",
      "Room             object\n",
      "year            float64\n",
      "horizon_id       object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Set the path to your folder containing the 10 CSV files\n",
    "csv_folder = \"/Users/inesschwartz/Desktop/Thesis/tables_clean\"  \n",
    "\n",
    "# List all CSV files in the folder\n",
    "csv_files = [f for f in os.listdir(csv_folder) if f.endswith(\".csv\")]\n",
    "\n",
    "# Loop through each file and display column data types\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(csv_folder, file)\n",
    "    print(f\"\\n📄 File: {file}\")\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(df.dtypes)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error reading {file}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foreign key imports and datatype consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## standardize datatypes for identifiers\n",
    "def convert_identifiers_to_string(df, id_columns):\n",
    "    \"\"\"\n",
    "    Converts specified identifier columns in a DataFrame to string type,\n",
    "    safely handling float64 values and preserving missing values (NA).\n",
    "    Avoids SettingWithCopyWarning.\n",
    "    \"\"\"\n",
    "    df = df.copy()  # ensure we're working with a copy, not a slice\n",
    "    for col in id_columns:\n",
    "        if col in df.columns:\n",
    "            df.loc[:, col] = df[col].apply(\n",
    "                lambda x: str(int(x)) if pd.notna(x) and isinstance(x, float) and x.is_integer()\n",
    "                else str(x) if pd.notna(x)\n",
    "                else pd.NA\n",
    "            ).astype(\"string\")\n",
    "    return df\n",
    "\n",
    "#usage\n",
    "\n",
    "# Define identifier columns\n",
    "identifier_columns = [\n",
    "    'sample_id', 'site_info_id', 'profile_id',\n",
    "    'horizon_id', 'lab_sample_id'\n",
    "]\n",
    "\n",
    "# Apply to each relevant dataframe\n",
    "samples_check = convert_identifiers_to_string(samples_check, identifier_columns)\n",
    "morphology_clean = convert_identifiers_to_string(morphology_clean, identifier_columns)\n",
    "profile_clean = convert_identifiers_to_string(profile_clean, identifier_columns)\n",
    "merged1 = convert_identifiers_to_string(merged1, identifier_columns)\n",
    "site_info_clean = convert_identifiers_to_string(site_info_clean, identifier_columns)\n",
    "district_clean = convert_identifiers_to_string(district_clean, identifier_columns)\n",
    "soil_type_clean = convert_identifiers_to_string(soil_type_clean, identifier_columns)\n",
    "geo_features_clean = convert_identifiers_to_string(geo_features_clean, identifier_columns)\n",
    "topo_features_clean = convert_identifiers_to_string(topo_features_clean, identifier_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "samples_check column types:\n",
      "  sample_id: object\n",
      "  site_info_id: object\n",
      "  profile_id: object\n",
      "  horizon_id: object\n",
      "\n",
      "morphology_clean column types:\n",
      "  sample_id: object\n",
      "  profile_id: object\n",
      "  horizon_id: object\n",
      "\n",
      "profile_clean column types:\n",
      "  sample_id: object\n",
      "  site_info_id: object\n",
      "  profile_id: object\n",
      "\n",
      "merged1 column types:\n",
      "  sample_id: object\n",
      "  lab_sample_id: object\n",
      "\n",
      "site_info_clean column types:\n",
      "  site_info_id: string\n",
      "  profile_id: object\n",
      "\n",
      "district_clean column types:\n",
      "  sample_id: object\n",
      "  profile_id: object\n",
      "\n",
      "soil_type_clean column types:\n",
      "  profile_id: object\n",
      "\n",
      "geo_features_clean column types:\n",
      "  profile_id: object\n",
      "\n",
      "topo_features_clean column types:\n",
      "  profile_id: object\n"
     ]
    }
   ],
   "source": [
    "# Check types of identifier columns in each dataframe\n",
    "dfs = {\n",
    "    \"samples_check\": samples_check,\n",
    "    \"morphology_clean\": morphology_clean,\n",
    "    \"profile_clean\": profile_clean,\n",
    "    \"merged1\": merged1,\n",
    "    \"site_info_clean\": site_info_clean,\n",
    "    \"district_clean\": district_clean,\n",
    "    \"soil_type_clean\": soil_type_clean,\n",
    "    \"geo_features_clean\": geo_features_clean,\n",
    "    \"topo_features_clean\": topo_features_clean,\n",
    "}\n",
    "\n",
    "for name, df in dfs.items():\n",
    "    print(f\"\\n{name} column types:\")\n",
    "    for col in identifier_columns:\n",
    "        if col in df.columns:\n",
    "            print(f\"  {col}: {df[col].dtype}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9636 sample_id(s) in samples_clean are missing in morphology_horizon_clean.\n",
      "      sample_id\n",
      "3           633\n",
      "10          700\n",
      "11          707\n",
      "13          710\n",
      "16          719\n",
      "...         ...\n",
      "14710     18867\n",
      "14711     18868\n",
      "14712     18869\n",
      "14713     18870\n",
      "14714     18871\n",
      "\n",
      "[9636 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "## validate FK references in tables\n",
    "\n",
    "# Check for missing FK references in morphology\n",
    "missing_samples = samples_check[~samples_check['sample_id'].isin(morphology_clean['sample_id'])]\n",
    "\n",
    "print(f\"{len(missing_samples)} sample_id(s) in samples_clean are missing in morphology_horizon_clean.\")\n",
    "print(missing_samples[['sample_id']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9636 samples could not be matched with a horizon_id.\n"
     ]
    }
   ],
   "source": [
    "# Samples table horizon_id FK \n",
    "\n",
    "# Drop old horizon_id if it exists (to avoid confusion)\n",
    "samples_check = samples_check.drop(columns=['horizon_id'], errors='ignore')\n",
    "\n",
    "# Merge horizon_id from morph into samples\n",
    "samples_check = samples_check.merge(\n",
    "    morphology_clean[['sample_id', 'horizon_id']],\n",
    "    on='sample_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "missing = samples_check[samples_check['horizon_id'].isna()]\n",
    "print(f\"{len(missing)} samples could not be matched with a horizon_id.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>site_info_id</th>\n",
       "      <th>profile_id</th>\n",
       "      <th>horizon_id</th>\n",
       "      <th>year</th>\n",
       "      <th>shelf</th>\n",
       "      <th>Room</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>630</td>\n",
       "      <td>172</td>\n",
       "      <td>139</td>\n",
       "      <td>Hb_139/46_1_1</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>631</td>\n",
       "      <td>173</td>\n",
       "      <td>139</td>\n",
       "      <td>Hb_139/46_2_1</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>632</td>\n",
       "      <td>174</td>\n",
       "      <td>139</td>\n",
       "      <td>Hb_139/46_3_1</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>633</td>\n",
       "      <td>175</td>\n",
       "      <td>139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>687</td>\n",
       "      <td>1034</td>\n",
       "      <td>208</td>\n",
       "      <td>Hb_208/46_1_1</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sample_id site_info_id profile_id     horizon_id    year shelf Room\n",
       "0       630          172        139  Hb_139/46_1_1  1946.0     1   22\n",
       "1       631          173        139  Hb_139/46_2_1  1946.0     1   22\n",
       "2       632          174        139  Hb_139/46_3_1  1946.0     1   22\n",
       "3       633          175        139            NaN  1946.0     1   22\n",
       "4       687         1034        208  Hb_208/46_1_1  1946.0     1   22"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Re-order and select relevant columns\n",
    "samples_clean = samples_check[[\n",
    "    'sample_id',\n",
    "    'site_info_id',  \n",
    "    'profile_id',\n",
    "    'horizon_id',\n",
    "    'year',\n",
    "    'shelf',\n",
    "    'Room'  # Ensure this matches the column name in your DataFrame\n",
    "]].copy()\n",
    "\n",
    "# Preview the result\n",
    "samples_clean.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155 profiles missing site_info_id\n",
      "1288 profiles missing sample_id\n",
      "0 profiles missing soil_type_id\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>profile_record_id</th>\n",
       "      <th>profile_id</th>\n",
       "      <th>site_info_id</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>soil_type_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1/51</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1/57</td>\n",
       "      <td>1</td>\n",
       "      <td>4835</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1/57</td>\n",
       "      <td>1</td>\n",
       "      <td>4836</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1/57</td>\n",
       "      <td>1</td>\n",
       "      <td>4837</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1/57</td>\n",
       "      <td>1</td>\n",
       "      <td>4838</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   profile_record_id profile_id site_info_id sample_id  soil_type_id\n",
       "0                  1       1/51         <NA>       NaN             1\n",
       "1                  2       1/57            1      4835             2\n",
       "2                  3       1/57            1      4836             2\n",
       "3                  4       1/57            1      4837             2\n",
       "4                  5       1/57            1      4838             2"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop old FK columns if they exist\n",
    "profile_clean = profile_clean.drop(columns=['site_info_id', 'sample_id', 'soil_type_id'], errors='ignore')\n",
    "\n",
    "# Merge site_info_id from site_info_clean\n",
    "profile_clean = profile_clean.merge(\n",
    "    site_info_clean[['profile_id', 'site_info_id']],\n",
    "    on='profile_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Merge sample_id from samples_check\n",
    "profile_clean = profile_clean.merge(\n",
    "    samples_check[['profile_id', 'sample_id']],\n",
    "    on='profile_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Merge soil_type_id from soil_type_clean\n",
    "profile_clean = profile_clean.merge(\n",
    "    soil_type_clean[['profile_id', 'soil_type_id']],\n",
    "    on='profile_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Make unique record ID for profile info\n",
    "profile_clean.insert(0, 'profile_record_id', range(1, len(profile_clean) + 1))\n",
    "\n",
    "# Reorder columns to match SAMPLES schema\n",
    "column_order = [\n",
    "    'profile_record_id',\n",
    "    'profile_id',\n",
    "    'site_info_id',\n",
    "    'sample_id',\n",
    "    'soil_type_id'\n",
    "]\n",
    "profile_clean = profile_clean.loc[:, column_order]\n",
    "\n",
    "# Check for unmatched profile_ids in each join (optional)\n",
    "missing_site = profile_clean[profile_clean['site_info_id'].isna()]\n",
    "missing_sample = profile_clean[profile_clean['sample_id'].isna()]\n",
    "missing_soil = profile_clean[profile_clean['soil_type_id'].isna()]\n",
    "\n",
    "print(f\"{len(missing_site)} profiles missing site_info_id\")\n",
    "print(f\"{len(missing_sample)} profiles missing sample_id\")\n",
    "print(f\"{len(missing_soil)} profiles missing soil_type_id\")\n",
    "\n",
    "profile_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 records missing climate_id\n",
      "0 records missing topo_features_id\n",
      "2178 records missing district_id\n",
      "0 records missing geo_features_id\n"
     ]
    }
   ],
   "source": [
    "# Drop old FKs if they exist (only needs to be done once)\n",
    "site_info_clean = site_info_clean.drop(\n",
    "    columns=['land_cover_id', 'climate_id', 'geology_id', 'topo_feature_id', 'district_id', 'geo_features_id', 'topo_features_id'],\n",
    "    errors='ignore'\n",
    ")\n",
    "\n",
    "# Merge climate_id from climate_features_clean\n",
    "site_info_clean = site_info_clean.merge(\n",
    "    climate_features_clean[['profile_id', 'climate_id']],\n",
    "    on='profile_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Merge topo_features_id from topo_features_clean\n",
    "site_info_clean = site_info_clean.merge(\n",
    "    topo_features_clean[['profile_id', 'topo_features_id']],\n",
    "    on='profile_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Merge district_id from district_clean\n",
    "site_info_clean = site_info_clean.merge(\n",
    "    district_clean[['profile_id', 'district_id']],\n",
    "    on='profile_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Merge geo_features_id from geo_features_clean\n",
    "site_info_clean = site_info_clean.merge(\n",
    "    geo_features_clean[['profile_id', 'geo_features_id']],\n",
    "    on='profile_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "\n",
    "# Optional: Check for missing FKs\n",
    "missing_climate = site_info_clean[site_info_clean['climate_id'].isna()]\n",
    "missing_topo = site_info_clean[site_info_clean['topo_features_id'].isna()]\n",
    "missing_district = site_info_clean[site_info_clean['district_id'].isna()]\n",
    "missing_geology = site_info_clean[site_info_clean['geo_features_id'].isna()]\n",
    "\n",
    "print(f\"{len(missing_climate)} records missing climate_id\")\n",
    "print(f\"{len(missing_topo)} records missing topo_features_id\")\n",
    "print(f\"{len(missing_district)} records missing district_id\")\n",
    "print(f\"{len(missing_geology)} records missing geo_features_id\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVING CLEANED TABLES TO CSV FOR DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_check.to_csv(\"/Users/inesschwartz/Desktop/Thesis/tables_clean/samples_clean.csv\", index=False)\n",
    "merged1.to_csv(\"/Users/inesschwartz/Desktop/Thesis/tables_clean/analyses_clean.csv\", index=False)\n",
    "profile_clean.to_csv(\"/Users/inesschwartz/Desktop/Thesis/tables_clean/profile_clean.csv\", index=False)\n",
    "morphology_clean.to_csv(\"/Users/inesschwartz/Desktop/Thesis/tables_clean/morphology_horizon_clean.csv\", index=False)\n",
    "soil_type_clean.to_csv(\"/Users/inesschwartz/Desktop/Thesis/tables_clean/soil_type_clean.csv\", index=False)\n",
    "site_info_clean.to_csv(\"/Users/inesschwartz/Desktop/Thesis/tables_clean/site_info_clean.csv\", index=False)\n",
    "climate_features_clean.to_csv(\"/Users/inesschwartz/Desktop/Thesis/tables_clean/climate_features_clean.csv\", index=False)\n",
    "topo_features_clean.to_csv(\"/Users/inesschwartz/Desktop/Thesis/tables_clean/topo_features_clean.csv\", index=False)\n",
    "geo_features_clean.to_csv(\"/Users/inesschwartz/Desktop/Thesis/tables_clean/geo_features_clean.csv\", index=False)\n",
    "district_clean.to_csv(\"/Users/inesschwartz/Desktop/Thesis/tables_clean/district_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save random 100 rows of each table as mini versions for DB test\n",
    "import os\n",
    "\n",
    "# Create folder if it doesn't exist\n",
    "mini_path = \"/Users/inesschwartz/Desktop/Thesis/tables_clean_mini\"\n",
    "os.makedirs(mini_path, exist_ok=True)\n",
    "\n",
    "# Save random 100 rows of each table as mini versions\n",
    "samples_check.sample(n=100, random_state=42).to_csv(f\"{mini_path}/samples.csv\", index=False)\n",
    "merged1.sample(n=100, random_state=42).to_csv(f\"{mini_path}/analyses.csv\", index=False)\n",
    "profile_clean.sample(n=100, random_state=42).to_csv(f\"{mini_path}/profile.csv\", index=False)\n",
    "morphology_clean.sample(n=100, random_state=42).to_csv(f\"{mini_path}/morphology_horizon.csv\", index=False)\n",
    "soil_type_clean.sample(n=100, random_state=42).to_csv(f\"{mini_path}/soil_type.csv\", index=False)\n",
    "site_info_clean.sample(n=100, random_state=42).to_csv(f\"{mini_path}/site_info.csv\", index=False)\n",
    "climate_features_clean.sample(n=100, random_state=42).to_csv(f\"{mini_path}/climate_feat.csv\", index=False)\n",
    "topo_features_clean.sample(n=100, random_state=42).to_csv(f\"{mini_path}/topo_feat.csv\", index=False)\n",
    "geo_features_clean.sample(n=100, random_state=42).to_csv(f\"{mini_path}/geo_feat.csv\", index=False)\n",
    "district_clean.sample(n=100, random_state=42).to_csv(f\"{mini_path}/districts.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tp/79mdnyy56_xc3g1jvp9wf4_80000gn/T/ipykernel_1816/2163122740.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.replace(\"\", pd.NA, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "tables = {\n",
    "    \"samples\": samples_check,\n",
    "    \"analyses\": merged1,\n",
    "    \"profile\": profile_clean,\n",
    "    \"morphology_horizon\": morphology_clean,\n",
    "    \"soil_type\": soil_type_clean,\n",
    "    \"site_info\": site_info_clean,\n",
    "    \"climate_feat\": climate_features_clean,\n",
    "    \"topo_feat\": topo_features_clean,\n",
    "    \"geo_feat\": geo_features_clean,\n",
    "    \"districts\": district_clean\n",
    "}\n",
    "\n",
    "for name, df in tables.items():\n",
    "    df.replace(\"\", pd.NA, inplace=True)\n",
    "    df.to_csv(f\"/Users/inesschwartz/Desktop/Thesis/tables_clean_mini/{name}.csv\", index=False, na_rep=\"NULL\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Duplicate `profile_record_id` values and their rows:\n",
      "Empty DataFrame\n",
      "Columns: [profile_record_id, profile_id, site_info_id, sample_id, soil_type_id]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Count duplicates\n",
    "duplicates = profile_clean[profile_clean.duplicated('profile_record_id', keep=False)]\n",
    "\n",
    "# Step 2: Sort for clarity (optional)\n",
    "duplicates_sorted = duplicates.sort_values('profile_record_id')\n",
    "\n",
    "# Step 3: Print or inspect\n",
    "print(\"🔁 Duplicate `profile_record_id` values and their rows:\")\n",
    "print(duplicates_sorted)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
