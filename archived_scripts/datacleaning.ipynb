{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dateutil.parser import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and read data\n",
    "samples = pd.read_excel(\"/Users/inesschwartz/Desktop/Thesis/tables_soil_database/AmostrasAngolaTerrario.xlsx\")\n",
    "analyses = pd.read_excel(\"/Users/inesschwartz/Desktop/Thesis/tables_soil_database/Horizontes Analises.xlsx\")\n",
    "morphology = pd.read_excel(\"/Users/inesschwartz/Desktop/Thesis/tables_soil_database/Horizontes_Morfologia.xlsx\")\n",
    "profile_loc = pd.read_excel(\"/Users/inesschwartz/Desktop/Thesis/tables_soil_database/Perfis_local.xlsx\")\n",
    "soil_profile = pd.read_excel(\"/Users/inesschwartz/Desktop/Thesis/tables_soil_database/Perfis_solo.xlsx\")\n",
    "elemental_analyses = pd.read_excel(\"/Users/inesschwartz/Desktop/Thesis/tables_soil_database/Data XRF Angola_inicial.xlsx\")\n",
    "#soil_type = pd.read_excel(\"/Users/inesschwartz/Desktop/Thesis/tables_soil_database/Perfis_solo.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# samples table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['172' '173' '175' ... '1072' '1077' '1078']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>site_info_id</th>\n",
       "      <th>year</th>\n",
       "      <th>profile_id</th>\n",
       "      <th>campaign</th>\n",
       "      <th>country</th>\n",
       "      <th>district</th>\n",
       "      <th>sample_sifted</th>\n",
       "      <th>Província</th>\n",
       "      <th>sample_not_sifted</th>\n",
       "      <th>shelf</th>\n",
       "      <th>room</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>630</td>\n",
       "      <td>172</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>139</td>\n",
       "      <td>MA/46</td>\n",
       "      <td>Angola</td>\n",
       "      <td>Huambo</td>\n",
       "      <td>X</td>\n",
       "      <td>Huambo</td>\n",
       "      <td>null</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>631</td>\n",
       "      <td>173</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>139</td>\n",
       "      <td>MA/46</td>\n",
       "      <td>Angola</td>\n",
       "      <td>Huambo</td>\n",
       "      <td>X</td>\n",
       "      <td>Huambo</td>\n",
       "      <td>null</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>632</td>\n",
       "      <td>174</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>139</td>\n",
       "      <td>MA/46</td>\n",
       "      <td>Angola</td>\n",
       "      <td>Huambo</td>\n",
       "      <td>X</td>\n",
       "      <td>Huambo</td>\n",
       "      <td>null</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>633</td>\n",
       "      <td>175</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>139</td>\n",
       "      <td>MA/46</td>\n",
       "      <td>Angola</td>\n",
       "      <td>Huambo</td>\n",
       "      <td>X</td>\n",
       "      <td>Huambo</td>\n",
       "      <td>null</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>687</td>\n",
       "      <td>1034</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>208</td>\n",
       "      <td>MA/46</td>\n",
       "      <td>Angola</td>\n",
       "      <td>Huambo</td>\n",
       "      <td>X</td>\n",
       "      <td>Huambo</td>\n",
       "      <td>null</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_id site_info_id    year profile_id campaign country district  \\\n",
       "0        630          172  1946.0        139    MA/46  Angola   Huambo   \n",
       "1        631          173  1946.0        139    MA/46  Angola   Huambo   \n",
       "2        632          174  1946.0        139    MA/46  Angola   Huambo   \n",
       "3        633          175  1946.0        139    MA/46  Angola   Huambo   \n",
       "4        687         1034  1946.0        208    MA/46  Angola   Huambo   \n",
       "\n",
       "  sample_sifted Província sample_not_sifted shelf room  \n",
       "0             X    Huambo              null     1   22  \n",
       "1             X    Huambo              null     1   22  \n",
       "2             X    Huambo              null     1   22  \n",
       "3             X    Huambo              null     1   22  \n",
       "4             X    Huambo              null     1   22  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = pd.read_excel(\"/Users/inesschwartz/Desktop/Thesis/tables_soil_database/AmostrasAngolaTerrario.xlsx\")\n",
    "# Rename columns in the 'dat' DataFrame\n",
    "samples.rename(columns={\n",
    "    'Registo': 'sample_id',\n",
    "    'Nº Campo': 'site_info_id',\n",
    "    'Ano': 'year',\n",
    "    'Perfil': 'profile_id',\n",
    "    'Campanha': 'campaign',\n",
    "    'Colónia_Pais': 'country',\n",
    "    'Distrito': 'district',\n",
    "    'AmostraCrivada': 'sample_sifted',\n",
    "    'AmostraNaoCrivada': 'sample_not_sifted',\n",
    "    'Prateleira': 'shelf',\n",
    "    'Sala': 'room'\n",
    "}, inplace=True)\n",
    "\n",
    "\n",
    "# Replace nulls with the string 'null'\n",
    "samples_filled = samples.fillna('null')\n",
    "\n",
    "# Filter out and print duplicated samples (including the first occurrence)\n",
    "duplicated_values = samples['sample_id'][samples['sample_id'].duplicated()].unique()\n",
    "print(duplicated_values)\n",
    "\n",
    "duplicated_sites = samples['site_info_id'][samples['site_info_id'].duplicated()].unique()\n",
    "print(duplicated_sites)\n",
    "\n",
    "samples['site_info_id'] = samples['site_info_id'].astype(str)\n",
    "\n",
    "year_clean = samples['year'] = pd.to_datetime(samples['year'], format='%Y').dt.year\n",
    "\n",
    "# remove non-utf-8 characters in dataframa\n",
    "#samples_filled = samples_filled.applymap(lambda x: x.encode('utf-8', 'ignore').decode('utf-8') if isinstance(x, str) else x)\n",
    "\n",
    "# # strip leading/trailing whitespace\n",
    "# str_cols = samples_filled.select_dtypes(include=['object', 'string']).columns\n",
    "# for col in str_cols:\n",
    "#     samples_filled[col] = samples_filled[col].str.strip()\n",
    "\n",
    "# drop columns i won't be using\n",
    "samples_filled = samples_filled.drop('Obs', axis=1)\n",
    "\n",
    "samples_clean = samples_filled\n",
    "samples_clean.head()\n",
    "#samples_clean.to_csv(\"/Users/inesschwartz/Desktop/Thesis/tables_clean/samples_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tp/79mdnyy56_xc3g1jvp9wf4_80000gn/T/ipykernel_8876/2902848211.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  samples_ready['horizon_id']=samples_ready['horizon_id'].astype(str)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>site_info_id</th>\n",
       "      <th>profile_id</th>\n",
       "      <th>horizon_id</th>\n",
       "      <th>shelf</th>\n",
       "      <th>Room</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>630</td>\n",
       "      <td>172</td>\n",
       "      <td>139</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1946.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>631</td>\n",
       "      <td>173</td>\n",
       "      <td>139</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1946.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>632</td>\n",
       "      <td>174</td>\n",
       "      <td>139</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1946.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>633</td>\n",
       "      <td>175</td>\n",
       "      <td>139</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1946.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>687</td>\n",
       "      <td>1034</td>\n",
       "      <td>208</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1946.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_id site_info_id profile_id horizon_id shelf Room    year\n",
       "0        630          172        139       <NA>     1   22  1946.0\n",
       "1        631          173        139       <NA>     1   22  1946.0\n",
       "2        632          174        139       <NA>     1   22  1946.0\n",
       "3        633          175        139       <NA>     1   22  1946.0\n",
       "4        687         1034        208       <NA>     1   22  1946.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## reorder tables to fit schema\n",
    "# SAMPLES (\n",
    "#     sample_id,          -- int, PK\n",
    "#     sample\n",
    "#     profile,         -- FK\n",
    "#     lab_info_id,        -- FK\n",
    "#     Horizon_number,     -- FK, int\n",
    "#     Shelf,              -- VARCHAR\n",
    "#     Room,               -- VARCHAR\n",
    "#     Year                -- int\n",
    "# )\n",
    "\n",
    "#drop from samples_clean: campaign, country, province, sample_not_sifted\n",
    "\n",
    "# Drop unnecessary columns\n",
    "samples_clean = samples_filled.drop(columns=[\n",
    "    'campaign', 'country', 'Província', 'sample_not_sifted', 'sample_sifted'\n",
    "])\n",
    "\n",
    "# Add missing columns\n",
    "samples_clean['lab_info_id'] = pd.NA\n",
    "samples_clean['horizon_id'] = pd.NA  # only if you don't already have it — remove if it exists\n",
    "\n",
    "\n",
    "# Rename for consistent schema (only if needed)\n",
    "samples_clean = samples_clean.rename(columns={\n",
    "    'profile': 'profile',\n",
    "    'shelf': 'shelf',\n",
    "    'room': 'Room',\n",
    "    'year': 'year'\n",
    "})\n",
    "\n",
    "# Reorder columns to match SAMPLES schema\n",
    "samples_ready = samples_clean[[\n",
    "    'sample_id',\n",
    "    'site_info_id',\n",
    "    'profile_id',\n",
    "    'horizon_id',\n",
    "    'shelf',\n",
    "    'Room',\n",
    "    'year'\n",
    "]]\n",
    "\n",
    "samples_ready['horizon_id']=samples_ready['horizon_id'].astype(str)\n",
    "\n",
    "\n",
    "# Preview the result\n",
    "samples_ready.head()\n",
    "#samples_ready.to_csv(\"/Users/inesschwartz/Desktop/Thesis/tables_clean/samples_clean.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tp/79mdnyy56_xc3g1jvp9wf4_80000gn/T/ipykernel_8876/1149372123.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  samples_ready['shelf'] = samples_ready['shelf'].astype(\"string\")\n"
     ]
    }
   ],
   "source": [
    "samples_ready['shelf'] = samples_ready['shelf'].astype(\"string\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Column 'sample_id' is not float, found int64.\n",
      "✅ Column 'site_info_id' is string.\n",
      "✅ Column 'profile_id' is string.\n",
      "❌ Column 'horizon_id' is not float, found object.\n",
      "✅ Column 'shelf' is string.\n",
      "❌ Column 'year' is not a valid year.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "# Expected types\n",
    "expected_types = {\n",
    "    'sample_id': float,\n",
    "    'site_info_id': str,\n",
    "    'profile_id': str,\n",
    "    'horizon_id': float,\n",
    "    'shelf': str,\n",
    "    'year': 'year'  # Special handling for year as date\n",
    "}\n",
    "\n",
    "# Function to check if a column is a year (date or int-like)\n",
    "def is_year_column(series):\n",
    "    if pd.api.types.is_datetime64_any_dtype(series):\n",
    "        return all(series.dt.year.between(1900, datetime.datetime.now().year))\n",
    "    elif pd.api.types.is_integer_dtype(series):\n",
    "        return all((series >= 1900) & (series <= datetime.datetime.now().year))\n",
    "    return False\n",
    "\n",
    "# Check data types\n",
    "for column, expected_type in expected_types.items():\n",
    "    if column not in samples_ready.columns:\n",
    "        print(f\"❌ Column '{column}' not found in DataFrame.\")\n",
    "        continue\n",
    "\n",
    "    actual_dtype = samples_ready[column].dtype\n",
    "\n",
    "    if expected_type == 'year':\n",
    "        if is_year_column(samples_ready[column]):\n",
    "            print(f\"✅ Column '{column}' is a valid year.\")\n",
    "        else:\n",
    "            print(f\"❌ Column '{column}' is not a valid year.\")\n",
    "    elif expected_type == float:\n",
    "        if pd.api.types.is_float_dtype(samples_ready[column]):\n",
    "            print(f\"✅ Column '{column}' is float.\")\n",
    "        else:\n",
    "            print(f\"❌ Column '{column}' is not float, found {actual_dtype}.\")\n",
    "    elif expected_type == int:\n",
    "        if pd.api.types.is_integer_dtype(samples_ready[column]):\n",
    "            print(f\"✅ Column '{column}' is int.\")\n",
    "        else:\n",
    "            print(f\"❌ Column '{column}' is not int, found {actual_dtype}.\")\n",
    "    elif expected_type == str:\n",
    "        if pd.api.types.is_string_dtype(samples_ready[column]):\n",
    "            print(f\"✅ Column '{column}' is string.\")\n",
    "        else:\n",
    "            print(f\"❌ Column '{column}' is not string, found {actual_dtype}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Column 'sample_id' converted to float.\n",
      "✅ Column 'site_info_id' converted to string.\n",
      "✅ Column 'profile_id' converted to string.\n",
      "✅ Column 'year' converted to year (int).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tp/79mdnyy56_xc3g1jvp9wf4_80000gn/T/ipykernel_8876/332639328.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  samples_ready[column] = samples_ready[column].astype(float)\n",
      "/var/folders/tp/79mdnyy56_xc3g1jvp9wf4_80000gn/T/ipykernel_8876/332639328.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  samples_ready[column] = samples_ready[column].astype(str)\n",
      "/var/folders/tp/79mdnyy56_xc3g1jvp9wf4_80000gn/T/ipykernel_8876/332639328.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  samples_ready[column] = samples_ready[column].astype(str)\n",
      "/var/folders/tp/79mdnyy56_xc3g1jvp9wf4_80000gn/T/ipykernel_8876/332639328.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  samples_ready[column] = pd.to_datetime(samples_ready[column], errors='coerce')\n",
      "/var/folders/tp/79mdnyy56_xc3g1jvp9wf4_80000gn/T/ipykernel_8876/332639328.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  samples_ready[column] = samples_ready[column].dt.year\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "# Expected types and target conversions\n",
    "expected_types = {\n",
    "    'sample_id': float,\n",
    "    'site_info_id': str,\n",
    "    'profile_id': str,\n",
    "    'horizon_id': object,\n",
    "    'shelf': object,\n",
    "    'year': 'year'  # special case\n",
    "}\n",
    "\n",
    "# Function to check if a column is a valid year\n",
    "def is_year_column(series):\n",
    "    if pd.api.types.is_datetime64_any_dtype(series):\n",
    "        return all(series.dt.year.between(1900, datetime.datetime.now().year))\n",
    "    elif pd.api.types.is_integer_dtype(series):\n",
    "        return all((series >= 1900) & (series <= datetime.datetime.now().year))\n",
    "    return False\n",
    "\n",
    "# Loop through columns to check and convert\n",
    "for column, expected_type in expected_types.items():\n",
    "    if column not in samples_ready.columns:\n",
    "        print(f\"❌ Column '{column}' not found in DataFrame.\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        if expected_type == 'year':\n",
    "            # Convert to datetime if needed\n",
    "            if not pd.api.types.is_datetime64_any_dtype(samples_ready[column]):\n",
    "                samples_ready[column] = pd.to_datetime(samples_ready[column], errors='coerce')\n",
    "            # Extract year as integer\n",
    "            samples_ready[column] = samples_ready[column].dt.year\n",
    "            print(f\"✅ Column '{column}' converted to year (int).\")\n",
    "\n",
    "        elif expected_type == float:\n",
    "            samples_ready[column] = samples_ready[column].astype(float)\n",
    "            print(f\"✅ Column '{column}' converted to float.\")\n",
    "\n",
    "        elif expected_type == int:\n",
    "            samples_ready[column] = samples_ready[column].astype(int)\n",
    "            print(f\"✅ Column '{column}' converted to int.\")\n",
    "\n",
    "        elif expected_type == str:\n",
    "            samples_ready[column] = samples_ready[column].astype(str)\n",
    "            print(f\"✅ Column '{column}' converted to string.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to convert column '{column}' to {expected_type}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANALYSES table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10337.    nan 11608.  3497.  3498.  2923.  2924.  2925.  2926.  2927.\n",
      "  2928.  2929.  2930. 16355. 16356.   419.   420. 15682. 13817. 13965.\n",
      "  3418.  9230.  8639.  3529.]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lab_sample_id</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>horizon_id</th>\n",
       "      <th>analysis_id</th>\n",
       "      <th>profile_id</th>\n",
       "      <th>NA</th>\n",
       "      <th>upper_limit</th>\n",
       "      <th>lower_limit</th>\n",
       "      <th>EG</th>\n",
       "      <th>thick_clay</th>\n",
       "      <th>...</th>\n",
       "      <th>V</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>sulfates</th>\n",
       "      <th>conductivity</th>\n",
       "      <th>soluble_sodium</th>\n",
       "      <th>Min_&lt;0,002</th>\n",
       "      <th>Min_0,05-0,02</th>\n",
       "      <th>Min_0,2-0,05</th>\n",
       "      <th>Min_2-0,2</th>\n",
       "      <th>Confirmar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10999.0</td>\n",
       "      <td>B_101/62_1_1</td>\n",
       "      <td>B_101/62_1_1</td>\n",
       "      <td>101/62</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.700001</td>\n",
       "      <td>...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>B_101/62_2_1</td>\n",
       "      <td>B_101/62_2_1</td>\n",
       "      <td>101/62</td>\n",
       "      <td>2</td>\n",
       "      <td>11.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.799999</td>\n",
       "      <td>...</td>\n",
       "      <td>10.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>11001.0</td>\n",
       "      <td>B_101/62_3_1</td>\n",
       "      <td>B_101/62_3_1</td>\n",
       "      <td>101/62</td>\n",
       "      <td>3</td>\n",
       "      <td>28.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>11002.0</td>\n",
       "      <td>B_101/62_4_1</td>\n",
       "      <td>B_101/62_4_1</td>\n",
       "      <td>101/62</td>\n",
       "      <td>4</td>\n",
       "      <td>55.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.599998</td>\n",
       "      <td>...</td>\n",
       "      <td>8.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>11003.0</td>\n",
       "      <td>B_101/62_5_2</td>\n",
       "      <td>B_101/62_5_21</td>\n",
       "      <td>101/62</td>\n",
       "      <td>5</td>\n",
       "      <td>90.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.799999</td>\n",
       "      <td>...</td>\n",
       "      <td>7.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   lab_sample_id  sample_id    horizon_id    analysis_id profile_id  NA  \\\n",
       "0              1    10999.0  B_101/62_1_1   B_101/62_1_1     101/62   1   \n",
       "1              2    11000.0  B_101/62_2_1   B_101/62_2_1     101/62   2   \n",
       "2              3    11001.0  B_101/62_3_1   B_101/62_3_1     101/62   3   \n",
       "3              4    11002.0  B_101/62_4_1   B_101/62_4_1     101/62   4   \n",
       "4              5    11003.0  B_101/62_5_2  B_101/62_5_21     101/62   5   \n",
       "\n",
       "   upper_limit  lower_limit  EG  thick_clay  ...     V  chlorides  sulfates  \\\n",
       "0          0.0         11.0 NaN   61.700001  ...  23.0        NaN       NaN   \n",
       "1         11.0         28.0 NaN   52.799999  ...  10.6        NaN       NaN   \n",
       "2         28.0         54.0 NaN   42.500000  ...   5.6        NaN       NaN   \n",
       "3         55.0         85.0 NaN   42.599998  ...   8.8        NaN       NaN   \n",
       "4         90.0        120.0 NaN   36.799999  ...   7.7        NaN       NaN   \n",
       "\n",
       "   conductivity  soluble_sodium  Min_<0,002  Min_0,05-0,02  Min_0,2-0,05  \\\n",
       "0           NaN             0.0         NaN            NaN           NaN   \n",
       "1           NaN             0.0         NaN            NaN           NaN   \n",
       "2           NaN             0.0         NaN            NaN           NaN   \n",
       "3           NaN             0.0         NaN            NaN           NaN   \n",
       "4           NaN             0.0         NaN            NaN           NaN   \n",
       "\n",
       "   Min_2-0,2  Confirmar  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyses.rename(columns={\n",
    "    'Amostra': 'sample_id',\n",
    "    'Morfo_id': 'horizon_id',\n",
    "    'Analise-id': 'analysis_id',\n",
    "    'PERFIL': 'profile_id',\n",
    "    'LS': 'upper_limit',\n",
    "    'LI': 'lower_limit',\n",
    "    'EG': 'EG',\n",
    "    'AG': 'thick_clay',\n",
    "    'AF': 'fine_clay',\n",
    "    'Argila': 'clay',\n",
    "    'L': 'silt',\n",
    "    'Gesso': 'gypsum',\n",
    "    'Fe livre': 'free_iron',\n",
    "    'CO':'organic_carbon',\n",
    "    'N total': 'total_N',\n",
    "    'MO': 'OM',\n",
    "    'Soma de bases': 'exchangable_bases_sum',\n",
    "    'CTC': 'CEC',\n",
    "    'Cloretos':'chlorides',\n",
    "    'Sulfatos':'sulfates',\n",
    "    'Condutividade':'conductivity',\n",
    "    'Sódio solúvel':'soluble_sodium',\n",
    "    'P205 total': 'P205',\n",
    "    'pH (H2O)':'pH_H2O',\n",
    "    'pH(KCL)':'pH_KCL',\n",
    "    'MO': 'organic_material'\n",
    "}, inplace=True)\n",
    "\n",
    "# Replace nulls with the string 'null'\n",
    "analyses_filled = analyses.fillna('null')\n",
    "\n",
    "# Filter out and print duplicated samples (including the first occurrence)\n",
    "duplicated_values = analyses['sample_id'][analyses['sample_id'].duplicated()].unique()\n",
    "print(duplicated_values)\n",
    "\n",
    "# Drop columns not needed\n",
    "analyses_drop = analyses.drop([\n",
    "    'EqMol (SiO2)', 'EqMol(Al2O3)', 'EqMol(Fe2O3)', 'SiO2/Al2O3', \n",
    "    'SiO2/Fe2O3', 'SiO2/R2O3', 'Fe2O3/Al2O3', 'FE2O3_TARG', \n",
    "    'FE2O3_LARG', 'CEC_ARG', 'GR', 'ID', 'COD_PROV'\n",
    "], axis=1)\n",
    "\n",
    "# Add a new Primary Key ID column starting from 1\n",
    "analyses_drop.insert(0, 'lab_sample_id', range(1, len(analyses_drop) + 1))\n",
    "\n",
    "# Final cleaned dataframe\n",
    "analyses2 = analyses_drop\n",
    "\n",
    "\n",
    "#preview\n",
    "analyses2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lab_sample_id</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>minerology_id</th>\n",
       "      <th>EG</th>\n",
       "      <th>thick_clay</th>\n",
       "      <th>fine_clay</th>\n",
       "      <th>silt</th>\n",
       "      <th>clay</th>\n",
       "      <th>Eq_Hum</th>\n",
       "      <th>atm_1/3</th>\n",
       "      <th>...</th>\n",
       "      <th>K+</th>\n",
       "      <th>exchangable_bases_sum</th>\n",
       "      <th>CEC</th>\n",
       "      <th>V</th>\n",
       "      <th>conductivity</th>\n",
       "      <th>soluble_sodium</th>\n",
       "      <th>Min_&lt;0,002</th>\n",
       "      <th>Min_0,05-0,02</th>\n",
       "      <th>Min_0,2-0,05</th>\n",
       "      <th>Min_2-0,2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10999.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.700001</td>\n",
       "      <td>32.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.3</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.83</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.799999</td>\n",
       "      <td>35.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>11.4</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.98</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>11001.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.500000</td>\n",
       "      <td>46.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>11.1</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.62</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>11002.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.599998</td>\n",
       "      <td>41.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>15.4</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.91</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>11003.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.799999</td>\n",
       "      <td>47.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>14.5</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.04</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>11004.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.099998</td>\n",
       "      <td>41.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>11.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>11011.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.300000</td>\n",
       "      <td>48.5</td>\n",
       "      <td>17.6</td>\n",
       "      <td>18.5</td>\n",
       "      <td>19.700001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.49</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>11012.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.600000</td>\n",
       "      <td>42.3</td>\n",
       "      <td>17.8</td>\n",
       "      <td>21.3</td>\n",
       "      <td>19.600000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.96</td>\n",
       "      <td>20.600000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>11013.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>36.8</td>\n",
       "      <td>22.1</td>\n",
       "      <td>29.1</td>\n",
       "      <td>21.700001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.02</td>\n",
       "      <td>16.900000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>11014.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>21.0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>34.8</td>\n",
       "      <td>21.6</td>\n",
       "      <td>32.6</td>\n",
       "      <td>21.600000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.11</td>\n",
       "      <td>19.299999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>11015.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>43.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>34.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>33.5</td>\n",
       "      <td>21.900000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.33</td>\n",
       "      <td>22.799999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>11016.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>35.6</td>\n",
       "      <td>10.8</td>\n",
       "      <td>38.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>11017.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.800000</td>\n",
       "      <td>39.6</td>\n",
       "      <td>12.9</td>\n",
       "      <td>33.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>2923.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>4.0</td>\n",
       "      <td>48.900002</td>\n",
       "      <td>33.6</td>\n",
       "      <td>4.3</td>\n",
       "      <td>13.1</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.18</td>\n",
       "      <td>24.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>2924.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>4.0</td>\n",
       "      <td>43.200001</td>\n",
       "      <td>40.1</td>\n",
       "      <td>3.6</td>\n",
       "      <td>13.1</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.10</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>2925.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>4.0</td>\n",
       "      <td>42.900002</td>\n",
       "      <td>38.8</td>\n",
       "      <td>5.9</td>\n",
       "      <td>12.5</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.15</td>\n",
       "      <td>22.299999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>2926.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25.799999</td>\n",
       "      <td>27.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>42.2</td>\n",
       "      <td>19.600000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.86</td>\n",
       "      <td>17.900000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>2927.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>30.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>40.5</td>\n",
       "      <td>18.700001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.87</td>\n",
       "      <td>24.700001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>2928.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23.100000</td>\n",
       "      <td>30.9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>41.2</td>\n",
       "      <td>19.299999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.10</td>\n",
       "      <td>21.900000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>2929.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.400000</td>\n",
       "      <td>29.3</td>\n",
       "      <td>6.6</td>\n",
       "      <td>39.7</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.52</td>\n",
       "      <td>27.400000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    lab_sample_id  sample_id minerology_id    EG  thick_clay  fine_clay  silt  \\\n",
       "0               1    10999.0          <NA>   NaN   61.700001       32.8   0.2   \n",
       "1               2    11000.0          <NA>   NaN   52.799999       35.1   0.7   \n",
       "2               3    11001.0          <NA>   NaN   42.500000       46.2   0.2   \n",
       "3               4    11002.0          <NA>   NaN   42.599998       41.8   0.2   \n",
       "4               5    11003.0          <NA>   NaN   36.799999       47.5   1.2   \n",
       "5               6    11004.0          <NA>   NaN   45.099998       41.8   1.4   \n",
       "6               7    11011.0          <NA>   1.0   15.300000       48.5  17.6   \n",
       "7               8    11012.0          <NA>   3.0   18.600000       42.3  17.8   \n",
       "8               9    11013.0          <NA>   7.0   12.000000       36.8  22.1   \n",
       "9              10    11014.0          <NA>  21.0   11.000000       34.8  21.6   \n",
       "10             11    11015.0          <NA>  43.0   10.000000       34.0  22.5   \n",
       "11             12    11016.0          <NA>   NaN   14.900000       35.6  10.8   \n",
       "12             13    11017.0          <NA>   NaN   13.800000       39.6  12.9   \n",
       "13             14     2923.0          <NA>   4.0   48.900002       33.6   4.3   \n",
       "14             15     2924.0          <NA>   4.0   43.200001       40.1   3.6   \n",
       "15             16     2925.0          <NA>   4.0   42.900002       38.8   5.9   \n",
       "16             17     2926.0          <NA>   4.0   25.799999       27.7   4.4   \n",
       "17             18     2927.0          <NA>   2.0   25.500000       30.4   3.6   \n",
       "18             19     2928.0          <NA>   3.0   23.100000       30.9   4.9   \n",
       "19             20     2929.0          <NA>   4.0   24.400000       29.3   6.6   \n",
       "\n",
       "    clay     Eq_Hum  atm_1/3  ...    K+  exchangable_bases_sum   CEC  \\\n",
       "0    5.3   4.600000      NaN  ...  0.03                    NaN  1.83   \n",
       "1   11.4   6.400000      NaN  ...  0.03                    NaN  1.98   \n",
       "2   11.1   6.300000      NaN  ...  0.01                    NaN  1.62   \n",
       "3   15.4   5.200000      NaN  ...  0.01                    NaN  0.91   \n",
       "4   14.5   7.300000      NaN  ...  0.01                    NaN  1.04   \n",
       "5   11.7   0.000000      NaN  ...   NaN                    NaN   NaN   \n",
       "6   18.5  19.700001      NaN  ...  0.18                    NaN  4.49   \n",
       "7   21.3  19.600000      NaN  ...  0.07                    NaN  2.96   \n",
       "8   29.1  21.700001      NaN  ...  0.04                    NaN  3.02   \n",
       "9   32.6  21.600000      NaN  ...  0.03                    NaN  3.11   \n",
       "10  33.5  21.900000      NaN  ...  0.03                    NaN  3.33   \n",
       "11  38.7   0.000000      NaN  ...   NaN                    NaN   NaN   \n",
       "12  33.7   0.000000      NaN  ...   NaN                    NaN   NaN   \n",
       "13  13.1   9.500000      NaN  ...  0.06                    NaN  3.18   \n",
       "14  13.1   7.400000      NaN  ...  0.04                    NaN  3.10   \n",
       "15  12.5   8.500000      NaN  ...  0.04                    NaN  2.15   \n",
       "16  42.2  19.600000      NaN  ...  0.10                    NaN  3.86   \n",
       "17  40.5  18.700001      NaN  ...  0.25                    NaN  2.87   \n",
       "18  41.2  19.299999      NaN  ...  0.25                    NaN  3.10   \n",
       "19  39.7  20.000000      NaN  ...  0.19                    NaN  2.52   \n",
       "\n",
       "            V  conductivity  soluble_sodium  Min_<0,002  Min_0,05-0,02  \\\n",
       "0   23.000000           NaN             0.0         NaN            NaN   \n",
       "1   10.600000           NaN             0.0         NaN            NaN   \n",
       "2    5.600000           NaN             0.0         NaN            NaN   \n",
       "3    8.800000           NaN             0.0         NaN            NaN   \n",
       "4    7.700000           NaN             0.0         NaN            NaN   \n",
       "5         NaN           NaN             0.0         NaN            NaN   \n",
       "6   32.500000           NaN             0.0         NaN            NaN   \n",
       "7   20.600000           NaN             0.0         NaN            NaN   \n",
       "8   16.900000           NaN             0.0         NaN            NaN   \n",
       "9   19.299999           NaN             0.0         NaN            NaN   \n",
       "10  22.799999           NaN             0.0         NaN            NaN   \n",
       "11        NaN           NaN             0.0         NaN            NaN   \n",
       "12        NaN           NaN             0.0         NaN            NaN   \n",
       "13  24.500000           NaN             0.0         NaN            NaN   \n",
       "14  14.500000           NaN             0.0         NaN            NaN   \n",
       "15  22.299999           NaN             0.0         NaN            NaN   \n",
       "16  17.900000           NaN             0.0         NaN            NaN   \n",
       "17  24.700001           NaN             0.0         NaN            NaN   \n",
       "18  21.900000           NaN             0.0         NaN            NaN   \n",
       "19  27.400000           NaN             0.0         NaN            NaN   \n",
       "\n",
       "    Min_0,2-0,05  Min_2-0,2  \n",
       "0            NaN        NaN  \n",
       "1            NaN        NaN  \n",
       "2            NaN        NaN  \n",
       "3            NaN        NaN  \n",
       "4            NaN        NaN  \n",
       "5            NaN        NaN  \n",
       "6            NaN        NaN  \n",
       "7            NaN        NaN  \n",
       "8            NaN        NaN  \n",
       "9            NaN        NaN  \n",
       "10           NaN        NaN  \n",
       "11           NaN        NaN  \n",
       "12           NaN        NaN  \n",
       "13           NaN        NaN  \n",
       "14           NaN        NaN  \n",
       "15           NaN        NaN  \n",
       "16           NaN        NaN  \n",
       "17           NaN        NaN  \n",
       "18           NaN        NaN  \n",
       "19           NaN        NaN  \n",
       "\n",
       "[20 rows x 33 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ANALYSES\n",
    "\n",
    "\n",
    "# Reorder columns to match SAMPLES schema\n",
    "# Define the desired final column order\n",
    "final_columns = [\n",
    "    'lab_sample_id',\n",
    "    'sample_id',\n",
    "    'minerology_id',\n",
    "    'EG',\n",
    "    'thick_clay',\n",
    "    'fine_clay',\n",
    "    'silt',\n",
    "    'clay',\n",
    "    'Eq_Hum',\n",
    "    'atm_1/3',\n",
    "    'atm_15',\n",
    "    'CACO3',\n",
    "    'gypsum',\n",
    "    'free_iron',\n",
    "    'organic_carbon',\n",
    "    'total_N',\n",
    "    'P205',\n",
    "    'organic_material',\n",
    "    'pH_H2O',\n",
    "    'pH_KCL',\n",
    "    'Ca++',\n",
    "    'Mg++',\n",
    "    'Na+',\n",
    "    'K+',\n",
    "    'exchangable_bases_sum',\n",
    "    'CEC',\n",
    "    'V',\n",
    "    'conductivity',\n",
    "    'soluble_sodium',\n",
    "    'Min_<0,002',\n",
    "    'Min_0,05-0,02',\n",
    "    'Min_0,2-0,05',\n",
    "    'Min_2-0,2',\n",
    "]\n",
    "\n",
    "\n",
    "# Add missing columns with NaN values\n",
    "for col in final_columns:\n",
    "    if col not in analyses2.columns:\n",
    "        analyses2[col] = pd.NA  # or np.nan if you prefer\n",
    "\n",
    "# Reorder columns\n",
    "analyses_ready = analyses2[final_columns]\n",
    "\n",
    "# Preview first 20 rows\n",
    "analyses_ready.head(20)\n",
    "\n",
    "# Export to CSV\n",
    "#analyses_ready.to_csv(\"/Users/inesschwartz/Desktop/Thesis/tables_clean/analyses_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## joining elemental analyses to analyses (still not correct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>Soil Profile</th>\n",
       "      <th>Code</th>\n",
       "      <th>Code.1</th>\n",
       "      <th>Depht</th>\n",
       "      <th>Sampling Date</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>P</th>\n",
       "      <th>...</th>\n",
       "      <th>Ta</th>\n",
       "      <th>W</th>\n",
       "      <th>Pt</th>\n",
       "      <th>Au</th>\n",
       "      <th>Hg</th>\n",
       "      <th>Tl</th>\n",
       "      <th>Pb</th>\n",
       "      <th>Bi</th>\n",
       "      <th>Th</th>\n",
       "      <th>U</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16105</td>\n",
       "      <td>PS7C/55</td>\n",
       "      <td>A-159C</td>\n",
       "      <td>S-1159</td>\n",
       "      <td>0.00-0.11</td>\n",
       "      <td>1965-06-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50563.666667</td>\n",
       "      <td>383607.333333</td>\n",
       "      <td>606.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16217</td>\n",
       "      <td>P83C/65</td>\n",
       "      <td>A-171C</td>\n",
       "      <td>S-1171</td>\n",
       "      <td>0.00-0.15</td>\n",
       "      <td>1965-07-09</td>\n",
       "      <td>1168.0</td>\n",
       "      <td>45979.000000</td>\n",
       "      <td>393787.666667</td>\n",
       "      <td>609.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16033</td>\n",
       "      <td>PSOC/65</td>\n",
       "      <td>A.87C</td>\n",
       "      <td>S-1087</td>\n",
       "      <td>0.00-0.13</td>\n",
       "      <td>1965-07-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49541.333333</td>\n",
       "      <td>390160.000000</td>\n",
       "      <td>694.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16252</td>\n",
       "      <td>P115C/65</td>\n",
       "      <td>A-312C</td>\n",
       "      <td>S-1312</td>\n",
       "      <td>0.00-0.15</td>\n",
       "      <td>1965-07-27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77839.666667</td>\n",
       "      <td>358230.000000</td>\n",
       "      <td>601.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16231</td>\n",
       "      <td>P276C/65</td>\n",
       "      <td>A-291C</td>\n",
       "      <td>S-1291</td>\n",
       "      <td>0.00-0.12</td>\n",
       "      <td>1965-08-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41215.000000</td>\n",
       "      <td>392816.333333</td>\n",
       "      <td>702.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_id Soil Profile    Code  Code.1      Depht Sampling Date      Mg  \\\n",
       "0      16105      PS7C/55  A-159C  S-1159  0.00-0.11    1965-06-07     0.0   \n",
       "1      16217      P83C/65  A-171C  S-1171  0.00-0.15    1965-07-09  1168.0   \n",
       "2      16033      PSOC/65   A.87C  S-1087  0.00-0.13    1965-07-19     0.0   \n",
       "3      16252     P115C/65  A-312C  S-1312  0.00-0.15    1965-07-27     0.0   \n",
       "4      16231     P276C/65  A-291C  S-1291  0.00-0.12    1965-08-08     0.0   \n",
       "\n",
       "             Al             Si           P  ...    Ta     W   Pt  Au  \\\n",
       "0  50563.666667  383607.333333  606.333333  ...   NaN   NaN  6.0 NaN   \n",
       "1  45979.000000  393787.666667  609.000000  ...   NaN   NaN  NaN NaN   \n",
       "2  49541.333333  390160.000000  694.333333  ...  21.0   NaN  NaN NaN   \n",
       "3  77839.666667  358230.000000  601.666667  ...  28.0  10.0  NaN NaN   \n",
       "4  41215.000000  392816.333333  702.666667  ...  20.0   NaN  NaN NaN   \n",
       "\n",
       "         Hg   Tl         Pb   Bi    Th   U  \n",
       "0  5.666667  4.0        NaN  NaN   NaN NaN  \n",
       "1  6.666667  3.0        NaN  3.0   NaN NaN  \n",
       "2  7.666667  NaN  10.666667  NaN  11.0 NaN  \n",
       "3  9.666667  3.0        NaN  NaN  10.5 NaN  \n",
       "4  7.333333  NaN        NaN  NaN   NaN NaN  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename 'Lab. Code' to 'sample_id'\n",
    "elemental_analyses.rename(columns={'Lab. Code': 'sample_id'}, inplace=True)\n",
    "\n",
    "# Temporarily convert to string to do the replacements\n",
    "sample_id_cleaned = elemental_analyses['sample_id'].astype(str)\n",
    "sample_id_cleaned = sample_id_cleaned.str.replace('C-', '', regex=False)\n",
    "sample_id_cleaned = sample_id_cleaned.str.replace(' MNL', '', regex=False)\n",
    "\n",
    "# Then convert to numeric (int or float, depending on your data)\n",
    "elemental_analyses['sample_id'] = pd.to_numeric(sample_id_cleaned, errors='coerce')\n",
    "\n",
    "elemental_analyses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "elemental_analyses.rename(columns={\n",
    "    'Code': 'field_sample_code'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "print (analyses_ready['sample_id'].dtype)\n",
    "print (elemental_analyses['sample_id'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "elemental_analyses['sample_id'] = elemental_analyses['sample_id'].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample IDs in elemental_analyses not found in analyses_ready:\n",
      "[16105. 16217. 16033. 16231. 16208. 16274. 16225. 15731. 16078. 15786.\n",
      " 15693. 15678. 15959. 16372. 16418. 16459. 16477. 15498. 15437. 12749.\n",
      " 13109. 14337. 14319. 15484. 15508. 15614. 15580. 15582. 15606. 15463.\n",
      " 14496. 11343. 17892. 16976. 17269. 18248. 16946. 17686. 17728. 17415.\n",
      " 17642. 18212. 17016. 17282. 18429. 17340. 18824. 18448.  8721.  7313.\n",
      "  5502.  5392.  7317.  8626.  7193.  7254.  7293.  8240. 15397. 14403.\n",
      " 14983. 16126. 15059. 15322. 15268. 14808. 15106.]\n"
     ]
    }
   ],
   "source": [
    "# Check which sample_ids in elemental_analyses are NOT in analyses_ready\n",
    "missing_ids = elemental_analyses[~elemental_analyses['sample_id'].isin(analyses_ready['sample_id'])]\n",
    "\n",
    "# Display them\n",
    "print(\"Sample IDs in elemental_analyses not found in analyses_ready:\")\n",
    "print(missing_ids['sample_id'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lab_sample_id</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>minerology_id</th>\n",
       "      <th>EG</th>\n",
       "      <th>thick_clay</th>\n",
       "      <th>fine_clay</th>\n",
       "      <th>silt</th>\n",
       "      <th>clay</th>\n",
       "      <th>Eq_Hum</th>\n",
       "      <th>atm_1/3</th>\n",
       "      <th>...</th>\n",
       "      <th>Ta</th>\n",
       "      <th>W</th>\n",
       "      <th>Pt</th>\n",
       "      <th>Au</th>\n",
       "      <th>Hg</th>\n",
       "      <th>Tl</th>\n",
       "      <th>Pb</th>\n",
       "      <th>Bi</th>\n",
       "      <th>Th</th>\n",
       "      <th>U</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10999.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.700001</td>\n",
       "      <td>32.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.799999</td>\n",
       "      <td>35.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>11.4</td>\n",
       "      <td>6.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>11001.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.500000</td>\n",
       "      <td>46.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>11.1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>11002.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.599998</td>\n",
       "      <td>41.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>15.4</td>\n",
       "      <td>5.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>11003.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.799999</td>\n",
       "      <td>47.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>14.5</td>\n",
       "      <td>7.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   lab_sample_id  sample_id minerology_id  EG  thick_clay  fine_clay  silt  \\\n",
       "0              1    10999.0          <NA> NaN   61.700001       32.8   0.2   \n",
       "1              2    11000.0          <NA> NaN   52.799999       35.1   0.7   \n",
       "2              3    11001.0          <NA> NaN   42.500000       46.2   0.2   \n",
       "3              4    11002.0          <NA> NaN   42.599998       41.8   0.2   \n",
       "4              5    11003.0          <NA> NaN   36.799999       47.5   1.2   \n",
       "\n",
       "   clay  Eq_Hum  atm_1/3  ...  Ta   W  Pt  Au  Hg  Tl  Pb  Bi  Th   U  \n",
       "0   5.3     4.6      NaN  ... NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "1  11.4     6.4      NaN  ... NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "2  11.1     6.3      NaN  ... NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "3  15.4     5.2      NaN  ... NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "4  14.5     7.3      NaN  ... NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged1= analyses_ready.merge(elemental_analyses, on='sample_id', how='left')\n",
    "merged1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      lab_sample_id  sample_id minerology_id  EG  thick_clay  fine_clay  silt  \\\n",
      "1361           1362     6940.0          <NA> NaN        31.1       43.8   2.7   \n",
      "\n",
      "      clay  Eq_Hum  atm_1/3  ...  K+  exchangable_bases_sum  CEC   V  \\\n",
      "1361  22.7    18.9      NaN  ... NaN                    NaN  NaN NaN   \n",
      "\n",
      "      conductivity  soluble_sodium  Min_<0,002  Min_0,05-0,02  Min_0,2-0,05  \\\n",
      "1361           NaN             0.0         NaN            NaN           NaN   \n",
      "\n",
      "      Min_2-0,2  \n",
      "1361        NaN  \n",
      "\n",
      "[1 rows x 33 columns]\n",
      "    sample_id Soil Profile field_sample_code Code.1      Depht Sampling Date  \\\n",
      "80     6940.0      P134/59          A-320/59  S-492  1.30-1.70    1954-08-06   \n",
      "\n",
      "             Mg             Al             Si      P  ...    Ta   W  Pt  Au  \\\n",
      "80  1457.666667  106266.333333  308859.666667  468.0  ...  26.0 NaN NaN NaN   \n",
      "\n",
      "           Hg   Tl         Pb  Bi         Th   U  \n",
      "80  10.666667  4.0  25.333333 NaN  12.333333 NaN  \n",
      "\n",
      "[1 rows x 44 columns]\n"
     ]
    }
   ],
   "source": [
    "print(analyses_ready[analyses_ready['sample_id'] == 6940])\n",
    "print(elemental_analyses[elemental_analyses['sample_id'] == 6940])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prep final dataset\n",
    "final_columns = [\n",
    "    'lab_sample_id',\n",
    "    'sample_id',\n",
    "    'EG',\n",
    "    'thick_clay',\n",
    "    'fine_clay',\n",
    "    'silt',\n",
    "    'clay',\n",
    "    'Eq_Hum',\n",
    "    'atm_1/3',\n",
    "    'atm_15',\n",
    "    'CACO3',\n",
    "    'gypsum',\n",
    "    'free_iron',\n",
    "    'organic_carbon',\n",
    "    'total_N',\n",
    "    'P205',\n",
    "    'organic_material',\n",
    "    'pH_H2O',\n",
    "    'pH_KCL',\n",
    "    'Ca++',\n",
    "    'Mg++',\n",
    "    'Na+',\n",
    "    'K+',\n",
    "    'exchangable_bases_sum',\n",
    "    'CEC',\n",
    "    'V',\n",
    "    'conductivity',\n",
    "    'soluble_sodium',\n",
    "    'Min_<0,002',\n",
    "    'Min_0,05-0,02',\n",
    "    'Min_0,2-0,05',\n",
    "    'Min_2-0,2',\n",
    "    'field_sample_code',\n",
    "    'Depht',\n",
    "    'Al',\n",
    "    'Si',\n",
    "    'P',\n",
    "    'S',\n",
    "    'Cl',\n",
    "    'Ti',\n",
    "    'Cr',\n",
    "    'Mn',\n",
    "    'Fe',\n",
    "    'Co',\n",
    "    'Ni',\n",
    "    'Cu',\n",
    "    'Zn',\n",
    "    'As',\n",
    "    'Se',\n",
    "    'Rb',\n",
    "    'Sr',\n",
    "    'Zr',\n",
    "    'Nb',\n",
    "    'Mo',\n",
    "    'Cd',\n",
    "    'Sn',\n",
    "    'Sb',\n",
    "    'Ba',\n",
    "    'Ta',\n",
    "    'W',\n",
    "    'Pt',\n",
    "    'Au',\n",
    "    'Hg',\n",
    "    'Tl',\n",
    "    'Pb',\n",
    "    'Bi',\n",
    "    'Th',\n",
    "    'U',\n",
    "]\n",
    "\n",
    "# Add missing columns with NaN values\n",
    "for col in final_columns:\n",
    "    if col not in merged1.columns:\n",
    "        merged1[col] = pd.NA  # or np.nan if you prefer\n",
    "\n",
    "# Reorder columns\n",
    "merged1 = merged1[final_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      lab_sample_id  sample_id minerology_id  EG  thick_clay  fine_clay  silt  \\\n",
      "1361           1362     6940.0          <NA> NaN        31.1       43.8   2.7   \n",
      "\n",
      "      clay  Eq_Hum  atm_1/3  ...  K+  exchangable_bases_sum  CEC   V  \\\n",
      "1361  22.7    18.9      NaN  ... NaN                    NaN  NaN NaN   \n",
      "\n",
      "      conductivity  soluble_sodium  Min_<0,002  Min_0,05-0,02  Min_0,2-0,05  \\\n",
      "1361           NaN             0.0         NaN            NaN           NaN   \n",
      "\n",
      "      Min_2-0,2  \n",
      "1361        NaN  \n",
      "\n",
      "[1 rows x 33 columns]\n",
      "    sample_id Soil Profile field_sample_code Code.1      Depht Sampling Date  \\\n",
      "80     6940.0      P134/59          A-320/59  S-492  1.30-1.70    1954-08-06   \n",
      "\n",
      "             Mg             Al             Si      P  ...    Ta   W  Pt  Au  \\\n",
      "80  1457.666667  106266.333333  308859.666667  468.0  ...  26.0 NaN NaN NaN   \n",
      "\n",
      "           Hg   Tl         Pb  Bi         Th   U  \n",
      "80  10.666667  4.0  25.333333 NaN  12.333333 NaN  \n",
      "\n",
      "[1 rows x 44 columns]\n"
     ]
    }
   ],
   "source": [
    "print(analyses_ready[analyses_ready['sample_id'] == 6940])\n",
    "print(elemental_analyses[elemental_analyses['sample_id'] == 6940])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lab_sample_id</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>EG</th>\n",
       "      <th>thick_clay</th>\n",
       "      <th>fine_clay</th>\n",
       "      <th>silt</th>\n",
       "      <th>clay</th>\n",
       "      <th>Eq_Hum</th>\n",
       "      <th>atm_1/3</th>\n",
       "      <th>atm_15</th>\n",
       "      <th>...</th>\n",
       "      <th>Ta</th>\n",
       "      <th>W</th>\n",
       "      <th>Pt</th>\n",
       "      <th>Au</th>\n",
       "      <th>Hg</th>\n",
       "      <th>Tl</th>\n",
       "      <th>Pb</th>\n",
       "      <th>Bi</th>\n",
       "      <th>Th</th>\n",
       "      <th>U</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10999.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.700001</td>\n",
       "      <td>32.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.799999</td>\n",
       "      <td>35.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>11.4</td>\n",
       "      <td>6.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>11001.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.500000</td>\n",
       "      <td>46.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>11.1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>11002.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.599998</td>\n",
       "      <td>41.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>15.4</td>\n",
       "      <td>5.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>11003.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.799999</td>\n",
       "      <td>47.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>14.5</td>\n",
       "      <td>7.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   lab_sample_id  sample_id  EG  thick_clay  fine_clay  silt  clay  Eq_Hum  \\\n",
       "0              1    10999.0 NaN   61.700001       32.8   0.2   5.3     4.6   \n",
       "1              2    11000.0 NaN   52.799999       35.1   0.7  11.4     6.4   \n",
       "2              3    11001.0 NaN   42.500000       46.2   0.2  11.1     6.3   \n",
       "3              4    11002.0 NaN   42.599998       41.8   0.2  15.4     5.2   \n",
       "4              5    11003.0 NaN   36.799999       47.5   1.2  14.5     7.3   \n",
       "\n",
       "   atm_1/3  atm_15  ...  Ta   W  Pt  Au  Hg  Tl  Pb  Bi  Th   U  \n",
       "0      NaN     NaN  ... NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "1      NaN     NaN  ... NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "2      NaN     NaN  ... NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "3      NaN     NaN  ... NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "4      NaN     NaN  ... NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types of each column in merged1:\n",
      "\n",
      "lab_sample_id      int64\n",
      "sample_id        float64\n",
      "EG               float64\n",
      "thick_clay       float64\n",
      "fine_clay        float64\n",
      "                  ...   \n",
      "Tl               float64\n",
      "Pb               float64\n",
      "Bi               float64\n",
      "Th               float64\n",
      "U                float64\n",
      "Length: 68, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Define final column list\n",
    "final_columns = [\n",
    "    'lab_sample_id', 'sample_id', 'EG', 'thick_clay', 'fine_clay', 'silt', 'clay', 'Eq_Hum', 'atm_1/3', 'atm_15',\n",
    "    'CACO3', 'gypsum', 'free_iron', 'organic_carbon', 'total_N', 'P205', 'organic_material', 'pH_H2O', 'pH_KCL',\n",
    "    'Ca++', 'Mg++', 'Na+', 'K+', 'exchangable_bases_sum', 'CEC', 'V', 'conductivity', 'soluble_sodium', 'Min_<0,002',\n",
    "    'Min_0,05-0,02', 'Min_0,2-0,05', 'Min_2-0,2', \n",
    "    'field_sample_code', 'Depth', 'Al', 'Si', 'P', 'S', 'Cl', 'Ti', 'Cr', 'Mn', 'Fe', 'Co', 'Ni', 'Cu', 'Zn',\n",
    "    'As', 'Se', 'Rb', 'Sr', 'Zr', 'Nb', 'Mo', 'Cd', 'Sn', 'Sb', 'Ba', 'Ta', 'W', 'Pt', 'Au', 'Hg', 'Tl', 'Pb', 'Bi',\n",
    "    'Th', 'U',\n",
    "]\n",
    "\n",
    "# Ensure all columns exist in the DataFrame\n",
    "for col in final_columns:\n",
    "    if col not in merged1.columns:\n",
    "        merged1[col] = pd.NA  # or np.nan if preferred\n",
    "\n",
    "# Reorder DataFrame columns\n",
    "merged1 = merged1[final_columns]\n",
    "\n",
    "# Check and print the datatypes of each column\n",
    "print(\"Data types of each column in merged1:\\n\")\n",
    "print(merged1.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged1.to_csv(\"/Users/inesschwartz/Desktop/Thesis/tables_clean/analyses_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### soil profile table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  profile_id grouping    REF province country  \\\n",
      "0       1/51     H 62   62.0    Huíla  Angola   \n",
      "1       1/57      M 9    9.0   Namibe  Angola   \n",
      "2       1/59    Cb 52   52.0  Cabinda  Angola   \n",
      "3       1/63   Mj 116  116.0  Malanje  Angola   \n",
      "4      10/54    H 59'   59.0    Huíla  Angola   \n",
      "\n",
      "                                               LOCAL  \\\n",
      "0  Estrada Sá da Bandeira - Quijungo a 58,8 km do...   \n",
      "1  Estrada Moçamedes-Porto Alexandre, a 0,2 km de...   \n",
      "2  Estrada Buco Zau-Dinge, no cruzamento com o se...   \n",
      "3                           A 0,7 km a S-SW de Quela   \n",
      "4  Picada que parte da estrada Vila Paiva Couceir...   \n",
      "\n",
      "                 DESCRITOR1            DESCRITOR2             DESCRITOR3  \\\n",
      "0    J. V. Botelho da Costa      R. Pinto Ricardo                     AA   \n",
      "1           E. M. S. Câmara      R. Pinto Ricardo                    NaN   \n",
      "2           E. M. S. Câmara      R. Pinto Ricardo  J. A. Castanho Póvoas   \n",
      "3  F. A. Milho da Conceição        J. F. R. Matos       R. Pinto Ricardo   \n",
      "4          R. Pinto Ricardo  E. P. Cardoso Franco                    NaN   \n",
      "\n",
      "        date           CEP_GR  \\\n",
      "0 1951-08-14              NaN   \n",
      "1 1957-06-26         Arídicos   \n",
      "2 1959-07-07  Psamoferrálicos   \n",
      "3 1963-06-25     Ferralíticos   \n",
      "4 1954-07-22     Ferralíticos   \n",
      "\n",
      "                                            CEP_NAME   FAO Fase D_INSERÇAO  \\\n",
      "0                                                NaN   NaN  NaN 2007-10-16   \n",
      "1              Arídicos com calcário Pardo-cinzentos  CLha  NaN 2007-10-09   \n",
      "2  Psamo-ferrálicos Amarelos ou Alaranjados, sedi...  FRxa  NaN 2010-03-08   \n",
      "3  Fracamente Ferrálicos Vermelhos Clino-argílico...   FRh  NaN 2009-01-07   \n",
      "4             Fracamente Ferrálicos pardo-amarelados   FRh  NaN 2007-10-15   \n",
      "\n",
      "                                          Publicação                 WRB_old  \\\n",
      "0                                                NaN                     NaN   \n",
      "1                                                NaN  Areni-Haplic Calcisols   \n",
      "2  Carta Geral dos Solos de Angola - Provincia de...                     NaN   \n",
      "3  Carta Geral dos Solos de Angola - Provincia de...                     NaN   \n",
      "4                                                NaN                     NaN   \n",
      "\n",
      "   Missão  \n",
      "0     NaN  \n",
      "1     NaN  \n",
      "2     NaN  \n",
      "3     NaN  \n",
      "4     NaN  \n"
     ]
    }
   ],
   "source": [
    "## rename columns\n",
    "soil_profile = pd.read_excel(\"/Users/inesschwartz/Desktop/Thesis/tables_soil_database/Perfis_solo.xlsx\")\n",
    "\n",
    "#rename columns\n",
    "soil_profile.rename(columns={\n",
    "    'Perfil': 'profile_id',\n",
    "    'Agrupamento': 'grouping',\n",
    "    'Pro': 'province',\n",
    "    'País': 'country',\n",
    "    'Local': 'location',\n",
    "    'DATA': 'date',\n",
    "    'CEP_NOME': 'CEP_NAME',\n",
    "}, inplace=True)\n",
    "\n",
    "# Show first few rows\n",
    "print(soil_profile.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>profile_id</th>\n",
       "      <th>site_info_id</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>soil_type_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/51</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/57</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/59</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/63</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/54</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  profile_id site_info_id sample_id soil_type_id\n",
       "0       1/51         <NA>      <NA>         <NA>\n",
       "1       1/57         <NA>      <NA>         <NA>\n",
       "2       1/59         <NA>      <NA>         <NA>\n",
       "3       1/63         <NA>      <NA>         <NA>\n",
       "4      10/54         <NA>      <NA>         <NA>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop unnecessary columns\n",
    "soil_profile_cleaning1 = soil_profile.drop(columns=[\n",
    "    'grouping', 'REF', 'province', 'country', 'LOCAL', 'DESCRITOR1', 'DESCRITOR2', 'DESCRITOR3', 'CEP_GR'\n",
    "])\n",
    "\n",
    "\n",
    "soil_profile_cleaning2 = soil_profile.drop(columns=[\n",
    "    'grouping', 'REF', 'province', 'country', 'LOCAL', 'DESCRITOR1', 'DESCRITOR2', 'DESCRITOR3', 'date', 'CEP_GR'\n",
    "])\n",
    "# Add missing columns\n",
    "soil_profile_cleaning2['site_info_id'] = pd.NA\n",
    "soil_profile_cleaning2['sample_id'] = pd.NA \n",
    "soil_profile_cleaning2['soil_type_id'] = pd.NA  \n",
    "\n",
    "soil_profile_cleaning2['site_info_id'] = soil_profile_cleaning2['site_info_id'].astype(str)\n",
    "\n",
    "\n",
    "\n",
    "# Reorder columns to match SAMPLES schema\n",
    "profile_clean = soil_profile_cleaning2[[\n",
    "    'profile_id',\n",
    "    'site_info_id',\n",
    "    'sample_id',\n",
    "    'soil_type_id'\n",
    "]]\n",
    "\n",
    "# Preview the result\n",
    "profile_clean.head()\n",
    "#profile_clean.to_csv(\"/Users/inesschwartz/Desktop/Thesis/tables_clean/profile_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>profile_id</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/51</td>\n",
       "      <td>1951-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/57</td>\n",
       "      <td>1957-06-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/59</td>\n",
       "      <td>1959-07-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/63</td>\n",
       "      <td>1963-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/54</td>\n",
       "      <td>1954-07-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  profile_id       date\n",
       "0       1/51 1951-08-14\n",
       "1       1/57 1957-06-26\n",
       "2       1/59 1959-07-07\n",
       "3       1/63 1963-06-25\n",
       "4      10/54 1954-07-22"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soil_profile_cleaning1 = soil_profile_cleaning1[[\n",
    "    'profile_id',\n",
    "    'date'\n",
    "]]\n",
    "\n",
    "soil_profile_cleaning1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types of each column in profile_clean:\n",
      "\n",
      "profile_id      object\n",
      "site_info_id    object\n",
      "sample_id       object\n",
      "soil_type_id    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check and print the datatypes of each column\n",
    "print(\"Data types of each column in profile_clean:\\n\")\n",
    "print(profile_clean.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Morphology Horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "## rename columns\n",
    "#rename columns\n",
    "morphology.rename(columns={\n",
    "    'Morfo_id':'horizon_id',\n",
    "    'Amostra': 'sample_id',\n",
    "    'Perfil': 'profile_id',\n",
    "    'CM':'horizon_layer',\n",
    "    'Limite Superior': 'upper_depth',\n",
    "    'Limite inferior': 'lower_depth',\n",
    "    'Grau de humidade': 'moisture_degree',\n",
    "    'Quantidade de raízes': 'root_quantity',\n",
    "    'Diâmetro de raízes': 'root_diameter',\n",
    "    'Textura': 'texture',\n",
    "    'Tipo de estrutura': 'structure_type',\n",
    "    'Classes de estrutura': 'structure_class',\n",
    "    'Grau de estrutura': 'structure_degree',\n",
    "    'Diâmetro de poros': 'pore_diameter',\n",
    "    'Quantidade de poros': 'pore_quantity',\n",
    "    'Forma de poros': 'pore_shape',\n",
    "    'Cor (s)': 'dry_color_name',\n",
    "    'Matiz (s)': 'dry_hue',\n",
    "    'Valor (s)':'dry_value',\n",
    "    'Croma (s)': 'dry_chroma',\n",
    "    'Cor (h)': 'moist_color_name',\n",
    "    'Matiz (h)': 'moist_hue',\n",
    "    'Valor (h)': 'moist_value',\n",
    "    'Croma (h)': 'moist_chroma',\n",
    "    'Compacidade':'compaction',\n",
    "    'Dureza': 'durability'\n",
    "}, inplace=True)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "morphology_cleaning = morphology.drop(columns=[\n",
    "    'ID1', 'Agrupamento', 'REF', 'Pro', 'Observaçoes', 'Horizonte de diagnóstico', 'Propriedade de diagnóstico', 'Nitidez do limite', 'Designação do horizonte', 'Observaçoes', 'Confirmar', 'Adesividade', 'Plasticidade', 'Efervescência com HCl', 'Friabilidade', 'Orientação das Fendas', 'Largura das fendas', 'Quantidade de fendas'\n",
    "])\n",
    "\n",
    "\n",
    "#drop accents\n",
    "import unicodedata\n",
    "def remove_accents(text):\n",
    "    if isinstance(text, str):\n",
    "        # Normalize and remove diacritics\n",
    "        text = unicodedata.normalize('NFKD', text)\n",
    "        text = ''.join(c for c in text if not unicodedata.combining(c))\n",
    "        return text\n",
    "    return text\n",
    "\n",
    "# Apply to all cells in the DataFrame\n",
    "morphology_cleaning = morphology_cleaning.applymap(remove_accents)\n",
    "\n",
    "morphology_cleaning = morphology_cleaning.fillna('null')\n",
    "\n",
    "\n",
    "\n",
    "# Reorder columns to match SAMPLES schema\n",
    "morphology_clean = morphology_cleaning[[\n",
    "    'horizon_id',\n",
    "    'sample_id',\n",
    "    'profile_id',\n",
    "    'horizon_layer',\n",
    "    'upper_depth',\n",
    "    'lower_depth',\n",
    "    'moisture_degree',\n",
    "    'root_quantity',\n",
    "    'root_diameter',\n",
    "    'texture',\n",
    "    'structure_type',\n",
    "    'structure_class',\n",
    "    'structure_degree',\n",
    "    'pore_diameter',\n",
    "    'pore_quantity',\n",
    "    'pore_shape',\n",
    "    'dry_color_name',\n",
    "    'dry_hue',\n",
    "    'dry_value',\n",
    "    'dry_chroma',\n",
    "    'moist_color_name',\n",
    "    'moist_hue',\n",
    "    'moist_value',\n",
    "    'moist_chroma',\n",
    "    'compaction',\n",
    "    'durability'\n",
    "]]\n",
    "\n",
    "#morphology_clean.head()\n",
    "#morphology_clean.to_csv(\"/Users/inesschwartz/Desktop/Thesis/tables_clean/morphology_horizon_clean.csv\", index=False)\n",
    "\n",
    "# Show first few rows\n",
    "morphology_cleaning.head()\n",
    "morphology_clean.head(15)\n",
    "\n",
    "morphology_clean.to_csv(\"/Users/inesschwartz/Desktop/Thesis/tables_clean/morphology_horizon_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types of each column in profile_clean:\n",
      "\n",
      "horizon_id          object\n",
      "sample_id           object\n",
      "profile_id          object\n",
      "horizon_layer       object\n",
      "upper_depth         object\n",
      "lower_depth         object\n",
      "moisture_degree     object\n",
      "root_quantity       object\n",
      "root_diameter       object\n",
      "texture             object\n",
      "structure_type      object\n",
      "structure_class     object\n",
      "structure_degree    object\n",
      "pore_diameter       object\n",
      "pore_quantity       object\n",
      "pore_shape          object\n",
      "dry_color_name      object\n",
      "dry_hue             object\n",
      "dry_value           object\n",
      "dry_chroma          object\n",
      "moist_color_name    object\n",
      "moist_hue           object\n",
      "moist_value         object\n",
      "moist_chroma        object\n",
      "compaction          object\n",
      "durability          object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check and print the datatypes of each column\n",
    "print(\"Data types of each column in profile_clean:\\n\")\n",
    "print(morphology_clean.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soil type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns\n",
    "#rename columns\n",
    "soil_type = soil_profile\n",
    "\n",
    "soil_type.rename(columns={\n",
    "    'Perfil': 'profile_id',\n",
    "    'Agrupamento': 'grouping',\n",
    "    'Pro': 'province',\n",
    "    'País': 'country',\n",
    "    'Local': 'location',\n",
    "    'DATA': 'date',\n",
    "    'CEP_NOME': 'CEP_NAME',\n",
    "}, inplace=True)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "soil_type_cleaning = soil_type.drop(columns=[\n",
    "    'REF', 'province', 'country', 'LOCAL', 'DESCRITOR1', 'DESCRITOR2', 'DESCRITOR3', 'date', 'Fase', 'D_INSERÇAO', 'Publicação', 'WRB_old', 'Missão'\n",
    "])\n",
    "# Add a new Primary Key ID column starting from 1\n",
    "soil_type_cleaning.insert(0, 'soil_type_id', range(1, len(soil_type_cleaning) + 1))\n",
    "\n",
    "#drop accents\n",
    "import unicodedata\n",
    "def remove_accents(text):\n",
    "    if isinstance(text, str):\n",
    "        # Normalize and remove diacritics\n",
    "        text = unicodedata.normalize('NFKD', text)\n",
    "        text = ''.join(c for c in text if not unicodedata.combining(c))\n",
    "        return text\n",
    "    return text\n",
    "\n",
    "# Apply to all cells in the DataFrame\n",
    "soil_type_cleaning = soil_type_cleaning.applymap(remove_accents)\n",
    "\n",
    "soil_type_cleaning.head()\n",
    "\n",
    "soil_type_clean = soil_type_cleaning\n",
    "soil_type_clean.to_csv(\"/Users/inesschwartz/Desktop/Thesis/tables_clean/soil_type_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types of each column in profile_clean:\n",
      "\n",
      "soil_type_id     int64\n",
      "profile_id      object\n",
      "grouping        object\n",
      "CEP_GR          object\n",
      "CEP_NAME        object\n",
      "FAO             object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check and print the datatypes of each column\n",
    "print(\"Data types of each column in profile_clean:\\n\")\n",
    "print(soil_type_clean.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Site_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>PERFIL</th>\n",
       "      <th>X_COORD</th>\n",
       "      <th>Y_COORD</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LTGRAUS</th>\n",
       "      <th>LTMIN</th>\n",
       "      <th>LTSEC</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>LGGRAUS</th>\n",
       "      <th>LGMIN</th>\n",
       "      <th>LGSEC</th>\n",
       "      <th>AGRUPAMENT</th>\n",
       "      <th>PRO</th>\n",
       "      <th>LOCAL</th>\n",
       "      <th>TOPOGRAFIA</th>\n",
       "      <th>ALTITUDE</th>\n",
       "      <th>GEOLOGIA</th>\n",
       "      <th>LITOLOGIA</th>\n",
       "      <th>LITOLOGIA_1954</th>\n",
       "      <th>CL_THORNTH</th>\n",
       "      <th>CL_KOPPEN</th>\n",
       "      <th>PMA</th>\n",
       "      <th>TMA</th>\n",
       "      <th>REG_HÍDRIC</th>\n",
       "      <th>REG_TÉRMIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2770</td>\n",
       "      <td>1/57</td>\n",
       "      <td>12.161278</td>\n",
       "      <td>-15.222598</td>\n",
       "      <td>-15,20108696</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>12,15307971</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>M  9</td>\n",
       "      <td>Namibe</td>\n",
       "      <td>Estrada Moçamedes-Porto Alexandre, a 0,2 km de...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>1/59</td>\n",
       "      <td>12.575775</td>\n",
       "      <td>-4.866986</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cb 52</td>\n",
       "      <td>Cabinda</td>\n",
       "      <td>Estrada Buco Zau-Dinge, no cruzamento com o se...</td>\n",
       "      <td>D5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Oendolongo</td>\n",
       "      <td>pp</td>\n",
       "      <td>Sistema do Maiombe</td>\n",
       "      <td>B1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1618</td>\n",
       "      <td>1/61</td>\n",
       "      <td>15.098840</td>\n",
       "      <td>-11.225411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cuanza Sul</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>881</td>\n",
       "      <td>1/63</td>\n",
       "      <td>17.081955</td>\n",
       "      <td>-9.274587</td>\n",
       "      <td>-9,27458667755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17,08195495605</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mj 116</td>\n",
       "      <td>Malanje</td>\n",
       "      <td>A 0,7 km a S-SW de Quela</td>\n",
       "      <td>D1</td>\n",
       "      <td>1210.0</td>\n",
       "      <td>Karroo</td>\n",
       "      <td>Cs/Cal</td>\n",
       "      <td>Série de Cassanje - T2'T1</td>\n",
       "      <td>B3</td>\n",
       "      <td>Aw</td>\n",
       "      <td>1400-1600</td>\n",
       "      <td>21-22</td>\n",
       "      <td>TUSu</td>\n",
       "      <td>iH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1750</td>\n",
       "      <td>1/64</td>\n",
       "      <td>20.788116</td>\n",
       "      <td>-11.568683</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moxico</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID PERFIL    X_COORD    Y_COORD        LATITUDE  LTGRAUS  LTMIN  LTSEC  \\\n",
       "0  2770   1/57  12.161278 -15.222598    -15,20108696    -15.0   12.0    3.9   \n",
       "1    48   1/59  12.575775  -4.866986             NaN      0.0    0.0    0.0   \n",
       "2  1618   1/61  15.098840 -11.225411             NaN      0.0    0.0    0.0   \n",
       "3   881   1/63  17.081955  -9.274587  -9,27458667755      0.0    0.0    0.0   \n",
       "4  1750   1/64  20.788116 -11.568683             NaN      0.0    0.0    0.0   \n",
       "\n",
       "        LONGITUDE  LGGRAUS  LGMIN  LGSEC AGRUPAMENT         PRO  \\\n",
       "0     12,15307971     12.0    9.0   11.1       M  9      Namibe   \n",
       "1             NaN      0.0    0.0    0.0      Cb 52     Cabinda   \n",
       "2             NaN      0.0    0.0    0.0        NaN  Cuanza Sul   \n",
       "3  17,08195495605      0.0    0.0    0.0     Mj 116     Malanje   \n",
       "4             NaN      0.0    0.0    0.0        NaN      Moxico   \n",
       "\n",
       "                                               LOCAL TOPOGRAFIA  ALTITUDE  \\\n",
       "0  Estrada Moçamedes-Porto Alexandre, a 0,2 km de...        NaN      32.0   \n",
       "1  Estrada Buco Zau-Dinge, no cruzamento com o se...         D5       NaN   \n",
       "2                                                NaN        NaN       NaN   \n",
       "3                           A 0,7 km a S-SW de Quela         D1    1210.0   \n",
       "4                                                NaN        NaN       NaN   \n",
       "\n",
       "     GEOLOGIA LITOLOGIA             LITOLOGIA_1954 CL_THORNTH CL_KOPPEN  \\\n",
       "0         NaN         d                        NaN          E       NaN   \n",
       "1  Oendolongo        pp         Sistema do Maiombe         B1       NaN   \n",
       "2         NaN       NaN                        NaN        NaN       NaN   \n",
       "3      Karroo    Cs/Cal  Série de Cassanje - T2'T1         B3        Aw   \n",
       "4         NaN       NaN                        NaN        NaN       NaN   \n",
       "\n",
       "         PMA    TMA REG_HÍDRIC REG_TÉRMIC  \n",
       "0        NaN    NaN        NaN        NaN  \n",
       "1        NaN    NaN        NaN        NaN  \n",
       "2        NaN    NaN        NaN        NaN  \n",
       "3  1400-1600  21-22       TUSu         iH  \n",
       "4        NaN    NaN        NaN        NaN  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile_loc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_info_id</th>\n",
       "      <th>profile_id</th>\n",
       "      <th>X_coord</th>\n",
       "      <th>Y_coord</th>\n",
       "      <th>land_cover_id</th>\n",
       "      <th>climate_id</th>\n",
       "      <th>geology_id</th>\n",
       "      <th>topo_feature_id</th>\n",
       "      <th>sampling_date</th>\n",
       "      <th>districts_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1/57</td>\n",
       "      <td>12.161278</td>\n",
       "      <td>-15.222598</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1/59</td>\n",
       "      <td>12.575775</td>\n",
       "      <td>-4.866986</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1/61</td>\n",
       "      <td>15.098840</td>\n",
       "      <td>-11.225411</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1/63</td>\n",
       "      <td>17.081955</td>\n",
       "      <td>-9.274587</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1/64</td>\n",
       "      <td>20.788116</td>\n",
       "      <td>-11.568683</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   site_info_id profile_id    X_coord    Y_coord land_cover_id climate_id  \\\n",
       "0             1       1/57  12.161278 -15.222598          <NA>       <NA>   \n",
       "1             2       1/59  12.575775  -4.866986          <NA>       <NA>   \n",
       "2             3       1/61  15.098840 -11.225411          <NA>       <NA>   \n",
       "3             4       1/63  17.081955  -9.274587          <NA>       <NA>   \n",
       "4             5       1/64  20.788116 -11.568683          <NA>       <NA>   \n",
       "\n",
       "  geology_id topo_feature_id sampling_date districts_id  \n",
       "0       <NA>            <NA>          <NA>         <NA>  \n",
       "1       <NA>            <NA>          <NA>         <NA>  \n",
       "2       <NA>            <NA>          <NA>         <NA>  \n",
       "3       <NA>            <NA>          <NA>         <NA>  \n",
       "4       <NA>            <NA>          <NA>         <NA>  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "site_info_cleaning = profile_loc\n",
    "\n",
    "site_info_cleaning.rename(columns={\n",
    "    'PERFIL': 'profile_id',\n",
    "    'X_COORD': 'X_coord',\n",
    "    'Y_COORD': 'Y_coord'\n",
    "}, inplace=True)\n",
    "\n",
    "# Add a new Primary Key ID column starting from 1\n",
    "site_info_cleaning.insert(0, 'site_info_id', range(1, len(site_info_cleaning) + 1))\n",
    "\n",
    "\n",
    "# Add missing columns\n",
    "site_info_cleaning['land_cover_id'] = pd.NA\n",
    "site_info_cleaning['climate_id'] = pd.NA  \n",
    "site_info_cleaning['geology_id'] = pd.NA\n",
    "site_info_cleaning['topo_feature_id'] = pd.NA  \n",
    "site_info_cleaning['sampling_date'] = pd.NA\n",
    "site_info_cleaning['districts_id'] = pd.NA  \n",
    "\n",
    "\n",
    "site_info_clean = site_info_cleaning[[\n",
    "    'site_info_id',\n",
    "    'profile_id', ##do I add profile ID here to then try to merge date info from soil Perfis_solo table? or is this too complicated?\n",
    "    'X_coord',\n",
    "    'Y_coord',\n",
    "    'land_cover_id',\n",
    "    'climate_id',\n",
    "    'geology_id',\n",
    "    'topo_feature_id',\n",
    "    'sampling_date',\n",
    "    'districts_id'\n",
    "]]\n",
    "\n",
    "site_info_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "##merging date info from perfis_solo to site_info table\n",
    "\n",
    "merged = soil_profile_cleaning1.merge(site_info_clean, on='profile_id', how='left')\n",
    "\n",
    "merged['site_info_id'] = merged['site_info_id'].astype(str)\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "merged.head()\n",
    "\n",
    "merged.to_csv(\"/Users/inesschwartz/Desktop/Thesis/tables_clean/site_info_clean.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types of each column in profile_clean:\n",
      "\n",
      "profile_id                 object\n",
      "date               datetime64[ns]\n",
      "site_info_id               object\n",
      "X_coord                   float64\n",
      "Y_coord                   float64\n",
      "land_cover_id              object\n",
      "climate_id                 object\n",
      "geology_id                 object\n",
      "topo_feature_id            object\n",
      "sampling_date              object\n",
      "districts_id               object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check and print the datatypes of each column\n",
    "print(\"Data types of each column in profile_clean:\\n\")\n",
    "print(merged.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Climate table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original Excel data\n",
    "profile_loc = pd.read_excel(\"/Users/inesschwartz/Desktop/Thesis/tables_soil_database/Perfis_local.xlsx\")\n",
    "\n",
    "# Create a copy for cleaning\n",
    "climate_features_cleaning = profile_loc.copy()\n",
    "\n",
    "# Mapping from climate codes to descriptions\n",
    "code_to_description = {\n",
    "    \"B1\": \"Húmido\",\n",
    "    \"B2\": \"Húmido\",\n",
    "    \"B3\": \"Húmido\",\n",
    "    \"B4\": \"Húmido\",\n",
    "    \"C1\": \"Sub-húmido seco\",\n",
    "    \"C2\": \"Sub-húmido chuvoso\",\n",
    "    \"D\": \"Semi-árido\",\n",
    "    \"E\": \"Árido\",\n",
    "    \"Aw\": \"Tropical chuvoso com estação seca no Inverno, de savana\",\n",
    "    \"BSw\": \"Seco de estepe, com chuva predominante no Verão\",\n",
    "    \"BWw\": \"Seco de deserto, com chuva predominante no Verão\",\n",
    "    \"Cw\": \"Mesotérmico húmido com estação seca no Inverno\",\n",
    "    \"ARe\": \"Arídico extremo\",\n",
    "    \"ARf\": \"Arídico fraco\",\n",
    "    \"ARt\": \"Arídico típico\",\n",
    "    \"tUDs\": \"Tempúdico seco\",\n",
    "    \"tUSh\": \"Tempústico húmido\",\n",
    "    \"tUSt\": \"Tempústico típico\",\n",
    "    \"TUDs\": \"Tropúdico seco\",\n",
    "    \"TUSa\": \"Tropústico arídico\",\n",
    "    \"TUSu\": \"Tropústico údico\",\n",
    "    \"TUSt\": \"Tropustico típico\",\n",
    "    \"H\": \"Hipertérmico\",\n",
    "    \"iH\": \"Iso-Hipertérmico\",\n",
    "    \"iT\": \"Iso-Térmico\",\n",
    "    \"T\": \"Térmico\"\n",
    "}\n",
    "\n",
    "\n",
    "# Replace climate codes with descriptions directly in the two columns\n",
    "climate_features_cleaning[\"CL_THORNTH\"] = climate_features_cleaning[\"CL_THORNTH\"].replace(code_to_description)\n",
    "climate_features_cleaning[\"CL_KOPPEN\"] = climate_features_cleaning[\"CL_KOPPEN\"].replace(code_to_description)\n",
    "climate_features_cleaning[\"REG_HÍDRIC\"] = climate_features_cleaning[\"REG_HÍDRIC\"].replace(code_to_description)\n",
    "climate_features_cleaning[\"REG_TÉRMIC\"] = climate_features_cleaning[\"REG_TÉRMIC\"].replace(code_to_description)\n",
    "\n",
    "# Rename columns for clarity\n",
    "climate_features_cleaning.rename(columns={\n",
    "    'PERFIL': 'profile_id',\n",
    "    'CL_THORNTH': 'thornthwaite_climate',\n",
    "    'CL_KOPPEN': 'koppen_climate',\n",
    "    'TMA': 'mean_annual_temp',\n",
    "    'PMA': 'mean_annual_precip',\n",
    "    'REG_HÍDRIC': 'hydric_regime',\n",
    "    'REG_TÉRMIC': 'thermal_regime'\n",
    "}, inplace=True)\n",
    "\n",
    "# Add primary key column\n",
    "climate_features_cleaning.insert(0, 'climate_id', range(1, len(climate_features_cleaning) + 1))\n",
    "\n",
    "# Select and reorder relevant columns\n",
    "climate_features_clean = climate_features_cleaning[[\n",
    "    'climate_id',\n",
    "    'profile_id',  # Yes, keep this to allow merging with soil profile data later\n",
    "    'mean_annual_temp',\n",
    "    'mean_annual_precip',\n",
    "    'koppen_climate',\n",
    "    'thornthwaite_climate',\n",
    "    'hydric_regime',\n",
    "    'thermal_regime'\n",
    "]]\n",
    "\n",
    "#drop accents\n",
    "import unicodedata\n",
    "def remove_accents(text):\n",
    "    if isinstance(text, str):\n",
    "        # Normalize and remove diacritics\n",
    "        text = unicodedata.normalize('NFKD', text)\n",
    "        text = ''.join(c for c in text if not unicodedata.combining(c))\n",
    "        return text\n",
    "    return text\n",
    "\n",
    "# Apply to all cells in the DataFrame\n",
    "climate_features_cleaning = climate_features_cleaning.applymap(remove_accents)\n",
    "\n",
    "# Preview\n",
    "climate_features_clean.head()\n",
    "climate_features_clean.to_csv(\"/Users/inesschwartz/Desktop/Thesis/tables_clean/climate_features_clean.csv\", index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types of each column in profile_clean:\n",
      "\n",
      "climate_id               int64\n",
      "profile_id              object\n",
      "mean_annual_temp        object\n",
      "mean_annual_precip      object\n",
      "koppen_climate          object\n",
      "thornthwaite_climate    object\n",
      "hydric_regime           object\n",
      "thermal_regime          object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check and print the datatypes of each column\n",
    "print(\"Data types of each column in profile_clean:\\n\")\n",
    "print(climate_features_clean.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topographic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topo_features_id</th>\n",
       "      <th>profile_id</th>\n",
       "      <th>slope_code</th>\n",
       "      <th>altitude</th>\n",
       "      <th>aspect</th>\n",
       "      <th>land_surface_temp</th>\n",
       "      <th>dem_elevation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1/57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1/59</td>\n",
       "      <td>D5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1/61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1/63</td>\n",
       "      <td>D1</td>\n",
       "      <td>1210.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1/64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topo_features_id profile_id slope_code  altitude aspect land_surface_temp  \\\n",
       "0                 1       1/57        NaN      32.0   <NA>              <NA>   \n",
       "1                 2       1/59         D5       NaN   <NA>              <NA>   \n",
       "2                 3       1/61        NaN       NaN   <NA>              <NA>   \n",
       "3                 4       1/63         D1    1210.0   <NA>              <NA>   \n",
       "4                 5       1/64        NaN       NaN   <NA>              <NA>   \n",
       "\n",
       "  dem_elevation  \n",
       "0          <NA>  \n",
       "1          <NA>  \n",
       "2          <NA>  \n",
       "3          <NA>  \n",
       "4          <NA>  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load original Excel data\n",
    "profile_loc = pd.read_excel(\"/Users/inesschwartz/Desktop/Thesis/tables_soil_database/Perfis_local.xlsx\")\n",
    "\n",
    "# Create a copy for cleaning\n",
    "topo_features_cleaning = profile_loc.copy()\n",
    "\n",
    "# Rename columns for clarity\n",
    "topo_features_cleaning.rename(columns={\n",
    "    'PERFIL': 'profile_id',\n",
    "    'TOPOGRAFIA': 'slope_code',\n",
    "    'ALTITUDE': 'altitude',\n",
    "}, inplace=True)\n",
    "\n",
    "# Add missing columns\n",
    "topo_features_cleaning['aspect'] = pd.NA  \n",
    "topo_features_cleaning['land_surface_temp'] = pd.NA\n",
    "topo_features_cleaning['dem_elevation'] = pd.NA  \n",
    "\n",
    "# Add primary key column\n",
    "topo_features_cleaning.insert(0, 'topo_features_id', range(1, len(topo_features_cleaning) + 1))\n",
    "\n",
    "# Create slope class mapping dictionary\n",
    "slope_code_to_description = {\n",
    "    \"D1\": \"Plano (Declives < 2%)\",\n",
    "    \"D2\": \"Ondulado muito suave (Declives > 2% e < 3%)\",\n",
    "    \"D3\": \"Ondulado suave (Declives > 3% e < 5%)\",\n",
    "    \"D4\": \"Ondulado (Declives > 5% e < 8%)\",\n",
    "    \"D5\": \"Acidentado (Declives > 8% e < 15%)\",\n",
    "    \"D6\": \"Escarpado (Declives >15% e < 30%)\",\n",
    "    \"D7\": \"Montanhoso (Declives > 30%)\"\n",
    "}\n",
    "\n",
    "# Create a mapping DataFrame for slope classes\n",
    "slope_classes_df = pd.DataFrame([\n",
    "    {\"slope_code\": code, \"slope_description\": desc}\n",
    "    for code, desc in slope_code_to_description.items()\n",
    "])\n",
    "\n",
    "# Save mapping table to CSV\n",
    "slope_classes_df.to_csv(\"/Users/inesschwartz/Desktop/Thesis/tables_clean/slope_classes_mapping.csv\", index=False)\n",
    "\n",
    "# Final cleaned topo features table (referencing slope_code, not description)\n",
    "topo_features_clean = topo_features_cleaning[[\n",
    "    'topo_features_id',\n",
    "    'profile_id', \n",
    "    'slope_code',\n",
    "    'altitude',\n",
    "    'aspect',\n",
    "    'land_surface_temp',\n",
    "    'dem_elevation'\n",
    "]]\n",
    "\n",
    "# Save cleaned topo features table\n",
    "topo_features_clean.to_csv(\"/Users/inesschwartz/Desktop/Thesis/tables_clean/topo_features_clean.csv\", index=False)\n",
    "\n",
    "# Preview\n",
    "topo_features_clean.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types of each column in profile_clean:\n",
      "\n",
      "topo_features_id       int64\n",
      "profile_id            object\n",
      "slope_code            object\n",
      "altitude             float64\n",
      "aspect                object\n",
      "land_surface_temp     object\n",
      "dem_elevation         object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check and print the datatypes of each column\n",
    "print(\"Data types of each column in profile_clean:\\n\")\n",
    "print(topo_features_clean.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geological Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_features_id</th>\n",
       "      <th>profile_id</th>\n",
       "      <th>geology_id</th>\n",
       "      <th>lithology_id</th>\n",
       "      <th>lithology_1954_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1/57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1/59</td>\n",
       "      <td>Oendolongo</td>\n",
       "      <td>pp</td>\n",
       "      <td>Sistema do Maiombe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1/61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1/63</td>\n",
       "      <td>Karroo</td>\n",
       "      <td>Cs/Cal</td>\n",
       "      <td>Série de Cassanje - T2'T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1/64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   geo_features_id profile_id  geology_id lithology_id  \\\n",
       "0                1       1/57         NaN            d   \n",
       "1                2       1/59  Oendolongo           pp   \n",
       "2                3       1/61         NaN          NaN   \n",
       "3                4       1/63      Karroo       Cs/Cal   \n",
       "4                5       1/64         NaN          NaN   \n",
       "\n",
       "           lithology_1954_id  \n",
       "0                        NaN  \n",
       "1         Sistema do Maiombe  \n",
       "2                        NaN  \n",
       "3  Série de Cassanje - T2'T1  \n",
       "4                        NaN  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load cleaned geo features data\n",
    "geo_features_cleaning = pd.read_excel(\"/Users/inesschwartz/Desktop/Thesis/tables_soil_database/Perfis_local.xlsx\")\n",
    "\n",
    "# Rename columns\n",
    "geo_features_cleaning.rename(columns={\n",
    "    'PERFIL': 'profile_id',\n",
    "    'GEOLOGIA': 'geology_id',\n",
    "    'LITOLOGIA': 'lithology_id',\n",
    "    'LITOLOGIA_1954': 'lithology_1954_id',\n",
    "}, inplace=True)\n",
    "\n",
    "# Add primary key column\n",
    "geo_features_cleaning.insert(0, 'geo_features_id', range(1, len(geo_features_cleaning) + 1))\n",
    "\n",
    "# Final normalized geo_features table (with codes as foreign keys)\n",
    "geo_features_clean = geo_features_cleaning[[\n",
    "    'geo_features_id',\n",
    "    'profile_id',\n",
    "    'geology_id',\n",
    "    'lithology_id',\n",
    "    'lithology_1954_id'\n",
    "]]\n",
    "\n",
    "# Save the cleaned table\n",
    "geo_features_clean.to_csv(\"/Users/inesschwartz/Desktop/Thesis/tables_clean/geo_features_clean.csv\", index=False)\n",
    "\n",
    "#preview\n",
    "geo_features_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "## mapping tables\n",
    "# Mappings for geology\n",
    "geology_mapping = {\n",
    "    \"Kalahari\": \"Sistema do Kalahari\",\n",
    "    \"Superficiais\": \"Formações Superficiais\",\n",
    "    \"Karroo\": \"Sistema do Karroo\",\n",
    "    \"Bembe\": \"Sistema do Bembe\",\n",
    "    \"Oendolongo\": \"Sistema do Oendolongo\",\n",
    "    \"Base\": \"Complexo de base\",\n",
    "    \"Proterozóico\": \"Proterozóico\",\n",
    "    \"Pleistocénico\": \"Pleistocénico\",\n",
    "    \"Terciário\": \"Terciário (médio e inferior)\",\n",
    "    \"TQ\": \"Quaternário e Terciário superior\",\n",
    "    \"Cretácio\": \"\",  # no description provided\n",
    "    \"RPKS\": \"Recente Plistocénico e Kalahari Superior\"\n",
    "}\n",
    "\n",
    "# Mappings for lithology_1954\n",
    "lithology_1954_mapping = {\n",
    "    \"γ\": \"Granitos, Granodioritos e Quartzodioritos\",\n",
    "    \"PL\": \"Xistos, metaquartzitos, conglomerados, arcoses, ect.\",\n",
    "    \"λ\": \"Rochas eruptivas indeterminadas\",\n",
    "    \"δp\": \"Doleritos, doleritos pigeoníticos\",\n",
    "    \"δab\": \"Diabases, diabases albito-cloriticas\",\n",
    "    \"ε\": \"Noritos, gabros e peridotitos\",\n",
    "    \"JK\": \"Composto de conglomerados, areias, cascalhos do Kalahari\",\n",
    "    \"C\": \"Série Xisto - calcária\",\n",
    "    \"Cal\": \"Sedimentos arenosos não consolidados\",\n",
    "    \"K\": \"Série xisto - gresosa\",\n",
    "    \"RT\": \"Não diferenciado\",\n",
    "    \"σ\": \"Sienitos, sienitos nefelínicos\",\n",
    "    \"Q\": \"Depósitos fossilíferos\",\n",
    "    \"CS\": \"Grande conglomerado e série de Mwashya\"\n",
    "}\n",
    "\n",
    "# Mappings for lithology\n",
    "lithology_mapping = {\n",
    "    \"a\": \"Rochas arenáceas consolidadas\",\n",
    "    \"aq\": \"Grés quartzíticos do Oendolongo\",\n",
    "    \"b\": \"Rochas eruptivas básicas\",\n",
    "    \"c\": \"Rochas sedimentares consolidadas calcárias\",\n",
    "    \"c'\": \"Rochas sedimentares não consolidadas calcárias\",\n",
    "    \"cg\": \"Rochas cristalofílicas argiláceas\",\n",
    "    \"d\": \"Sedimentos não consolidados de origem marinha\",\n",
    "    \"dc\": \"Depósitos coluvionares\",\n",
    "    \"dr\": \"Diorítos\",\n",
    "    \"e\": \"Rochas sedimentares consolidadas não calcárias\",\n",
    "    \"g\": \"Rochas argiláceas consolidadas não calcárias\",\n",
    "    \"g'\": \"Rochas argiláceas não consolidadas não calcárias\",\n",
    "    \"g''\": \"Rochas cristalinas pouco micas em quartzo\",\n",
    "    \"gp\": \"Rochas do  complexo gabro-plagioclastíco\",\n",
    "    \"k\": \"Sedimentos não consolidados grosseiros do Kalahari\",\n",
    "    \"m\": \"Rochas sedimentares não consolidadas calco-gipsíferas\",\n",
    "    \"m'\": \"Depósitos coluvionares margosos\",\n",
    "    \"mm\": \"Materiais mistos\",\n",
    "    \"n\": \"Sedimentos não consolidados de origem continental\",\n",
    "    \"nd\": \"não descrito\",\n",
    "    \"pp\": \"Sedimentos não consolidados grosseiros plio-plistocénicos\",\n",
    "    \"q\": \"Rochas cristalinas quartzíferas\",\n",
    "    \"q'\": \"Materiais redistribuídos provenientes de desagregação rochas crist. quartzíferas\",\n",
    "    \"qf\": \"Quartzitos ferruginosos do Oendolongo\",\n",
    "    \"r\": \"Sedimentos grosseiros não especificados\",\n",
    "    \"s\": \"Sienitos\",\n",
    "    \"sx\": \"Formações (ou rochas) sedimentares não especificadas\",\n",
    "    \"sx1\": \"Rochas sedimentares consolidadas com e sem calcário\",\n",
    "    \"sx2\": \"Rochas sedimentares consolidadas\",\n",
    "    \"v\": \"Materiais vulcânicos\",\n",
    "    \"v'\": \"Rochas do complexo alcalino e/ou carboatítico\",\n",
    "    \"x\": \"Rochas consolidadas não especificadas\",\n",
    "    \"xm\": \"Xistos metamórficos\",\n",
    "    \"xq\": \"Rochas cristalinas não especificadas\",\n",
    "    \"z\": \"Rochas metassedimentares\"\n",
    "}\n",
    "\n",
    "# Save each mapping as a DataFrame\n",
    "pd.DataFrame([\n",
    "    {\"geology_code\": k, \"geology_description\": v}\n",
    "    for k, v in geology_mapping.items()\n",
    "]).to_csv(\"/Users/inesschwartz/Desktop/Thesis/tables_clean/geology_mapping.csv\", index=False)\n",
    "\n",
    "pd.DataFrame([\n",
    "    {\"lithology_code\": k, \"lithology_description\": v}\n",
    "    for k, v in lithology_mapping.items()\n",
    "]).to_csv(\"/Users/inesschwartz/Desktop/Thesis/tables_clean/lithology_mapping.csv\", index=False)\n",
    "\n",
    "pd.DataFrame([\n",
    "    {\"lithology_1954_code\": k, \"lithology_1954_description\": v}\n",
    "    for k, v in lithology_1954_mapping.items()\n",
    "]).to_csv(\"/Users/inesschwartz/Desktop/Thesis/tables_clean/lithology1954_mapping.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types of each column in lithology_mapping:\n",
      "\n",
      "geo_features_id       int64\n",
      "profile_id           object\n",
      "geology_id           object\n",
      "lithology_id         object\n",
      "lithology_1954_id    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check and print the datatypes of each column\n",
    "print(\"Data types of each column in lithology_mapping:\\n\")\n",
    "print(geo_features_clean.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>site_info_id</th>\n",
       "      <th>year</th>\n",
       "      <th>profile_id</th>\n",
       "      <th>campaign</th>\n",
       "      <th>country</th>\n",
       "      <th>district</th>\n",
       "      <th>sample_sifted</th>\n",
       "      <th>Província</th>\n",
       "      <th>sample_not_sifted</th>\n",
       "      <th>shelf</th>\n",
       "      <th>room</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>630</td>\n",
       "      <td>172</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>139</td>\n",
       "      <td>MA/46</td>\n",
       "      <td>Angola</td>\n",
       "      <td>Huambo</td>\n",
       "      <td>X</td>\n",
       "      <td>Huambo</td>\n",
       "      <td>null</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>631</td>\n",
       "      <td>173</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>139</td>\n",
       "      <td>MA/46</td>\n",
       "      <td>Angola</td>\n",
       "      <td>Huambo</td>\n",
       "      <td>X</td>\n",
       "      <td>Huambo</td>\n",
       "      <td>null</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>632</td>\n",
       "      <td>174</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>139</td>\n",
       "      <td>MA/46</td>\n",
       "      <td>Angola</td>\n",
       "      <td>Huambo</td>\n",
       "      <td>X</td>\n",
       "      <td>Huambo</td>\n",
       "      <td>null</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>633</td>\n",
       "      <td>175</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>139</td>\n",
       "      <td>MA/46</td>\n",
       "      <td>Angola</td>\n",
       "      <td>Huambo</td>\n",
       "      <td>X</td>\n",
       "      <td>Huambo</td>\n",
       "      <td>null</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>687</td>\n",
       "      <td>1034</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>208</td>\n",
       "      <td>MA/46</td>\n",
       "      <td>Angola</td>\n",
       "      <td>Huambo</td>\n",
       "      <td>X</td>\n",
       "      <td>Huambo</td>\n",
       "      <td>null</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_id site_info_id    year profile_id campaign country district  \\\n",
       "0        630          172  1946.0        139    MA/46  Angola   Huambo   \n",
       "1        631          173  1946.0        139    MA/46  Angola   Huambo   \n",
       "2        632          174  1946.0        139    MA/46  Angola   Huambo   \n",
       "3        633          175  1946.0        139    MA/46  Angola   Huambo   \n",
       "4        687         1034  1946.0        208    MA/46  Angola   Huambo   \n",
       "\n",
       "  sample_sifted Província sample_not_sifted shelf room  \n",
       "0             X    Huambo              null     1   22  \n",
       "1             X    Huambo              null     1   22  \n",
       "2             X    Huambo              null     1   22  \n",
       "3             X    Huambo              null     1   22  \n",
       "4             X    Huambo              null     1   22  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_filled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tp/79mdnyy56_xc3g1jvp9wf4_80000gn/T/ipykernel_12211/3700924969.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  district_clean['sample_id'] = district_clean['sample_id'].astype(float)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>district_id</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>profile_id</th>\n",
       "      <th>district</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>630.0</td>\n",
       "      <td>139</td>\n",
       "      <td>Huambo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>631.0</td>\n",
       "      <td>139</td>\n",
       "      <td>Huambo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>632.0</td>\n",
       "      <td>139</td>\n",
       "      <td>Huambo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>633.0</td>\n",
       "      <td>139</td>\n",
       "      <td>Huambo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>687.0</td>\n",
       "      <td>208</td>\n",
       "      <td>Huambo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   district_id  sample_id profile_id district\n",
       "0            1      630.0        139   Huambo\n",
       "1            2      631.0        139   Huambo\n",
       "2            3      632.0        139   Huambo\n",
       "3            4      633.0        139   Huambo\n",
       "4            5      687.0        208   Huambo"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final normalized districts table (with codes as foreign keys)\n",
    "district_cleaning = samples\n",
    "\n",
    "# Add primary key column\n",
    "district_cleaning.insert(0, 'district_id', range(1, len(district_cleaning) + 1))\n",
    "\n",
    "district_clean = district_cleaning[[\n",
    "    'district_id',\n",
    "    'sample_id',\n",
    "    'profile_id',\n",
    "    'district'\n",
    "]]\n",
    "\n",
    "district_clean['sample_id'] = district_clean['sample_id'].astype(float)\n",
    "\n",
    "\n",
    "district_clean.to_csv(\"/Users/inesschwartz/Desktop/Thesis/tables_clean/district_clean.csv\", index=False)\n",
    "#preview:\n",
    "district_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minerology_info tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_features_id</th>\n",
       "      <th>profile_id</th>\n",
       "      <th>geology_id</th>\n",
       "      <th>lithology_id</th>\n",
       "      <th>lithology_1954_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1/57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1/59</td>\n",
       "      <td>Oendolongo</td>\n",
       "      <td>pp</td>\n",
       "      <td>Sistema do Maiombe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1/61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1/63</td>\n",
       "      <td>Karroo</td>\n",
       "      <td>Cs/Cal</td>\n",
       "      <td>Série de Cassanje - T2'T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1/64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   geo_features_id profile_id  geology_id lithology_id  \\\n",
       "0                1       1/57         NaN            d   \n",
       "1                2       1/59  Oendolongo           pp   \n",
       "2                3       1/61         NaN          NaN   \n",
       "3                4       1/63      Karroo       Cs/Cal   \n",
       "4                5       1/64         NaN          NaN   \n",
       "\n",
       "           lithology_1954_id  \n",
       "0                        NaN  \n",
       "1         Sistema do Maiombe  \n",
       "2                        NaN  \n",
       "3  Série de Cassanje - T2'T1  \n",
       "4                        NaN  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load cleaned minerology features data\n",
    "minerology_cleaning = pd.read_excel(\"/Users/inesschwartz/Desktop/Thesis/tables_soil_database/Perfis_local.xlsx\")\n",
    "\n",
    "# Rename columns\n",
    "geo_features_cleaning.rename(columns={\n",
    "    'PERFIL': 'profile_id',\n",
    "    'GEOLOGIA': 'geology_id',\n",
    "    'LITOLOGIA': 'lithology_id',\n",
    "    'LITOLOGIA_1954': 'lithology_1954_id',\n",
    "}, inplace=True)\n",
    "\n",
    "# Add primary key column\n",
    "#geo_features_cleaning.insert(0, 'geo_features_id', range(1, len(geo_features_cleaning) + 1))\n",
    "\n",
    "# Final normalized geo_features table (with codes as foreign keys)\n",
    "geo_features_clean = geo_features_cleaning[[\n",
    "    'geo_features_id',\n",
    "    'profile_id',\n",
    "    'geology_id',\n",
    "    'lithology_id',\n",
    "    'lithology_1954_id'\n",
    "]]\n",
    "\n",
    "geo_features_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking csv data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📄 File: district_clean.csv\n",
      "district_id      int64\n",
      "sample_id      float64\n",
      "profile_id      object\n",
      "district        object\n",
      "dtype: object\n",
      "\n",
      "📄 File: soil_type_clean.csv\n",
      "soil_type_id     int64\n",
      "profile_id      object\n",
      "grouping        object\n",
      "CEP_GR          object\n",
      "CEP_NAME        object\n",
      "FAO             object\n",
      "dtype: object\n",
      "\n",
      "📄 File: analyses_clean.csv\n",
      "lab_sample_id      int64\n",
      "sample_id        float64\n",
      "EG               float64\n",
      "thick_clay       float64\n",
      "fine_clay        float64\n",
      "                  ...   \n",
      "Tl               float64\n",
      "Pb               float64\n",
      "Bi               float64\n",
      "Th               float64\n",
      "U                float64\n",
      "Length: 68, dtype: object\n",
      "\n",
      "📄 File: climate_features_clean.csv\n",
      "climate_id               int64\n",
      "profile_id              object\n",
      "mean_annual_temp        object\n",
      "mean_annual_precip      object\n",
      "koppen_climate          object\n",
      "thornthwaite_climate    object\n",
      "hydric_regime           object\n",
      "thermal_regime          object\n",
      "dtype: object\n",
      "\n",
      "📄 File: analyses_clean_check2.csv\n",
      "lab_sample_id      int64\n",
      "sample_id        float64\n",
      "EG               float64\n",
      "thick_clay       float64\n",
      "fine_clay        float64\n",
      "                  ...   \n",
      "Tl               float64\n",
      "Pb               float64\n",
      "Bi               float64\n",
      "Th               float64\n",
      "U                float64\n",
      "Length: 71, dtype: object\n",
      "\n",
      "📄 File: slope_classes_mapping.csv\n",
      "slope_code           object\n",
      "slope_description    object\n",
      "dtype: object\n",
      "\n",
      "📄 File: analyses_clean_check1.csv\n",
      "sample_id        int64\n",
      "sample_id.1    float64\n",
      "EG             float64\n",
      "thick_clay     float64\n",
      "fine_clay      float64\n",
      "                ...   \n",
      "Tl             float64\n",
      "Pb             float64\n",
      "Bi             float64\n",
      "Th             float64\n",
      "U              float64\n",
      "Length: 61, dtype: object\n",
      "\n",
      "📄 File: geology_mapping.csv\n",
      "geology_code           object\n",
      "geology_description    object\n",
      "dtype: object\n",
      "\n",
      "📄 File: lithology1954_mapping.csv\n",
      "lithology_1954_code           object\n",
      "lithology_1954_description    object\n",
      "dtype: object\n",
      "\n",
      "📄 File: geo_features_clean.csv\n",
      "geo_features_id       int64\n",
      "profile_id           object\n",
      "geology_id           object\n",
      "lithology_id         object\n",
      "lithology_1954_id    object\n",
      "dtype: object\n",
      "\n",
      "📄 File: profile_clean.csv\n",
      "profile_id       object\n",
      "site_info_id    float64\n",
      "sample_id       float64\n",
      "soil_type_id    float64\n",
      "dtype: object\n",
      "\n",
      "📄 File: morphology_horizon_clean.csv\n",
      "horizon_id           object\n",
      "sample_id           float64\n",
      "profile_id           object\n",
      "horizon_layer       float64\n",
      "upper_depth         float64\n",
      "lower_depth         float64\n",
      "moisture_degree      object\n",
      "root_quantity        object\n",
      "root_diameter        object\n",
      "texture              object\n",
      "structure_type       object\n",
      "structure_class      object\n",
      "structure_degree     object\n",
      "pore_diameter        object\n",
      "pore_quantity        object\n",
      "pore_shape           object\n",
      "dry_color_name       object\n",
      "dry_hue              object\n",
      "dry_value           float64\n",
      "dry_chroma          float64\n",
      "moist_color_name     object\n",
      "moist_hue            object\n",
      "moist_value         float64\n",
      "moist_chroma        float64\n",
      "compaction           object\n",
      "durability           object\n",
      "dtype: object\n",
      "\n",
      "📄 File: topo_features_clean.csv\n",
      "topo_features_id       int64\n",
      "profile_id            object\n",
      "slope_code            object\n",
      "altitude             float64\n",
      "aspect               float64\n",
      "land_surface_temp    float64\n",
      "dem_elevation        float64\n",
      "dtype: object\n",
      "\n",
      "📄 File: lithology_mapping.csv\n",
      "lithology_code           object\n",
      "lithology_description    object\n",
      "dtype: object\n",
      "\n",
      "📄 File: site_info_clean.csv\n",
      "profile_id          object\n",
      "date                object\n",
      "site_info_id       float64\n",
      "X_coord            float64\n",
      "Y_coord            float64\n",
      "land_cover_id      float64\n",
      "climate_id         float64\n",
      "geology_id         float64\n",
      "topo_feature_id    float64\n",
      "sampling_date      float64\n",
      "districts_id       float64\n",
      "dtype: object\n",
      "\n",
      "📄 File: samples_clean.csv\n",
      "sample_id         int64\n",
      "site_info_id     object\n",
      "profile_id       object\n",
      "horizon_id      float64\n",
      "Shelf            object\n",
      "Room             object\n",
      "year            float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Set the path to your folder containing the 10 CSV files\n",
    "csv_folder = \"/Users/inesschwartz/Desktop/Thesis/tables_clean\"  \n",
    "\n",
    "# List all CSV files in the folder\n",
    "csv_files = [f for f in os.listdir(csv_folder) if f.endswith(\".csv\")]\n",
    "\n",
    "# Loop through each file and display column data types\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(csv_folder, file)\n",
    "    print(f\"\\n📄 File: {file}\")\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(df.dtypes)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error reading {file}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
