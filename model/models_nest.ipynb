{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All models together to be run 50 times (once per subset/decluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**the modelling methodology**\n",
    "\n",
    "â€œEach declustered subset (DCáµ¢) was internally partitioned (80/20) to allow model validation on independent test data, ensuring that predictive performance and model stability were assessed under spatial independence. After internal validation, models were retrained on all samples in each DCáµ¢ to maximize predictive strength and produce the final maps used for ensemble averaging. The ensemble predictions were subsequently validated using the external holdout dataset (testâ‚) derived from the original data split.â€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running RF, OK, and RF+OK for 50 declustered subsets... â³\n",
      "âœ… Iteration 01 complete | RF RÂ²=0.332, OK RÂ²=0.042, RF+OK RÂ²=0.332\n",
      "âœ… Iteration 02 complete | RF RÂ²=0.319, OK RÂ²=0.010, RF+OK RÂ²=0.289\n",
      "âœ… Iteration 03 complete | RF RÂ²=0.329, OK RÂ²=-0.005, RF+OK RÂ²=0.289\n",
      "âœ… Iteration 04 complete | RF RÂ²=0.316, OK RÂ²=-0.010, RF+OK RÂ²=0.272\n",
      "âœ… Iteration 05 complete | RF RÂ²=0.335, OK RÂ²=0.042, RF+OK RÂ²=0.334\n",
      "âœ… Iteration 06 complete | RF RÂ²=0.349, OK RÂ²=0.001, RF+OK RÂ²=0.313\n",
      "âœ… Iteration 07 complete | RF RÂ²=0.321, OK RÂ²=0.058, RF+OK RÂ²=0.328\n",
      "âœ… Iteration 08 complete | RF RÂ²=0.324, OK RÂ²=0.057, RF+OK RÂ²=0.330\n",
      "âœ… Iteration 09 complete | RF RÂ²=0.326, OK RÂ²=-0.012, RF+OK RÂ²=0.281\n",
      "âœ… Iteration 10 complete | RF RÂ²=0.328, OK RÂ²=0.042, RF+OK RÂ²=0.327\n",
      "âœ… Iteration 11 complete | RF RÂ²=0.328, OK RÂ²=0.042, RF+OK RÂ²=0.327\n",
      "âœ… Iteration 12 complete | RF RÂ²=0.332, OK RÂ²=0.043, RF+OK RÂ²=0.332\n",
      "âœ… Iteration 13 complete | RF RÂ²=0.323, OK RÂ²=-0.012, RF+OK RÂ²=0.279\n",
      "âœ… Iteration 14 complete | RF RÂ²=0.315, OK RÂ²=0.045, RF+OK RÂ²=0.314\n",
      "âœ… Iteration 15 complete | RF RÂ²=0.319, OK RÂ²=0.010, RF+OK RÂ²=0.289\n",
      "âœ… Iteration 16 complete | RF RÂ²=0.334, OK RÂ²=0.069, RF+OK RÂ²=0.347\n",
      "âœ… Iteration 17 complete | RF RÂ²=0.335, OK RÂ²=0.042, RF+OK RÂ²=0.334\n",
      "âœ… Iteration 18 complete | RF RÂ²=0.347, OK RÂ²=-0.001, RF+OK RÂ²=0.309\n",
      "âœ… Iteration 19 complete | RF RÂ²=0.337, OK RÂ²=0.070, RF+OK RÂ²=0.351\n",
      "âœ… Iteration 20 complete | RF RÂ²=0.339, OK RÂ²=0.045, RF+OK RÂ²=0.341\n",
      "âœ… Iteration 21 complete | RF RÂ²=0.334, OK RÂ²=0.042, RF+OK RÂ²=0.333\n",
      "âœ… Iteration 22 complete | RF RÂ²=0.333, OK RÂ²=0.077, RF+OK RÂ²=0.350\n",
      "âœ… Iteration 23 complete | RF RÂ²=0.313, OK RÂ²=0.042, RF+OK RÂ²=0.312\n",
      "âœ… Iteration 24 complete | RF RÂ²=0.347, OK RÂ²=-0.001, RF+OK RÂ²=0.309\n",
      "âœ… Iteration 25 complete | RF RÂ²=0.318, OK RÂ²=-0.013, RF+OK RÂ²=0.273\n",
      "âœ… Iteration 26 complete | RF RÂ²=0.332, OK RÂ²=0.076, RF+OK RÂ²=0.346\n",
      "âœ… Iteration 27 complete | RF RÂ²=0.315, OK RÂ²=0.042, RF+OK RÂ²=0.313\n",
      "âœ… Iteration 28 complete | RF RÂ²=0.334, OK RÂ²=0.042, RF+OK RÂ²=0.333\n",
      "âœ… Iteration 29 complete | RF RÂ²=0.328, OK RÂ²=0.042, RF+OK RÂ²=0.327\n",
      "âœ… Iteration 30 complete | RF RÂ²=0.342, OK RÂ²=0.044, RF+OK RÂ²=0.343\n",
      "âœ… Iteration 31 complete | RF RÂ²=0.346, OK RÂ²=0.000, RF+OK RÂ²=0.310\n",
      "âœ… Iteration 32 complete | RF RÂ²=0.324, OK RÂ²=0.057, RF+OK RÂ²=0.330\n",
      "âœ… Iteration 33 complete | RF RÂ²=0.331, OK RÂ²=0.016, RF+OK RÂ²=0.304\n",
      "âœ… Iteration 34 complete | RF RÂ²=0.330, OK RÂ²=0.077, RF+OK RÂ²=0.345\n",
      "âœ… Iteration 35 complete | RF RÂ²=0.328, OK RÂ²=0.042, RF+OK RÂ²=0.327\n",
      "âœ… Iteration 36 complete | RF RÂ²=0.335, OK RÂ²=0.078, RF+OK RÂ²=0.352\n",
      "âœ… Iteration 37 complete | RF RÂ²=0.319, OK RÂ²=0.058, RF+OK RÂ²=0.327\n",
      "âœ… Iteration 38 complete | RF RÂ²=0.332, OK RÂ²=0.043, RF+OK RÂ²=0.332\n",
      "âœ… Iteration 39 complete | RF RÂ²=0.334, OK RÂ²=0.042, RF+OK RÂ²=0.333\n",
      "âœ… Iteration 40 complete | RF RÂ²=0.347, OK RÂ²=-0.001, RF+OK RÂ²=0.309\n",
      "âœ… Iteration 41 complete | RF RÂ²=0.331, OK RÂ²=0.016, RF+OK RÂ²=0.304\n",
      "âœ… Iteration 42 complete | RF RÂ²=0.346, OK RÂ²=0.000, RF+OK RÂ²=0.310\n",
      "âœ… Iteration 43 complete | RF RÂ²=0.323, OK RÂ²=-0.016, RF+OK RÂ²=0.276\n",
      "âœ… Iteration 44 complete | RF RÂ²=0.330, OK RÂ²=0.028, RF+OK RÂ²=0.309\n",
      "âœ… Iteration 45 complete | RF RÂ²=0.339, OK RÂ²=0.045, RF+OK RÂ²=0.341\n",
      "âœ… Iteration 46 complete | RF RÂ²=0.335, OK RÂ²=0.043, RF+OK RÂ²=0.335\n",
      "âœ… Iteration 47 complete | RF RÂ²=0.334, OK RÂ²=0.042, RF+OK RÂ²=0.333\n",
      "âœ… Iteration 48 complete | RF RÂ²=0.319, OK RÂ²=0.010, RF+OK RÂ²=0.289\n",
      "âœ… Iteration 49 complete | RF RÂ²=0.347, OK RÂ²=-0.001, RF+OK RÂ²=0.309\n",
      "âœ… Iteration 50 complete | RF RÂ²=0.323, OK RÂ²=-0.016, RF+OK RÂ²=0.276\n",
      "\n",
      "ğŸ“ All model results saved to: /Users/inesschwartz/Desktop/model/results_all_models.csv\n"
     ]
    }
   ],
   "source": [
    "# No cross validation steps --All models together to be run 50 times (once per subset/decluster) \n",
    "#  =========================================================\n",
    "# STEP â€” Run RF, OK, and RF+OK on all declustered subsets\n",
    "# =========================================================\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pykrige.ok import OrdinaryKriging\n",
    "\n",
    "# --- Paths ---\n",
    "decluster_dir = \"/Users/inesschwartz/Desktop/model/decluster_runs\"\n",
    "results_file = \"/Users/inesschwartz/Desktop/model/results_all_models.csv\"\n",
    "output_dir = \"/Users/inesschwartz/Desktop/model/predictions\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# --- Hyperparameters (from tuning step) ---\n",
    "rf_params = {\n",
    "    'n_estimators': 1500,\n",
    "    'min_samples_leaf': 3,\n",
    "    'max_features': 0.5,\n",
    "    'max_depth': None,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "# --- Fixed variogram parameters (from stability analysis) ---\n",
    "variogram_params = {\n",
    "    'model': 'exponential',\n",
    "    'variogram_parameters': {'nugget': 0.0022, 'sill': 0.22, 'range': 15000}\n",
    "}\n",
    "\n",
    "# --- Helper for metrics ---\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        'R2': r2_score(y_true, y_pred),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        'MAE': mean_absolute_error(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "# --- Results container ---\n",
    "results = []\n",
    "\n",
    "# --- Files ---\n",
    "files = sorted(glob.glob(os.path.join(decluster_dir, \"decluster_run_*.csv\")))\n",
    "print(f\"Running RF, OK, and RF+OK for {len(files)} declustered subsets... â³\")\n",
    "\n",
    "# =========================================================\n",
    "# MAIN LOOP\n",
    "# =========================================================\n",
    "for i, file in enumerate(files, start=1):\n",
    "    df = pd.read_csv(file)\n",
    "    target = 'log_soc_stock'\n",
    "\n",
    "    # --- Train/test split ---\n",
    "    train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    X_train = train.drop(columns=[target, 'X_coord', 'Y_coord', 'site_info_id'], errors='ignore')\n",
    "    y_train = train[target].values\n",
    "    X_test = test.drop(columns=[target, 'X_coord', 'Y_coord', 'site_info_id'], errors='ignore')\n",
    "    y_test = test[target].values\n",
    "\n",
    "    coords_train = train[['X_coord', 'Y_coord']].values\n",
    "    coords_test = test[['X_coord', 'Y_coord']].values\n",
    "\n",
    "    # =====================================================\n",
    "    # 1ï¸âƒ£ Ordinary Kriging (OK)\n",
    "    # =====================================================\n",
    "    ok = OrdinaryKriging(\n",
    "        x=coords_train[:, 0],\n",
    "        y=coords_train[:, 1],\n",
    "        z=y_train,\n",
    "        variogram_model=variogram_params['model'],\n",
    "        variogram_parameters=variogram_params['variogram_parameters'],\n",
    "        enable_plotting=False,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    y_pred_ok, _ = ok.execute('points', coords_test[:, 0], coords_test[:, 1])\n",
    "    metrics_ok = compute_metrics(y_test, y_pred_ok)\n",
    "    results.append({'iteration': i, 'model': 'OK', **metrics_ok})\n",
    "\n",
    "    # =====================================================\n",
    "    # 2ï¸âƒ£ Random Forest (RF)\n",
    "    # =====================================================\n",
    "    rf = RandomForestRegressor(**rf_params)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred_rf = rf.predict(X_test)\n",
    "    metrics_rf = compute_metrics(y_test, y_pred_rf)\n",
    "    results.append({'iteration': i, 'model': 'RF', **metrics_rf})\n",
    "\n",
    "    # =====================================================\n",
    "    # 3ï¸âƒ£ Hybrid RF + OK (residual kriging)\n",
    "    # =====================================================\n",
    "    residuals = y_train - rf.predict(X_train)\n",
    "    ok_resid = OrdinaryKriging(\n",
    "        x=coords_train[:, 0],\n",
    "        y=coords_train[:, 1],\n",
    "        z=residuals,\n",
    "        variogram_model=variogram_params['model'],\n",
    "        variogram_parameters=variogram_params['variogram_parameters'],\n",
    "        enable_plotting=False,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    residual_pred, _ = ok_resid.execute('points', coords_test[:, 0], coords_test[:, 1])\n",
    "    y_pred_rfok = y_pred_rf + residual_pred\n",
    "\n",
    "    metrics_rfok = compute_metrics(y_test, y_pred_rfok)\n",
    "    results.append({'iteration': i, 'model': 'RF+OK', **metrics_rfok})\n",
    "\n",
    "    print(f\"âœ… Iteration {i:02d} complete | RF RÂ²={metrics_rf['R2']:.3f}, OK RÂ²={metrics_ok['R2']:.3f}, RF+OK RÂ²={metrics_rfok['R2']:.3f}\")\n",
    "\n",
    "    # --- Save iteration predictions (optional) ---\n",
    "    out = test[['X_coord', 'Y_coord', target]].copy()\n",
    "    out['pred_RF'] = y_pred_rf\n",
    "    out['pred_OK'] = y_pred_ok\n",
    "    out['pred_RF_OK'] = y_pred_rfok\n",
    "    out.to_csv(os.path.join(output_dir, f\"predictions_iter_{i:03d}.csv\"), index=False)\n",
    "\n",
    "# =====================================================\n",
    "# Save all metrics\n",
    "# =====================================================\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(results_file, index=False)\n",
    "print(f\"\\nğŸ“ All model results saved to: {results_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Running calibration for first 10 declustered subsets...\n",
      "\n",
      "ğŸ“‚ Processing decluster subset 001 | n = 629\n",
      "âš™ï¸ Running internal 5-fold CV and validation...\n",
      "âœ… DC001 | RF RÂ²=0.333 | OK RÂ²=1.000 | Hybrid RÂ²=1.000\n",
      "\n",
      "ğŸ“‚ Processing decluster subset 002 | n = 629\n",
      "âš™ï¸ Running internal 5-fold CV and validation...\n",
      "âœ… DC002 | RF RÂ²=0.304 | OK RÂ²=1.000 | Hybrid RÂ²=1.000\n",
      "\n",
      "ğŸ“‚ Processing decluster subset 003 | n = 629\n",
      "âš™ï¸ Running internal 5-fold CV and validation...\n",
      "âœ… DC003 | RF RÂ²=0.321 | OK RÂ²=1.000 | Hybrid RÂ²=1.000\n",
      "\n",
      "ğŸ“‚ Processing decluster subset 004 | n = 629\n",
      "âš™ï¸ Running internal 5-fold CV and validation...\n",
      "âœ… DC004 | RF RÂ²=0.318 | OK RÂ²=1.000 | Hybrid RÂ²=1.000\n",
      "\n",
      "ğŸ“‚ Processing decluster subset 005 | n = 629\n",
      "âš™ï¸ Running internal 5-fold CV and validation...\n",
      "âœ… DC005 | RF RÂ²=0.325 | OK RÂ²=1.000 | Hybrid RÂ²=1.000\n",
      "\n",
      "ğŸ“‚ Processing decluster subset 006 | n = 629\n",
      "âš™ï¸ Running internal 5-fold CV and validation...\n",
      "âœ… DC006 | RF RÂ²=0.317 | OK RÂ²=1.000 | Hybrid RÂ²=1.000\n",
      "\n",
      "ğŸ“‚ Processing decluster subset 007 | n = 629\n",
      "âš™ï¸ Running internal 5-fold CV and validation...\n",
      "âœ… DC007 | RF RÂ²=0.324 | OK RÂ²=1.000 | Hybrid RÂ²=1.000\n",
      "\n",
      "ğŸ“‚ Processing decluster subset 008 | n = 629\n",
      "âš™ï¸ Running internal 5-fold CV and validation...\n",
      "âœ… DC008 | RF RÂ²=0.324 | OK RÂ²=1.000 | Hybrid RÂ²=1.000\n",
      "\n",
      "ğŸ“‚ Processing decluster subset 009 | n = 629\n",
      "âš™ï¸ Running internal 5-fold CV and validation...\n",
      "âœ… DC009 | RF RÂ²=0.309 | OK RÂ²=1.000 | Hybrid RÂ²=1.000\n",
      "\n",
      "ğŸ“‚ Processing decluster subset 010 | n = 629\n",
      "âš™ï¸ Running internal 5-fold CV and validation...\n",
      "âœ… DC010 | RF RÂ²=0.335 | OK RÂ²=1.000 | Hybrid RÂ²=1.000\n",
      "\n",
      "âœ… Calibration diagnostics complete.\n",
      "ğŸ“ Results saved to: /Users/inesschwartz/Desktop/model/results_calibration/calibration_results.csv\n"
     ]
    }
   ],
   "source": [
    "# (Calibration Diagnostics Only) didn't handle ok data well...\n",
    "# =========================================================\n",
    "# STEP â€” Decluster modeling loop (Calibration Diagnostics Only)\n",
    "# =========================================================\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import KFold\n",
    "from pykrige.ok import OrdinaryKriging\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# =========================================================\n",
    "# PATHS AND PARAMETERS\n",
    "# =========================================================\n",
    "decluster_dir = \"/Users/inesschwartz/Desktop/model/decluster_runs\"\n",
    "output_dir = \"/Users/inesschwartz/Desktop/model/results_calibration\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# --- RF parameters (from tuning) ---\n",
    "rf_params = {\n",
    "    'n_estimators': 1500,\n",
    "    'min_samples_leaf': 3,\n",
    "    'max_features': 0.5,\n",
    "    'max_depth': None,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "# Variogram parameters\n",
    "variogram_model = 'exponential'\n",
    "variogram_params = {'nugget': 0.0022, 'sill': 0.22, 'range': 15000}\n",
    "\n",
    "# =========================================================\n",
    "# HELPER FUNCTIONS\n",
    "# =========================================================\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    \"\"\"Compute standard regression metrics.\"\"\"\n",
    "    return {\n",
    "        'R2': r2_score(y_true, y_pred),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        'MAE': mean_absolute_error(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "def cross_validate_rf(X, y, k=5):\n",
    "    \"\"\"Run k-fold cross-validation for Random Forest.\"\"\"\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    metrics = []\n",
    "\n",
    "    for train_idx, test_idx in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        rf = RandomForestRegressor(**rf_params)\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_pred = rf.predict(X_test)\n",
    "        metrics.append(compute_metrics(y_test, y_pred))\n",
    "\n",
    "    avg = pd.DataFrame(metrics).mean().to_dict()\n",
    "    return avg\n",
    "\n",
    "def run_ok(coords, values, variogram_params, model='exponential'):\n",
    "    \"\"\"Run Ordinary Kriging with fixed variogram parameters.\"\"\"\n",
    "    ok = OrdinaryKriging(\n",
    "        x=coords[:, 0],\n",
    "        y=coords[:, 1],\n",
    "        z=values,\n",
    "        variogram_model=model,\n",
    "        variogram_parameters={\n",
    "            'sill': variogram_params['sill'],\n",
    "            'range': variogram_params['range'],\n",
    "            'nugget': variogram_params['nugget']\n",
    "        },\n",
    "        enable_plotting=False,\n",
    "        verbose=False\n",
    "    )\n",
    "    return ok\n",
    "\n",
    "def run_rf_ok(X, y, coords, variogram_params):\n",
    "    \"\"\"Run hybrid RF + OK (residual kriging).\"\"\"\n",
    "    rf = RandomForestRegressor(**rf_params)\n",
    "    rf.fit(X, y)\n",
    "    y_pred_rf = rf.predict(X)\n",
    "    residuals = y - y_pred_rf\n",
    "\n",
    "    ok = run_ok(coords, residuals, variogram_params)\n",
    "    residual_pred, _ = ok.execute('points', coords[:, 0], coords[:, 1])\n",
    "    y_pred_hybrid = y_pred_rf + residual_pred.data\n",
    "    return compute_metrics(y, y_pred_hybrid)\n",
    "\n",
    "# =========================================================\n",
    "# MAIN CALIBRATION LOOP\n",
    "# =========================================================\n",
    "files = sorted(glob.glob(os.path.join(decluster_dir, \"decluster_run_*.csv\")))\n",
    "n_calibration = 10  # limit to first 10 DCs\n",
    "\n",
    "print(f\"ğŸ” Running calibration for first {n_calibration} declustered subsets...\")\n",
    "\n",
    "calibration_results = []\n",
    "\n",
    "for i, file in enumerate(files[:n_calibration], start=1):\n",
    "    df = pd.read_csv(file)\n",
    "    print(f\"\\nğŸ“‚ Processing decluster subset {i:03d} | n = {len(df)}\")\n",
    "\n",
    "    target = 'log_soc_stock'\n",
    "    X = df.drop(columns=[target, 'X_coord', 'Y_coord', 'site_info_id'], errors='ignore')\n",
    "    y = df[target].values\n",
    "    coords = df[['X_coord', 'Y_coord']].values\n",
    "\n",
    "    print(\"âš™ï¸ Running internal 5-fold CV and validation...\")\n",
    "\n",
    "    # --- RF Cross-validation ---\n",
    "    rf_cv_metrics = cross_validate_rf(X, y, k=5)\n",
    "\n",
    "    # --- OK validation (LOO-style) ---\n",
    "    ok = run_ok(coords, y, variogram_params)\n",
    "    y_pred_ok, _ = ok.execute('points', coords[:, 0], coords[:, 1])\n",
    "    ok_metrics = compute_metrics(y, y_pred_ok)\n",
    "\n",
    "    # --- RF+OK residual kriging ---\n",
    "    hybrid_metrics = run_rf_ok(X, y, coords, variogram_params)\n",
    "\n",
    "    # --- Store results ---\n",
    "    calibration_results.append({'subset': i, 'model': 'RF_CV', **rf_cv_metrics})\n",
    "    calibration_results.append({'subset': i, 'model': 'OK', **ok_metrics})\n",
    "    calibration_results.append({'subset': i, 'model': 'RF+OK', **hybrid_metrics})\n",
    "\n",
    "    print(f\"âœ… DC{i:03d} | RF RÂ²={rf_cv_metrics['R2']:.3f} | OK RÂ²={ok_metrics['R2']:.3f} | Hybrid RÂ²={hybrid_metrics['R2']:.3f}\")\n",
    "\n",
    "# =========================================================\n",
    "# SAVE RESULTS\n",
    "# =========================================================\n",
    "out_csv = os.path.join(output_dir, \"calibration_results.csv\")\n",
    "pd.DataFrame(calibration_results).to_csv(out_csv, index=False)\n",
    "\n",
    "print(\"\\nâœ… Calibration diagnostics complete.\")\n",
    "print(f\"ğŸ“ Results saved to: {out_csv}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calibration results summary (DCâ‚â€“â‚â‚€):\n",
    "Random Forest shows consistent moderate predictive ability (RÂ² â‰ˆ 0.32, RMSE â‰ˆ 0.44).\n",
    "However, Ordinary Kriging (OK) and hybrid RF+OK show perfect interpolation (RÂ²=1.0), indicating they were evaluated on the same training data rather than withheld samples.\n",
    "The next step is to implement Leave-One-Out (LOO) kriging validation to obtain unbiased performance estimates for OK and RF+OK before proceeding to ensemble modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Running RF (Spatial K-Fold), OK (LOO), and RF+OK (LOO) for 10 decluster subsets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calibration progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [3:18:05<00:00, 1188.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ Calibration results saved to: /Users/inesschwartz/Desktop/model/results_final/calibration_results_spatial.csv\n",
      "âœ… Spatial K-Fold + LOO calibration complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# STEP â€” Decluster modeling loop with Spatial K-Fold & LOO\n",
    "# =========================================================\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import KFold\n",
    "from pykrige.ok import OrdinaryKriging\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# =========================================================\n",
    "# PATHS AND PARAMETERS\n",
    "# =========================================================\n",
    "decluster_dir = \"/Users/inesschwartz/Desktop/model/decluster_runs\"\n",
    "output_dir = \"/Users/inesschwartz/Desktop/model/results_final\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Random Forest tuned parameters\n",
    "rf_params = {\n",
    "    'n_estimators': 1500,\n",
    "    'min_samples_leaf': 3,\n",
    "    'max_features': 0.5,\n",
    "    'max_depth': None,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "# Variogram parameters (from calibration)\n",
    "variogram_model = 'exponential'\n",
    "variogram_params = {'nugget': 0.0022, 'sill': 0.22, 'range': 15000}\n",
    "\n",
    "# =========================================================\n",
    "# HELPER FUNCTIONS\n",
    "# =========================================================\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    \"\"\"Compute standard regression metrics.\"\"\"\n",
    "    return {\n",
    "        'R2': r2_score(y_true, y_pred),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        'MAE': mean_absolute_error(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "\n",
    "def spatial_kfold(coords, n_splits=5):\n",
    "    \"\"\"\n",
    "    Custom spatial K-Fold generator.\n",
    "    Splits data into roughly spatially distinct clusters\n",
    "    by sorting coordinates and splitting sequentially.\n",
    "    \"\"\"\n",
    "    # Sort by X + Y coordinate to ensure spatial grouping\n",
    "    idx = np.argsort(coords[:, 0] + coords[:, 1])\n",
    "    fold_sizes = np.full(n_splits, len(coords) // n_splits, dtype=int)\n",
    "    fold_sizes[:len(coords) % n_splits] += 1\n",
    "    current = 0\n",
    "    folds = []\n",
    "    for fold_size in fold_sizes:\n",
    "        start, stop = current, current + fold_size\n",
    "        test_idx = idx[start:stop]\n",
    "        train_idx = np.setdiff1d(np.arange(len(coords)), test_idx)\n",
    "        folds.append((train_idx, test_idx))\n",
    "        current = stop\n",
    "    return folds\n",
    "\n",
    "\n",
    "def cross_validate_rf_spatial(X, y, coords, n_splits=5):\n",
    "    \"\"\"Spatial K-Fold cross-validation for Random Forest.\"\"\"\n",
    "    folds = spatial_kfold(coords, n_splits)\n",
    "    metrics = []\n",
    "    for train_idx, test_idx in folds:\n",
    "        rf = RandomForestRegressor(**rf_params)\n",
    "        rf.fit(X.iloc[train_idx], y[train_idx])\n",
    "        y_pred = rf.predict(X.iloc[test_idx])\n",
    "        metrics.append(compute_metrics(y[test_idx], y_pred))\n",
    "    return pd.DataFrame(metrics).mean().to_dict()\n",
    "\n",
    "\n",
    "def loo_validate_ok(coords, values, variogram_params, model='exponential'):\n",
    "    \"\"\"Leave-One-Out Cross-Validation for Ordinary Kriging.\"\"\"\n",
    "    preds = np.zeros(len(values))\n",
    "    for i in range(len(values)):\n",
    "        mask = np.ones(len(values), dtype=bool)\n",
    "        mask[i] = False\n",
    "        ok = OrdinaryKriging(\n",
    "            x=coords[mask, 0],\n",
    "            y=coords[mask, 1],\n",
    "            z=values[mask],\n",
    "            variogram_model=model,\n",
    "            variogram_parameters={\n",
    "                'sill': variogram_params['sill'],\n",
    "                'range': variogram_params['range'],\n",
    "                'nugget': variogram_params['nugget']\n",
    "            },\n",
    "            enable_plotting=False,\n",
    "            verbose=False\n",
    "        )\n",
    "        zhat, _ = ok.execute('points',\n",
    "                             np.array([coords[i, 0]]),\n",
    "                             np.array([coords[i, 1]]))\n",
    "        preds[i] = zhat.data[0]\n",
    "    return compute_metrics(values, preds)\n",
    "\n",
    "\n",
    "def loo_validate_rf_ok(X, y, coords, variogram_params):\n",
    "    \"\"\"LOO validation for hybrid RF+OK (residual kriging).\"\"\"\n",
    "    preds = np.zeros(len(y))\n",
    "    for i in range(len(y)):\n",
    "        mask = np.ones(len(y), dtype=bool)\n",
    "        mask[i] = False\n",
    "        rf = RandomForestRegressor(**rf_params)\n",
    "        rf.fit(X.iloc[mask], y[mask])\n",
    "        y_pred_rf = rf.predict(X.iloc[mask])\n",
    "        residuals = y[mask] - y_pred_rf\n",
    "        ok = OrdinaryKriging(\n",
    "            x=coords[mask, 0],\n",
    "            y=coords[mask, 1],\n",
    "            z=residuals,\n",
    "            variogram_model='exponential',\n",
    "            variogram_parameters={\n",
    "                'sill': variogram_params['sill'],\n",
    "                'range': variogram_params['range'],\n",
    "                'nugget': variogram_params['nugget']\n",
    "            },\n",
    "            enable_plotting=False,\n",
    "            verbose=False\n",
    "        )\n",
    "        zhat, _ = ok.execute('points',\n",
    "                             np.array([coords[i, 0]]),\n",
    "                             np.array([coords[i, 1]]))\n",
    "        yhat_hybrid = rf.predict(X.iloc[[i]])[0] + zhat.data[0]\n",
    "        preds[i] = yhat_hybrid\n",
    "    return compute_metrics(y, preds)\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# MAIN CALIBRATION LOOP\n",
    "# =========================================================\n",
    "files = sorted(glob.glob(os.path.join(decluster_dir, \"decluster_run_*.csv\")))\n",
    "calibration_results = []\n",
    "\n",
    "print(f\"ğŸ” Running RF (Spatial K-Fold), OK (LOO), and RF+OK (LOO) for {len(files[:10])} decluster subsets...\")\n",
    "\n",
    "for i, file in enumerate(tqdm(files[:10], desc=\"Calibration progress\", ncols=100), start=1):\n",
    "    df = pd.read_csv(file)\n",
    "    target = 'log_soc_stock'\n",
    "    X = df.drop(columns=[target, 'X_coord', 'Y_coord', 'site_info_id'], errors='ignore')\n",
    "    y = df[target].values\n",
    "    coords = df[['X_coord', 'Y_coord']].values\n",
    "\n",
    "    rf_spatial = cross_validate_rf_spatial(X, y, coords, n_splits=5)\n",
    "    ok_loo = loo_validate_ok(coords, y, variogram_params, model=variogram_model)\n",
    "    hybrid_loo = loo_validate_rf_ok(X, y, coords, variogram_params)\n",
    "\n",
    "    calibration_results.append({'subset': i, 'model': 'RF_SpatialKFold', **rf_spatial})\n",
    "    calibration_results.append({'subset': i, 'model': 'OK_LOO', **ok_loo})\n",
    "    calibration_results.append({'subset': i, 'model': 'RF+OK_LOO', **hybrid_loo})\n",
    "\n",
    "# --- Save calibration results ---\n",
    "calib_path = os.path.join(output_dir, \"calibration_results_spatial.csv\")\n",
    "pd.DataFrame(calibration_results).to_csv(calib_path, index=False)\n",
    "\n",
    "print(f\"\\nğŸ“ Calibration results saved to: {calib_path}\")\n",
    "print(\"âœ… Spatial K-Fold + LOO calibration complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Running OK and RF+OK (LOO) for 5 declustered subsets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calibration progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [1:55:39<00:00, 1387.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ Calibration results saved to: /Users/inesschwartz/Desktop/model/results_calibration_ok/ok_rfok_calibration_results.csv\n",
      "âœ… Calibration complete.\n",
      "\n",
      "Summary (mean across 5 subsets):\n",
      "              R2   RMSE    MAE\n",
      "model                         \n",
      "OK_LOO     0.085  0.514  0.392\n",
      "RF+OK_LOO  0.332  0.439  0.315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## ok rf-ok trial\n",
    "\n",
    " # =========================================================\n",
    "# STEP â€” Calibration test for OK and RF+OK (5 declusters)\n",
    "# =========================================================\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from pykrige.ok import OrdinaryKriging\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# =========================================================\n",
    "# PATHS AND PARAMETERS\n",
    "# =========================================================\n",
    "decluster_dir = \"/Users/inesschwartz/Desktop/model/decluster_runs\"\n",
    "output_dir = \"/Users/inesschwartz/Desktop/model/results_calibration_ok\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Variogram parameters (from your calibration step)\n",
    "variogram_model = 'exponential'\n",
    "variogram_params = {'nugget': 0.0022, 'sill': 0.22, 'range': 15000}\n",
    "\n",
    "# Random Forest tuned parameters\n",
    "rf_params = {\n",
    "    'n_estimators': 1500,\n",
    "    'min_samples_leaf': 3,\n",
    "    'max_features': 0.5,\n",
    "    'max_depth': None,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "# =========================================================\n",
    "# HELPER FUNCTIONS\n",
    "# =========================================================\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    \"\"\"Compute regression metrics.\"\"\"\n",
    "    return {\n",
    "        'R2': r2_score(y_true, y_pred),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        'MAE': mean_absolute_error(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "\n",
    "def loo_validate_ok(coords, values, variogram_params, model='exponential'):\n",
    "    \"\"\"Leave-One-Out Cross-Validation for Ordinary Kriging.\"\"\"\n",
    "    preds = np.zeros(len(values))\n",
    "    for i in range(len(values)):\n",
    "        mask = np.ones(len(values), dtype=bool)\n",
    "        mask[i] = False\n",
    "\n",
    "        ok = OrdinaryKriging(\n",
    "            x=coords[mask, 0],\n",
    "            y=coords[mask, 1],\n",
    "            z=values[mask],\n",
    "            variogram_model=model,\n",
    "            variogram_parameters=[\n",
    "                variogram_params['sill'],\n",
    "                variogram_params['range'],\n",
    "                variogram_params['nugget']\n",
    "            ],\n",
    "            enable_plotting=False,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        zhat, _ = ok.execute('points',\n",
    "                             np.array([coords[i, 0]]),\n",
    "                             np.array([coords[i, 1]]))\n",
    "        preds[i] = zhat.data[0]\n",
    "\n",
    "    return compute_metrics(values, preds)\n",
    "\n",
    "\n",
    "def loo_validate_rf_ok(X, y, coords, variogram_params):\n",
    "    \"\"\"Leave-One-Out validation for hybrid RF+OK (residual kriging).\"\"\"\n",
    "    preds = np.zeros(len(y))\n",
    "    for i in range(len(y)):\n",
    "        mask = np.ones(len(y), dtype=bool)\n",
    "        mask[i] = False\n",
    "\n",
    "        rf = RandomForestRegressor(**rf_params)\n",
    "        rf.fit(X.iloc[mask], y[mask])\n",
    "        y_pred_rf = rf.predict(X.iloc[mask])\n",
    "        residuals = y[mask] - y_pred_rf\n",
    "\n",
    "        ok = OrdinaryKriging(\n",
    "            x=coords[mask, 0],\n",
    "            y=coords[mask, 1],\n",
    "            z=residuals,\n",
    "            variogram_model='exponential',\n",
    "            variogram_parameters=[\n",
    "                variogram_params['sill'],\n",
    "                variogram_params['range'],\n",
    "                variogram_params['nugget']\n",
    "            ],\n",
    "            enable_plotting=False,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        zhat, _ = ok.execute('points',\n",
    "                             np.array([coords[i, 0]]),\n",
    "                             np.array([coords[i, 1]]))\n",
    "        yhat_hybrid = rf.predict(X.iloc[[i]])[0] + zhat.data[0]\n",
    "        preds[i] = yhat_hybrid\n",
    "\n",
    "    return compute_metrics(y, preds)\n",
    "\n",
    "# =========================================================\n",
    "# MAIN CALIBRATION LOOP\n",
    "# =========================================================\n",
    "files = sorted(glob.glob(os.path.join(decluster_dir, \"decluster_run_*.csv\")))[:5]\n",
    "results = []\n",
    "\n",
    "print(f\"ğŸ” Running OK and RF+OK (LOO) for {len(files)} declustered subsets...\")\n",
    "\n",
    "for i, file in enumerate(tqdm(files, desc=\"Calibration progress\", ncols=100), start=1):\n",
    "    df = pd.read_csv(file)\n",
    "    target = 'log_soc_stock'\n",
    "    X = df.drop(columns=[target, 'X_coord', 'Y_coord', 'site_info_id'], errors='ignore')\n",
    "    y = df[target].values\n",
    "    coords = df[['X_coord', 'Y_coord']].values\n",
    "\n",
    "    ok_metrics = loo_validate_ok(coords, y, variogram_params, model=variogram_model)\n",
    "    hybrid_metrics = loo_validate_rf_ok(X, y, coords, variogram_params)\n",
    "\n",
    "    results.append({'subset': i, 'model': 'OK_LOO', **ok_metrics})\n",
    "    results.append({'subset': i, 'model': 'RF+OK_LOO', **hybrid_metrics})\n",
    "\n",
    "# =========================================================\n",
    "# SAVE & DISPLAY RESULTS\n",
    "# =========================================================\n",
    "results_df = pd.DataFrame(results)\n",
    "out_path = os.path.join(output_dir, \"ok_rfok_calibration_results.csv\")\n",
    "results_df.to_csv(out_path, index=False)\n",
    "\n",
    "print(f\"\\nğŸ“ Calibration results saved to: {out_path}\")\n",
    "print(\"âœ… Calibration complete.\\n\")\n",
    "\n",
    "print(\"Summary (mean across 5 subsets):\")\n",
    "print(results_df.groupby(\"model\")[[\"R2\", \"RMSE\", \"MAE\"]].mean().round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## full dc runs\n",
    "\n",
    "# =========================================================\n",
    "# STEP â€” Decluster modeling loop with Spatial K-Fold & LOO\n",
    "# =========================================================\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import KFold\n",
    "from pykrige.ok import OrdinaryKriging\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# =========================================================\n",
    "# PATHS AND PARAMETERS\n",
    "# =========================================================\n",
    "decluster_dir = \"/Users/inesschwartz/Desktop/model/decluster_runs\"\n",
    "output_dir = \"/Users/inesschwartz/Desktop/model/results_final\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Random Forest tuned parameters\n",
    "rf_params = {\n",
    "    'n_estimators': 1500,\n",
    "    'min_samples_leaf': 3,\n",
    "    'max_features': 0.5,\n",
    "    'max_depth': None,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "# Variogram parameters (from your calibration step)\n",
    "variogram_model = 'exponential'\n",
    "variogram_params = {'nugget': 0.0022, 'sill': 0.22, 'range': 15000}\n",
    "\n",
    "# =========================================================\n",
    "# HELPER FUNCTIONS\n",
    "# =========================================================\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    \"\"\"Compute standard regression metrics.\"\"\"\n",
    "    return {\n",
    "        'R2': r2_score(y_true, y_pred),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        'MAE': mean_absolute_error(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "\n",
    "def spatial_kfold(coords, n_splits=5):\n",
    "    \"\"\"\n",
    "    Custom spatial K-Fold generator.\n",
    "    Splits data into roughly spatially distinct clusters\n",
    "    by sorting coordinates and splitting sequentially.\n",
    "    \"\"\"\n",
    "    # Sort by X + Y coordinate to ensure spatial grouping\n",
    "    idx = np.argsort(coords[:, 0] + coords[:, 1])\n",
    "    fold_sizes = np.full(n_splits, len(coords) // n_splits, dtype=int)\n",
    "    fold_sizes[:len(coords) % n_splits] += 1\n",
    "    current = 0\n",
    "    folds = []\n",
    "    for fold_size in fold_sizes:\n",
    "        start, stop = current, current + fold_size\n",
    "        test_idx = idx[start:stop]\n",
    "        train_idx = np.setdiff1d(np.arange(len(coords)), test_idx)\n",
    "        folds.append((train_idx, test_idx))\n",
    "        current = stop\n",
    "    return folds\n",
    "\n",
    "\n",
    "def cross_validate_rf_spatial(X, y, coords, n_splits=5):\n",
    "    \"\"\"Spatial K-Fold cross-validation for Random Forest.\"\"\"\n",
    "    folds = spatial_kfold(coords, n_splits)\n",
    "    metrics = []\n",
    "    for train_idx, test_idx in folds:\n",
    "        rf = RandomForestRegressor(**rf_params)\n",
    "        rf.fit(X.iloc[train_idx], y[train_idx])\n",
    "        y_pred = rf.predict(X.iloc[test_idx])\n",
    "        metrics.append(compute_metrics(y[test_idx], y_pred))\n",
    "    return pd.DataFrame(metrics).mean().to_dict()\n",
    "\n",
    "\n",
    "def loo_validate_ok(coords, values, variogram_params, model='exponential'):\n",
    "    \"\"\"Leave-One-Out Cross-Validation for Ordinary Kriging.\"\"\"\n",
    "    preds = np.zeros(len(values))\n",
    "    for i in range(len(values)):\n",
    "        mask = np.ones(len(values), dtype=bool)\n",
    "        mask[i] = False\n",
    "\n",
    "        ok = OrdinaryKriging(\n",
    "            x=coords[mask, 0],\n",
    "            y=coords[mask, 1],\n",
    "            z=values[mask],\n",
    "            variogram_model=model,\n",
    "            variogram_parameters=[\n",
    "                variogram_params['sill'],\n",
    "                variogram_params['range'],\n",
    "                variogram_params['nugget']\n",
    "            ],\n",
    "            enable_plotting=False,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        zhat, _ = ok.execute('points',\n",
    "                             np.array([coords[i, 0]]),\n",
    "                             np.array([coords[i, 1]]))\n",
    "        preds[i] = zhat.data[0]\n",
    "\n",
    "    return compute_metrics(values, preds)\n",
    "\n",
    "\n",
    "def loo_validate_rf_ok(X, y, coords, variogram_params):\n",
    "    \"\"\"Leave-One-Out validation for hybrid RF+OK (residual kriging).\"\"\"\n",
    "    preds = np.zeros(len(y))\n",
    "    for i in range(len(y)):\n",
    "        mask = np.ones(len(y), dtype=bool)\n",
    "        mask[i] = False\n",
    "\n",
    "        rf = RandomForestRegressor(**rf_params)\n",
    "        rf.fit(X.iloc[mask], y[mask])\n",
    "        y_pred_rf = rf.predict(X.iloc[mask])\n",
    "        residuals = y[mask] - y_pred_rf\n",
    "\n",
    "        ok = OrdinaryKriging(\n",
    "            x=coords[mask, 0],\n",
    "            y=coords[mask, 1],\n",
    "            z=residuals,\n",
    "            variogram_model='exponential',\n",
    "            variogram_parameters=[\n",
    "                variogram_params['sill'],\n",
    "                variogram_params['range'],\n",
    "                variogram_params['nugget']\n",
    "            ],\n",
    "            enable_plotting=False,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        zhat, _ = ok.execute('points',\n",
    "                             np.array([coords[i, 0]]),\n",
    "                             np.array([coords[i, 1]]))\n",
    "        yhat_hybrid = rf.predict(X.iloc[[i]])[0] + zhat.data[0]\n",
    "        preds[i] = yhat_hybrid\n",
    "\n",
    "    return compute_metrics(y, preds)\n",
    "\n",
    "# =========================================================\n",
    "# MAIN CALIBRATION LOOP # can take out now that I ran and liked the results?\n",
    "# =========================================================\n",
    "files = sorted(glob.glob(os.path.join(decluster_dir, \"decluster_run_*.csv\")))[:5]\n",
    "results = []\n",
    "\n",
    "print(f\"ğŸ” Running OK and RF+OK (LOO) for {len(files)} declustered subsets...\")\n",
    "\n",
    "for i, file in enumerate(tqdm(files, desc=\"Calibration progress\", ncols=100), start=1):\n",
    "    df = pd.read_csv(file)\n",
    "    target = 'log_soc_stock'\n",
    "    X = df.drop(columns=[target, 'X_coord', 'Y_coord', 'site_info_id'], errors='ignore')\n",
    "    y = df[target].values\n",
    "    coords = df[['X_coord', 'Y_coord']].values\n",
    "\n",
    "    ok_metrics = loo_validate_ok(coords, y, variogram_params, model=variogram_model)\n",
    "    hybrid_metrics = loo_validate_rf_ok(X, y, coords, variogram_params)\n",
    "\n",
    "    results.append({'subset': i, 'model': 'OK_LOO', **ok_metrics})\n",
    "    results.append({'subset': i, 'model': 'RF+OK_LOO', **hybrid_metrics})\n",
    "\n",
    "# =========================================================\n",
    "# SAVE & DISPLAY RESULTS\n",
    "# =========================================================\n",
    "results_df = pd.DataFrame(results)\n",
    "out_path = os.path.join(output_dir, \"ok_rfok_calibration_results.csv\")\n",
    "results_df.to_csv(out_path, index=False)\n",
    "\n",
    "print(f\"\\nğŸ“ Calibration results saved to: {out_path}\")\n",
    "print(\"âœ… Calibration complete.\\n\")\n",
    "\n",
    "print(\"Summary (mean across 5 subsets):\")\n",
    "print(results_df.groupby(\"model\")[[\"R2\", \"RMSE\", \"MAE\"]].mean().round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final map prediction using RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Training samples: 725\n",
      "âœ… Prediction grid points: 1252955\n",
      "ğŸ¯ Final Random Forest model trained on full dataset.\n",
      "ğŸ“ˆ Predictions completed â€” generating raster...\n",
      "âœ… Final SOC stock map saved to:\n",
      "/Users/inesschwartz/Desktop/model/SOC_RF_final.tif\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# FINAL SOC MAP â€” Random Forest (full model)\n",
    "# =========================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import os\n",
    "\n",
    "# =========================================================\n",
    "# PATHS\n",
    "# =========================================================\n",
    "train_csv = \"/Users/inesschwartz/Desktop/model/train_final.csv\"  # Final training dataset (15 covariates)\n",
    "pred_grid_csv = \"/Users/inesschwartz/Desktop/model/covariates_stack_1km_utm33s.csv\"  # Aligned prediction grid\n",
    "output_raster = \"/Users/inesschwartz/Desktop/model/SOC_RF_final.tif\"\n",
    "\n",
    "# =========================================================\n",
    "# RANDOM FOREST PARAMETERS (from tuning)\n",
    "# =========================================================\n",
    "rf_params = {\n",
    "    \"n_estimators\": 1500,\n",
    "    \"min_samples_leaf\": 3,\n",
    "    \"max_features\": 0.5,\n",
    "    \"max_depth\": None,\n",
    "    \"random_state\": 42,\n",
    "    \"n_jobs\": -1\n",
    "}\n",
    "\n",
    "# =========================================================\n",
    "# 1ï¸âƒ£ LOAD DATA\n",
    "# =========================================================\n",
    "df_train = pd.read_csv(train_csv)\n",
    "df_pred = pd.read_csv(pred_grid_csv)\n",
    "\n",
    "target = \"log_soc_stock\"\n",
    "\n",
    "# Define same feature order as used during training\n",
    "features = [\n",
    "    \"MRRTF\", \"MRVBF\", \"annual_precip\", \"grazing_1950\", \"cropland_1950\",\n",
    "    \"precip_wettest_month\", \"relief_TRI\", \"standardized_height\", \"temp_annual_range\",\n",
    "    \"terrain_surf_convexity\", \"terrain_surf_texture\", \"tmax_mean\", \"valley_depth\",\n",
    "    \"faosoil_id\", \"slope_height\"\n",
    "]\n",
    "\n",
    "# Make sure both datasets have same columns and order\n",
    "X_train = df_train[features].copy()\n",
    "y_train = df_train[target].copy()\n",
    "X_pred = df_pred[features].copy()\n",
    "\n",
    "print(f\"âœ… Training samples: {len(df_train)}\")\n",
    "print(f\"âœ… Prediction grid points: {len(df_pred)}\")\n",
    "\n",
    "# =========================================================\n",
    "# 2ï¸âƒ£ TRAIN FINAL RF MODEL\n",
    "# =========================================================\n",
    "rf = RandomForestRegressor(**rf_params)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"ğŸ¯ Final Random Forest model trained on full dataset.\")\n",
    "\n",
    "# =========================================================\n",
    "# 3ï¸âƒ£ PREDICT OVER 1 KM GRID\n",
    "# =========================================================\n",
    "df_pred[\"pred_log_soc\"] = rf.predict(X_pred)\n",
    "df_pred[\"pred_soc\"] = np.exp(df_pred[\"pred_log_soc\"])  # back-transform log SOC if applicable\n",
    "\n",
    "print(\"ğŸ“ˆ Predictions completed â€” generating raster...\")\n",
    "\n",
    "# =========================================================\n",
    "# 4ï¸âƒ£ CREATE OUTPUT RASTER\n",
    "# =========================================================\n",
    "# Load any aligned reference raster for transform and shape\n",
    "ref_raster = \"/Volumes/One_Touch/angola_soils_thesis/GIS_Angola/data_processed/covariates_rasters/terraincovs/slope_height.tif\"\n",
    "\n",
    "with rasterio.open(ref_raster) as ref:\n",
    "    profile = ref.profile\n",
    "    transform = ref.transform\n",
    "    width = ref.width\n",
    "    height = ref.height\n",
    "    crs = ref.crs\n",
    "\n",
    "# Create an empty raster grid and fill values\n",
    "soc_pred_raster = np.full((height, width), np.nan, dtype=\"float32\")\n",
    "\n",
    "# Convert coordinates to row/col\n",
    "rows, cols = rasterio.transform.rowcol(transform, df_pred[\"X_coord\"], df_pred[\"Y_coord\"])\n",
    "valid_mask = (np.array(rows) >= 0) & (np.array(rows) < height) & (np.array(cols) >= 0) & (np.array(cols) < width)\n",
    "\n",
    "soc_pred_raster[rows[valid_mask], cols[valid_mask]] = df_pred.loc[valid_mask, \"pred_soc\"]\n",
    "\n",
    "# Update raster metadata\n",
    "profile.update(dtype=\"float32\", count=1, compress=\"lzw\", nodata=np.nan)\n",
    "\n",
    "# Write raster\n",
    "with rasterio.open(output_raster, \"w\", **profile) as dst:\n",
    "    dst.write(soc_pred_raster, 1)\n",
    "\n",
    "print(f\"âœ… Final SOC stock map saved to:\\n{output_raster}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Reference grid: 1379 Ã— 1532 | CRS: EPSG:32733\n",
      "ğŸ“‚ Found 50 prediction files.\n",
      "âœ… Loaded iteration 01: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_001.csv\n",
      "âœ… Loaded iteration 02: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_002.csv\n",
      "âœ… Loaded iteration 03: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_003.csv\n",
      "âœ… Loaded iteration 04: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_004.csv\n",
      "âœ… Loaded iteration 05: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_005.csv\n",
      "âœ… Loaded iteration 06: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_006.csv\n",
      "âœ… Loaded iteration 07: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_007.csv\n",
      "âœ… Loaded iteration 08: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_008.csv\n",
      "âœ… Loaded iteration 09: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_009.csv\n",
      "âœ… Loaded iteration 10: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_010.csv\n",
      "âœ… Loaded iteration 11: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_011.csv\n",
      "âœ… Loaded iteration 12: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_012.csv\n",
      "âœ… Loaded iteration 13: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_013.csv\n",
      "âœ… Loaded iteration 14: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_014.csv\n",
      "âœ… Loaded iteration 15: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_015.csv\n",
      "âœ… Loaded iteration 16: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_016.csv\n",
      "âœ… Loaded iteration 17: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_017.csv\n",
      "âœ… Loaded iteration 18: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_018.csv\n",
      "âœ… Loaded iteration 19: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_019.csv\n",
      "âœ… Loaded iteration 20: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_020.csv\n",
      "âœ… Loaded iteration 21: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_021.csv\n",
      "âœ… Loaded iteration 22: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_022.csv\n",
      "âœ… Loaded iteration 23: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_023.csv\n",
      "âœ… Loaded iteration 24: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_024.csv\n",
      "âœ… Loaded iteration 25: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_025.csv\n",
      "âœ… Loaded iteration 26: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_026.csv\n",
      "âœ… Loaded iteration 27: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_027.csv\n",
      "âœ… Loaded iteration 28: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_028.csv\n",
      "âœ… Loaded iteration 29: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_029.csv\n",
      "âœ… Loaded iteration 30: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_030.csv\n",
      "âœ… Loaded iteration 31: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_031.csv\n",
      "âœ… Loaded iteration 32: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_032.csv\n",
      "âœ… Loaded iteration 33: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_033.csv\n",
      "âœ… Loaded iteration 34: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_034.csv\n",
      "âœ… Loaded iteration 35: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_035.csv\n",
      "âœ… Loaded iteration 36: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_036.csv\n",
      "âœ… Loaded iteration 37: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_037.csv\n",
      "âœ… Loaded iteration 38: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_038.csv\n",
      "âœ… Loaded iteration 39: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_039.csv\n",
      "âœ… Loaded iteration 40: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_040.csv\n",
      "âœ… Loaded iteration 41: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_041.csv\n",
      "âœ… Loaded iteration 42: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_042.csv\n",
      "âœ… Loaded iteration 43: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_043.csv\n",
      "âœ… Loaded iteration 44: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_044.csv\n",
      "âœ… Loaded iteration 45: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_045.csv\n",
      "âœ… Loaded iteration 46: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_046.csv\n",
      "âœ… Loaded iteration 47: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_047.csv\n",
      "âœ… Loaded iteration 48: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_048.csv\n",
      "âœ… Loaded iteration 49: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_049.csv\n",
      "âœ… Loaded iteration 50: /Users/inesschwartz/Desktop/model/predictions/predictions_iter_050.csv\n",
      "âœ… Saved SOC_RF_mean raster â†’ /Users/inesschwartz/Desktop/model/ensemble_maps/SOC_RF_mean.tif\n",
      "âœ… Saved SOC_RF_std raster â†’ /Users/inesschwartz/Desktop/model/ensemble_maps/SOC_RF_std.tif\n",
      "âœ… Saved SOC_RFOK_mean raster â†’ /Users/inesschwartz/Desktop/model/ensemble_maps/SOC_RFOK_mean.tif\n",
      "âœ… Saved SOC_RFOK_std raster â†’ /Users/inesschwartz/Desktop/model/ensemble_maps/SOC_RFOK_std.tif\n",
      "\n",
      "ğŸ‰ Ensemble mean and uncertainty rasters created successfully!\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# SOC Ensemble Uncertainty Map (RF and RF+OK)\n",
    "# =========================================================\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio.transform import rowcol\n",
    "\n",
    "# --- Paths ---\n",
    "pred_dir = \"/Users/inesschwartz/Desktop/model/predictions\"\n",
    "ref_raster = \"/Volumes/One_Touch/angola_soils_thesis/GIS_Angola/data_processed/covariates_rasters/terraincovs/slope_height.tif\"\n",
    "out_dir = \"/Users/inesschwartz/Desktop/model/ensemble_maps\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# --- Load reference raster for spatial alignment ---\n",
    "with rasterio.open(ref_raster) as ref:\n",
    "    profile = ref.profile\n",
    "    transform = ref.transform\n",
    "    width, height = ref.width, ref.height\n",
    "    crs = ref.crs\n",
    "\n",
    "print(f\"ğŸ“ Reference grid: {width} Ã— {height} | CRS: {crs}\")\n",
    "\n",
    "# --- Collect all prediction CSVs ---\n",
    "csv_files = sorted(glob.glob(os.path.join(pred_dir, \"predictions_iter_*.csv\")))\n",
    "print(f\"ğŸ“‚ Found {len(csv_files)} prediction files.\")\n",
    "\n",
    "# --- Containers ---\n",
    "rf_preds, rfok_preds = [], []\n",
    "coords_ref = None\n",
    "\n",
    "# --- Read each decluster prediction ---\n",
    "for i, f in enumerate(csv_files, start=1):\n",
    "    df = pd.read_csv(f)\n",
    "    if coords_ref is None:\n",
    "        coords_ref = df[['X_coord', 'Y_coord']].copy()\n",
    "    rf_preds.append(df['pred_RF'].values)\n",
    "    rfok_preds.append(df['pred_RF_OK'].values)\n",
    "    print(f\"âœ… Loaded iteration {i:02d}: {f}\")\n",
    "\n",
    "# --- Stack predictions ---\n",
    "rf_stack = np.column_stack(rf_preds)\n",
    "rfok_stack = np.column_stack(rfok_preds)\n",
    "\n",
    "# --- Compute ensemble statistics ---\n",
    "rf_mean = np.nanmean(rf_stack, axis=1)\n",
    "rf_std = np.nanstd(rf_stack, axis=1)\n",
    "rfok_mean = np.nanmean(rfok_stack, axis=1)\n",
    "rfok_std = np.nanstd(rfok_stack, axis=1)\n",
    "\n",
    "# --- Create raster arrays ---\n",
    "rf_mean_raster = np.full((height, width), np.nan, dtype=\"float32\")\n",
    "rf_std_raster = np.full((height, width), np.nan, dtype=\"float32\")\n",
    "rfok_mean_raster = np.full((height, width), np.nan, dtype=\"float32\")\n",
    "rfok_std_raster = np.full((height, width), np.nan, dtype=\"float32\")\n",
    "\n",
    "# --- Convert coordinates to row/col positions ---\n",
    "rows, cols = rasterio.transform.rowcol(transform, coords_ref[\"X_coord\"], coords_ref[\"Y_coord\"])\n",
    "valid_mask = (\n",
    "    (np.array(rows) >= 0)\n",
    "    & (np.array(rows) < height)\n",
    "    & (np.array(cols) >= 0)\n",
    "    & (np.array(cols) < width)\n",
    ")\n",
    "\n",
    "rf_mean_raster[rows[valid_mask], cols[valid_mask]] = rf_mean[valid_mask]\n",
    "rf_std_raster[rows[valid_mask], cols[valid_mask]] = rf_std[valid_mask]\n",
    "rfok_mean_raster[rows[valid_mask], cols[valid_mask]] = rfok_mean[valid_mask]\n",
    "rfok_std_raster[rows[valid_mask], cols[valid_mask]] = rfok_std[valid_mask]\n",
    "\n",
    "# --- Update profile ---\n",
    "profile.update(dtype=\"float32\", count=1, compress=\"lzw\", nodata=np.nan)\n",
    "\n",
    "# --- Save rasters ---\n",
    "out_paths = {\n",
    "    \"SOC_RF_mean\": rf_mean_raster,\n",
    "    \"SOC_RF_std\": rf_std_raster,\n",
    "    \"SOC_RFOK_mean\": rfok_mean_raster,\n",
    "    \"SOC_RFOK_std\": rfok_std_raster,\n",
    "}\n",
    "\n",
    "for name, arr in out_paths.items():\n",
    "    out_path = os.path.join(out_dir, f\"{name}.tif\")\n",
    "    with rasterio.open(out_path, \"w\", **profile) as dst:\n",
    "        dst.write(arr, 1)\n",
    "    print(f\"âœ… Saved {name} raster â†’ {out_path}\")\n",
    "\n",
    "print(\"\\nğŸ‰ Ensemble mean and uncertainty rasters created successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
