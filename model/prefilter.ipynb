{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature selection pre filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial number of samples: 909\n",
      "Initial number of covariates: 74\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# 01. Data setup + global pre-filtering of covariates\n",
    "# =========================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# STEP 1 — Set up inputs\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# Example input file: your SOC sample data joined with covariates\n",
    "# Each row = sample point; includes coordinates, SOC value, and 75 covariates\n",
    "# Example columns: ['site_info_id', 'X_coord', 'Y_coord', 'log_soc_stock', 'cov1', 'cov2', ..., 'cov75']\n",
    "input_csv = \"/Users/inesschwartz/Desktop/final_training_dataset.csv\"\n",
    "df = pd.read_csv(input_csv)\n",
    "\n",
    "# Quick check\n",
    "print(f\"Initial number of samples: {len(df)}\")\n",
    "print(f\"Initial number of covariates: {df.shape[1] - 4}\")  # assuming first 4 cols = id, coords, log_soc_stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_soc_stock</th>\n",
       "      <th>site_info_id</th>\n",
       "      <th>X_coord</th>\n",
       "      <th>Y_coord</th>\n",
       "      <th>year</th>\n",
       "      <th>faosoil_id</th>\n",
       "      <th>landsurface_value</th>\n",
       "      <th>litho_value</th>\n",
       "      <th>formation</th>\n",
       "      <th>conv_rangeland_1950</th>\n",
       "      <th>...</th>\n",
       "      <th>slope_height</th>\n",
       "      <th>slope_length</th>\n",
       "      <th>standardized_height</th>\n",
       "      <th>terrain_surf_convexity</th>\n",
       "      <th>terrain_surf_texture</th>\n",
       "      <th>total_curve</th>\n",
       "      <th>twi</th>\n",
       "      <th>valley_depth</th>\n",
       "      <th>valley_index</th>\n",
       "      <th>watershed_basins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.260593</td>\n",
       "      <td>2139.0</td>\n",
       "      <td>637881.888723</td>\n",
       "      <td>8.608926e+06</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>79.743690</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>952.486816</td>\n",
       "      <td>49.512749</td>\n",
       "      <td>77.167595</td>\n",
       "      <td>1.178243e-09</td>\n",
       "      <td>5.827370</td>\n",
       "      <td>64.605621</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4340.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.659299</td>\n",
       "      <td>1927.0</td>\n",
       "      <td>385725.693290</td>\n",
       "      <td>8.669325e+06</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>209.757782</td>\n",
       "      <td>3414.213623</td>\n",
       "      <td>50.189114</td>\n",
       "      <td>43.616150</td>\n",
       "      <td>72.120461</td>\n",
       "      <td>8.122644e-10</td>\n",
       "      <td>8.748525</td>\n",
       "      <td>501.486071</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3570.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>248538.636350</td>\n",
       "      <td>9.488118e+06</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>17.13189</td>\n",
       "      <td>...</td>\n",
       "      <td>167.649002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>72.041985</td>\n",
       "      <td>39.723015</td>\n",
       "      <td>71.185776</td>\n",
       "      <td>4.263759e-10</td>\n",
       "      <td>5.255396</td>\n",
       "      <td>260.212341</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7588.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.972043</td>\n",
       "      <td>1701.0</td>\n",
       "      <td>840008.131292</td>\n",
       "      <td>8.731220e+06</td>\n",
       "      <td>1963.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>92.101753</td>\n",
       "      <td>4828.427246</td>\n",
       "      <td>509.570862</td>\n",
       "      <td>44.910591</td>\n",
       "      <td>72.663414</td>\n",
       "      <td>2.168373e-10</td>\n",
       "      <td>7.329942</td>\n",
       "      <td>111.684311</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5267.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.333861</td>\n",
       "      <td>1934.0</td>\n",
       "      <td>384135.495798</td>\n",
       "      <td>8.666721e+06</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>229.889511</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>69.800308</td>\n",
       "      <td>45.813786</td>\n",
       "      <td>71.682632</td>\n",
       "      <td>2.845996e-10</td>\n",
       "      <td>5.054585</td>\n",
       "      <td>501.486071</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3570.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   log_soc_stock  site_info_id        X_coord       Y_coord    year  \\\n",
       "0       1.260593        2139.0  637881.888723  8.608926e+06  1956.0   \n",
       "1       1.659299        1927.0  385725.693290  8.669325e+06  1958.0   \n",
       "2       0.000000          17.0  248538.636350  9.488118e+06  1959.0   \n",
       "3       0.972043        1701.0  840008.131292  8.731220e+06  1963.0   \n",
       "4       1.333861        1934.0  384135.495798  8.666721e+06  1958.0   \n",
       "\n",
       "   faosoil_id  landsurface_value  litho_value  formation  conv_rangeland_1950  \\\n",
       "0        43.0                2.0          2.0       97.0              0.00000   \n",
       "1       120.0                2.0          2.0      123.0              0.00000   \n",
       "2         8.0                2.0          2.0       66.0             17.13189   \n",
       "3        40.0                1.0          1.0       96.0              0.00000   \n",
       "4       120.0                2.0          2.0      123.0              0.00000   \n",
       "\n",
       "   ...  slope_height  slope_length  standardized_height  \\\n",
       "0  ...     79.743690   3000.000000           952.486816   \n",
       "1  ...    209.757782   3414.213623            50.189114   \n",
       "2  ...    167.649002      0.000000            72.041985   \n",
       "3  ...     92.101753   4828.427246           509.570862   \n",
       "4  ...    229.889511      0.000000            69.800308   \n",
       "\n",
       "   terrain_surf_convexity  terrain_surf_texture   total_curve       twi  \\\n",
       "0               49.512749             77.167595  1.178243e-09  5.827370   \n",
       "1               43.616150             72.120461  8.122644e-10  8.748525   \n",
       "2               39.723015             71.185776  4.263759e-10  5.255396   \n",
       "3               44.910591             72.663414  2.168373e-10  7.329942   \n",
       "4               45.813786             71.682632  2.845996e-10  5.054585   \n",
       "\n",
       "   valley_depth  valley_index  watershed_basins  \n",
       "0     64.605621           0.0            4340.0  \n",
       "1    501.486071           0.0            3570.0  \n",
       "2    260.212341           0.0            7588.0  \n",
       "3    111.684311           0.0            5267.0  \n",
       "4    501.486071           0.0            3570.0  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 727, Test samples: 182\n",
      "Removed 9 near-zero variance variables.\n",
      "Removed 21 highly correlated variables (|r| > 0.8).\n",
      "Removing year (VIF = 16758.97)\n",
      "Removing max_temp_warmest_month (VIF = 3729.61)\n",
      "Removing hillshade (VIF = 2351.14)\n",
      "Skipping removal of protected variable: tmax_mean (VIF = 1341.61)\n",
      "Removing mean_temp_coldest_quarter (VIF = 845.74)\n",
      "Removing grazing_1950 (VIF = 570.07)\n",
      "Skipping removal of protected variable: tmax_mean (VIF = 525.95)\n",
      "Removing isothermality (VIF = 361.79)\n",
      "Skipping removal of protected variable: tmax_mean (VIF = 358.40)\n",
      "Skipping removal of protected variable: normalized_height (VIF = 271.55)\n",
      "Skipping removal of protected variable: annual_precip (VIF = 186.32)\n",
      "Removing precip_wettest_month (VIF = 178.46)\n",
      "Skipping removal of protected variable: tmax_mean (VIF = 356.57)\n",
      "Skipping removal of protected variable: normalized_height (VIF = 262.38)\n",
      "Skipping removal of protected variable: terrain_surf_convexity (VIF = 142.82)\n",
      "Skipping removal of protected variable: annual_precip (VIF = 64.15)\n",
      "Skipping removal of protected variable: twi (VIF = 63.90)\n",
      "Removing slope_height (VIF = 49.06)\n",
      "Skipping removal of protected variable: tmax_mean (VIF = 329.69)\n",
      "Skipping removal of protected variable: terrain_surf_convexity (VIF = 140.92)\n",
      "Skipping removal of protected variable: normalized_height (VIF = 67.41)\n",
      "Skipping removal of protected variable: twi (VIF = 63.89)\n",
      "Skipping removal of protected variable: annual_precip (VIF = 62.48)\n",
      "Skipping removal of protected variable: terrain_surf_texture (VIF = 43.13)\n",
      "Removing temp_seasonality (VIF = 33.50)\n",
      "Skipping removal of protected variable: tmax_mean (VIF = 270.62)\n",
      "Skipping removal of protected variable: terrain_surf_convexity (VIF = 133.28)\n",
      "Skipping removal of protected variable: normalized_height (VIF = 64.47)\n",
      "Skipping removal of protected variable: twi (VIF = 62.97)\n",
      "Skipping removal of protected variable: annual_precip (VIF = 57.64)\n",
      "Skipping removal of protected variable: terrain_surf_texture (VIF = 42.99)\n",
      "Skipping removal of protected variable: MRVBF (VIF = 28.09)\n",
      "Removing precip_warmest_quarter (VIF = 25.16)\n",
      "Skipping removal of protected variable: tmax_mean (VIF = 264.32)\n",
      "Skipping removal of protected variable: terrain_surf_convexity (VIF = 132.75)\n",
      "Skipping removal of protected variable: normalized_height (VIF = 64.47)\n",
      "Skipping removal of protected variable: twi (VIF = 62.96)\n",
      "Skipping removal of protected variable: annual_precip (VIF = 51.22)\n",
      "Skipping removal of protected variable: terrain_surf_texture (VIF = 42.66)\n",
      "Skipping removal of protected variable: MRVBF (VIF = 27.97)\n",
      "Removing watershed_basins (VIF = 21.01)\n",
      "Skipping removal of protected variable: tmax_mean (VIF = 259.16)\n",
      "Skipping removal of protected variable: terrain_surf_convexity (VIF = 131.18)\n",
      "Skipping removal of protected variable: normalized_height (VIF = 64.42)\n",
      "Skipping removal of protected variable: twi (VIF = 62.92)\n",
      "Skipping removal of protected variable: annual_precip (VIF = 43.70)\n",
      "Skipping removal of protected variable: terrain_surf_texture (VIF = 40.81)\n",
      "Skipping removal of protected variable: MRVBF (VIF = 24.92)\n",
      "Remaining covariates after VIF filtering: 33\n",
      "Final covariate count (after protections): 33\n",
      "\n",
      "✅ Pre-filtering complete! Protected variables retained:\n",
      "['annual_precip', 'tmax_mean', 'twi', 'MRVBF', 'terrain_surf_convexity', 'terrain_surf_texture', 'normalized_height']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# STEP 2 — Hold out 20% test data (independent validation set)\n",
    "# ---------------------------------------------------------\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Save for later use\n",
    "train_df.to_csv(\"/Users/inesschwartz/Desktop/model/train_data.csv\", index=False)\n",
    "test_df.to_csv(\"/Users/inesschwartz/Desktop/model/test_data.csv\", index=False)\n",
    "\n",
    "print(f\"Training samples: {len(train_df)}, Test samples: {len(test_df)}\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# STEP 3 — Global pre-filtering of covariates (with protected variables)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# Define which columns are covariates\n",
    "non_covariates = ['site_info_id', 'X_coord', 'Y_coord', 'log_soc_stock']\n",
    "covariate_cols = [c for c in df.columns if c not in non_covariates]\n",
    "\n",
    "# List of expert-recommended covariates to KEEP no matter what\n",
    "protected_vars = [\n",
    "    \"annual_precip\",\n",
    "    \"tmax_mean\",\n",
    "    \"twi\",\n",
    "    \"MRVBF\",\n",
    "    \"terrain_surf_convexity\",\n",
    "    \"terrain_surf_texture\",\n",
    "    \"normalized_height\"\n",
    "]\n",
    "\n",
    "# --- 3A. Remove near-zero variance predictors ---\n",
    "var_threshold = 1e-5\n",
    "variances = train_df[covariate_cols].var()\n",
    "low_var = variances[variances < var_threshold].index.tolist()\n",
    "low_var = [v for v in low_var if v not in protected_vars]  # never drop protected\n",
    "print(f\"Removed {len(low_var)} near-zero variance variables.\")\n",
    "\n",
    "filtered_covs = [c for c in covariate_cols if c not in low_var]\n",
    "\n",
    "# --- 3B. Remove highly correlated variables (|r| > 0.8) ---\n",
    "corr_matrix = train_df[filtered_covs].corr().abs()\n",
    "upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "to_drop_corr = [col for col in upper_tri.columns if any(upper_tri[col] > 0.8)]\n",
    "# keep protected variables\n",
    "to_drop_corr = [v for v in to_drop_corr if v not in protected_vars]\n",
    "print(f\"Removed {len(to_drop_corr)} highly correlated variables (|r| > 0.8).\")\n",
    "\n",
    "filtered_covs = [c for c in filtered_covs if c not in to_drop_corr]\n",
    "\n",
    "# --- 3C. VIF filtering (relaxed, protected variables never dropped) ---\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "def calculate_vif(df_subset):\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"Variable\"] = df_subset.columns\n",
    "    vif_data[\"VIF\"] = [\n",
    "        variance_inflation_factor(df_subset.values, i)\n",
    "        for i in range(df_subset.shape[1])\n",
    "    ]\n",
    "    return vif_data\n",
    "\n",
    "X = train_df[filtered_covs].dropna().copy()\n",
    "vif_threshold = 20  # relaxed threshold for predictive models\n",
    "\n",
    "vif = calculate_vif(X)\n",
    "\n",
    "while vif[\"VIF\"].max() > vif_threshold:\n",
    "    remove_var = vif.loc[vif[\"VIF\"].idxmax(), \"Variable\"]\n",
    "    # skip removal if variable is protected\n",
    "    if remove_var in protected_vars:\n",
    "        print(f\"Skipping removal of protected variable: {remove_var} (VIF = {vif['VIF'].max():.2f})\")\n",
    "        # artificially lower its VIF to break potential infinite loop\n",
    "        vif.loc[vif['Variable'] == remove_var, 'VIF'] = vif_threshold - 0.1\n",
    "        continue\n",
    "    print(f\"Removing {remove_var} (VIF = {vif['VIF'].max():.2f})\")\n",
    "    filtered_covs.remove(remove_var)\n",
    "    vif = calculate_vif(X[filtered_covs])\n",
    "\n",
    "print(f\"Remaining covariates after VIF filtering: {len(filtered_covs)}\")\n",
    "\n",
    "# Ensure all protected variables are included\n",
    "for v in protected_vars:\n",
    "    if v not in filtered_covs and v in covariate_cols:\n",
    "        filtered_covs.append(v)\n",
    "        print(f\"Re-added protected variable: {v}\")\n",
    "\n",
    "print(f\"Final covariate count (after protections): {len(filtered_covs)}\")\n",
    "\n",
    "# Save outputs\n",
    "pd.Series(filtered_covs, name=\"covariate\").to_csv(\"/Users/inesschwartz/Desktop/model/filtered_covariates.csv\", index=False)\n",
    "train_filtered = train_df[non_covariates + filtered_covs]\n",
    "train_filtered.to_csv(\"/Users/inesschwartz/Desktop/model/train_filtered.csv\", index=False)\n",
    "\n",
    "print(\"\\n✅ Pre-filtering complete! Protected variables retained:\")\n",
    "print(protected_vars)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
