{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature selection pre filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial number of samples: 907\n",
      "Initial number of covariates: 62\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# 01. Data setup + global pre-filtering of covariates\n",
    "# =========================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# STEP 1 — Set up inputs\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# Example input file: your SOC sample data joined with covariates\n",
    "# Each row = sample point; includes coordinates, SOC value, and 75 covariates\n",
    "# Example columns: ['site_info_id', 'X_coord', 'Y_coord', 'log_soc_stock', 'cov1', 'cov2', ..., 'cov75']\n",
    "input_csv = \"/Users/inesschwartz/Desktop/final_training_dataset1.csv\"\n",
    "df = pd.read_csv(input_csv)\n",
    "\n",
    "# Quick check\n",
    "print(f\"Initial number of samples: {len(df)}\")\n",
    "print(f\"Initial number of covariates: {df.shape[1] - 4}\")  # assuming first 4 cols = id, coords, log_soc_stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['log_soc_stock', 'MRRTF', 'MRVBF', 'X_coord', 'Y_coord',\n",
       "       'annual_mean_temp', 'annual_precip', 'aspect', 'aspect_cos',\n",
       "       'aspect_sin', 'conv_rangeland_1950', 'conv_rangeland_1960',\n",
       "       'cropland_1950', 'cropland_1960', 'dem_1km_utm33s', 'faosoil_id',\n",
       "       'flow_accumulation', 'flow_directions', 'flowline_curve', 'formation',\n",
       "       'general_curve', 'grazing_1950', 'hill_height', 'hillshade',\n",
       "       'hillslope_index', 'isothermality', 'landsurface_value',\n",
       "       'length_slope_factor', 'litho_value', 'max_curve',\n",
       "       'max_temp_warmest_month', 'max_temp_warmest_month.1',\n",
       "       'mean_temp_coldest_quarter', 'midslope_position', 'min_curve',\n",
       "       'normalized_height', 'pasture_1950', 'pasture_1960', 'plan_curve',\n",
       "       'precip_coldest_quarter', 'precip_driest_month',\n",
       "       'precip_driest_quarter', 'precip_seasonality', 'precip_sum',\n",
       "       'precip_warmest_quarter', 'precip_wettest_month', 'profile_curve',\n",
       "       'rangeland_1950', 'rangeland_1960', 'relief_TRI', 'site_info_id',\n",
       "       'slope_height', 'slope_length', 'standardized_height',\n",
       "       'temp_annual_range', 'temp_annual_range.1', 'temp_seasonality',\n",
       "       'terrain_surf_convexity', 'terrain_surf_texture', 'tmax_mean_mean',\n",
       "       'tot_irri_1950', 'total_curve', 'twi', 'valley_depth', 'valley_index',\n",
       "       'year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 725, Test samples: 182\n",
      "Removed 7 near-zero variance variables.\n",
      "Removed 6 highly correlated variables (|r| > 0.8).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing annual_mean_temp (VIF = inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping removal of protected variable: max_temp_warmest_month (VIF = inf)\n",
      "Skipping removal of protected variable: temp_annual_range (VIF = inf)\n",
      "Remaining covariates after VIF filtering: 48\n",
      "Final covariate count (after protections): 48\n",
      "\n",
      "✅ Pre-filtering complete! Protected variables retained:\n",
      "['annual_precip', 'tmax_mean_mean', 'twi', 'MRVBF', 'terrain_surf_convexity', 'terrain_surf_texture', 'normalized_height', 'slope_height', 'litho_value', 'max_temp_warmest_month', 'standardized_height', 'temp_annual_range']\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# STEP 2 — Hold out 20% test data (independent validation set)\n",
    "# ---------------------------------------------------------\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Save for later use\n",
    "train_df.to_csv(\"/Users/inesschwartz/Desktop/model/train_data.csv\", index=False)\n",
    "test_df.to_csv(\"/Users/inesschwartz/Desktop/model/test_data.csv\", index=False)\n",
    "\n",
    "print(f\"Training samples: {len(train_df)}, Test samples: {len(test_df)}\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# STEP 3 — Global pre-filtering of covariates (with protected variables)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# Define which columns are covariates\n",
    "non_covariates = ['site_info_id', 'X_coord', 'Y_coord', 'log_soc_stock']\n",
    "covariate_cols = [c for c in df.columns if c not in non_covariates]\n",
    "\n",
    "# List of expert-recommended covariates to KEEP no matter what\n",
    "protected_vars = [\n",
    "    \"annual_precip\",\n",
    "    \"tmax_mean_mean\",\n",
    "    \"twi\",\n",
    "    \"MRVBF\",\n",
    "    \"terrain_surf_convexity\",\n",
    "    \"terrain_surf_texture\",\n",
    "    \"normalized_height\",\n",
    "    \"slope_height\",\n",
    "    \"litho_value\",\n",
    "    \"max_temp_warmest_month\",\n",
    "    \"standardized_height\",\n",
    "    \"temp_annual_range\"\n",
    "]\n",
    "\n",
    "# --- 3A. Remove near-zero variance predictors ---\n",
    "var_threshold = 1e-5\n",
    "variances = train_df[covariate_cols].var()\n",
    "low_var = variances[variances < var_threshold].index.tolist()\n",
    "low_var = [v for v in low_var if v not in protected_vars]  # never drop protected\n",
    "print(f\"Removed {len(low_var)} near-zero variance variables.\")\n",
    "\n",
    "filtered_covs = [c for c in covariate_cols if c not in low_var]\n",
    "\n",
    "# --- 3B. Remove highly correlated variables (|r| > 0.8) ---\n",
    "corr_matrix = train_df[filtered_covs].corr().abs()\n",
    "upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "to_drop_corr = [col for col in upper_tri.columns if any(upper_tri[col] > 0.8)]\n",
    "# keep protected variables\n",
    "to_drop_corr = [v for v in to_drop_corr if v not in protected_vars]\n",
    "print(f\"Removed {len(to_drop_corr)} highly correlated variables (|r| > 0.8).\")\n",
    "\n",
    "filtered_covs = [c for c in filtered_covs if c not in to_drop_corr]\n",
    "\n",
    "# --- 3C. VIF filtering (relaxed, protected variables never dropped) ---\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "def calculate_vif(df_subset):\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"Variable\"] = df_subset.columns\n",
    "    vif_data[\"VIF\"] = [\n",
    "        variance_inflation_factor(df_subset.values, i)\n",
    "        for i in range(df_subset.shape[1])\n",
    "    ]\n",
    "    return vif_data\n",
    "\n",
    "X = train_df[filtered_covs].dropna().copy()\n",
    "vif_threshold = 40  # relaxed threshold for predictive models\n",
    "\n",
    "vif = calculate_vif(X)\n",
    "\n",
    "while vif[\"VIF\"].max() > vif_threshold:\n",
    "    remove_var = vif.loc[vif[\"VIF\"].idxmax(), \"Variable\"]\n",
    "    # skip removal if variable is protected\n",
    "    if remove_var in protected_vars:\n",
    "        print(f\"Skipping removal of protected variable: {remove_var} (VIF = {vif['VIF'].max():.2f})\")\n",
    "        # artificially lower its VIF to break potential infinite loop\n",
    "        vif.loc[vif['Variable'] == remove_var, 'VIF'] = vif_threshold - 0.1\n",
    "        continue\n",
    "    print(f\"Removing {remove_var} (VIF = {vif['VIF'].max():.2f})\")\n",
    "    filtered_covs.remove(remove_var)\n",
    "    vif = calculate_vif(X[filtered_covs])\n",
    "\n",
    "print(f\"Remaining covariates after VIF filtering: {len(filtered_covs)}\")\n",
    "\n",
    "# Ensure all protected variables are included\n",
    "for v in protected_vars:\n",
    "    if v not in filtered_covs and v in covariate_cols:\n",
    "        filtered_covs.append(v)\n",
    "        print(f\"Re-added protected variable: {v}\")\n",
    "\n",
    "print(f\"Final covariate count (after protections): {len(filtered_covs)}\")\n",
    "\n",
    "# Save outputs\n",
    "pd.Series(filtered_covs, name=\"covariate\").to_csv(\"/Users/inesschwartz/Desktop/model/filtered_covariates.csv\", index=False)\n",
    "train_filtered = train_df[non_covariates + filtered_covs]\n",
    "train_filtered.to_csv(\"/Users/inesschwartz/Desktop/model/train_filtered.csv\", index=False)\n",
    "\n",
    "print(\"\\n✅ Pre-filtering complete! Protected variables retained:\")\n",
    "print(protected_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "site_info_id              0\n",
       "X_coord                   0\n",
       "normalized_height         0\n",
       "pasture_1950              0\n",
       "pasture_1960              0\n",
       "precip_coldest_quarter    0\n",
       "precip_driest_month       0\n",
       "precip_driest_quarter     0\n",
       "precip_seasonality        0\n",
       "precip_sum                0\n",
       "precip_warmest_quarter    0\n",
       "precip_wettest_month      0\n",
       "rangeland_1950            0\n",
       "relief_TRI                0\n",
       "slope_height              0\n",
       "slope_length              0\n",
       "standardized_height       0\n",
       "temp_annual_range         0\n",
       "terrain_surf_convexity    0\n",
       "terrain_surf_texture      0\n",
       "tmax_mean_mean            0\n",
       "tot_irri_1950             0\n",
       "twi                       0\n",
       "valley_depth              0\n",
       "valley_index              0\n",
       "midslope_position         0\n",
       "max_temp_warmest_month    0\n",
       "litho_value               0\n",
       "cropland_1950             0\n",
       "Y_coord                   0\n",
       "log_soc_stock             0\n",
       "MRRTF                     0\n",
       "MRVBF                     0\n",
       "annual_precip             0\n",
       "aspect                    0\n",
       "aspect_cos                0\n",
       "aspect_sin                0\n",
       "conv_rangeland_1950       0\n",
       "conv_rangeland_1960       0\n",
       "dem_1km_utm33s            0\n",
       "length_slope_factor       0\n",
       "faosoil_id                0\n",
       "flow_accumulation         0\n",
       "flow_directions           0\n",
       "formation                 0\n",
       "grazing_1950              0\n",
       "hill_height               0\n",
       "hillshade                 0\n",
       "hillslope_index           0\n",
       "isothermality             0\n",
       "landsurface_value         0\n",
       "year                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#double check for nulls\n",
    "train_filtered.isna().sum().sort_values(ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
