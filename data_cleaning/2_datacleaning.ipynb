{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read in cleaned CSV's\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dateutil.parser import parse\n",
    "\n",
    "#import and read data\n",
    "merged1 = pd.read_csv(\"/Users/inesschwartz/GreenDataScience/Thesis/tables_clean/merged1.csv\")\n",
    "samples1 = pd.read_csv(\"/Users/inesschwartz/Desktop/samples1.csv\")\n",
    "site_info1 = pd.read_csv(\"/Users/inesschwartz/Desktop/site_info1.csv\")\n",
    "morphology1 = pd.read_csv(\"/Users/inesschwartz/Desktop/morpho_cleaned.csv\") #change once translated script ready\n",
    "#profile_loc = pd.read_excel(\"\")\n",
    "#soil_profile = pd.read_excel(\"\")\n",
    "\n",
    "\n",
    "profile_record_clean1 = pd.read_csv(\"/Users/inesschwartz/Desktop/profile_record_clean.csv\") # just matches profile record w profile, 'site_info_id', sample_id', and soil_type_id\n",
    "\n",
    "#soil_type = pd.read_excel(\"/Users/inesschwartz/Desktop/Thesis/tables_soil_database/Perfis_solo.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in original csvs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dateutil.parser import parse\n",
    "\n",
    "#import and read data\n",
    "samples = pd.read_excel(\"/Users/inesschwartz/GreenDataScience/Thesis/tables_soil_database/AmostrasAngolaTerrario.xlsx\")\n",
    "analyses = pd.read_excel(\"/Users/inesschwartz/GreenDataScience/Thesis/tables_soil_database/Horizontes Analises.xlsx\")\n",
    "morphology = pd.read_excel(\"/Users/inesschwartz/GreenDataScience/Thesis/tables_soil_database/Horizontes_Morfologia.xlsx\")\n",
    "profile_loc = pd.read_excel(\"/Users/inesschwartz/GreenDataScience/Thesis/tables_soil_database/Perfis_local.xlsx\")\n",
    "soil_profile = pd.read_excel(\"/Users/inesschwartz/GreenDataScience/Thesis/tables_soil_database/Perfis_solo.xlsx\")\n",
    "elemental_analyses = pd.read_excel(\"/Users/inesschwartz/GreenDataScience/Thesis/tables_soil_database/Data XRF Angola_inicial.xlsx\")\n",
    "#soil_type = pd.read_excel(\"/Users/inesschwartz/Desktop/Thesis/tables_soil_database/Perfis_solo.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean samples data (AmostrasAngolaTerrario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for clarity\n",
    "samples.rename(columns={\n",
    "    'Registo': 'sample_id',\n",
    "    'N¬∫ Campo': 'site_info_id',\n",
    "    'Ano': 'year',\n",
    "    'Perfil': 'profile',\n",
    "    'Campanha': 'campaign',\n",
    "    'Col√≥nia_Pais': 'country',\n",
    "    'Distrito': 'district',\n",
    "    'AmostraCrivada': 'sample_sifted',\n",
    "    'AmostraNaoCrivada': 'sample_not_sifted',\n",
    "    'Prateleira': 'shelf',\n",
    "    'Sala': 'room'\n",
    "}, inplace=True)\n",
    "\n",
    "# Drop unused columns\n",
    "samples_cleaning = samples.drop(columns=[\n",
    "    'campaign', 'country', 'Prov√≠ncia', 'sample_not_sifted', 'sample_sifted', 'Obs'\n",
    "], errors='ignore')\n",
    "\n",
    "# # Add a new Primary Key ID column starting from 1\n",
    "# samples_cleaning.insert(0, 'sample_id', range(1, len(samples_cleaning) + 1))\n",
    "\n",
    "# Add empty FK columns\n",
    "samples_cleaning['lab_info_id'] = pd.NA\n",
    "samples_cleaning['morpho_id'] = pd.NA\n",
    "samples_cleaning['site_info_id'] = pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicates, nulls, datatypes etc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>site_info_id</th>\n",
       "      <th>year</th>\n",
       "      <th>profile</th>\n",
       "      <th>district</th>\n",
       "      <th>shelf</th>\n",
       "      <th>room</th>\n",
       "      <th>lab_info_id</th>\n",
       "      <th>morpho_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>630</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>139</td>\n",
       "      <td>Huambo</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>631</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>139</td>\n",
       "      <td>Huambo</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>632</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>139</td>\n",
       "      <td>Huambo</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>633</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>139</td>\n",
       "      <td>Huambo</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>687</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>208</td>\n",
       "      <td>Huambo</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_id site_info_id    year profile district shelf room lab_info_id  \\\n",
       "0        630         <NA>  1946.0     139   Huambo     1   22        <NA>   \n",
       "1        631         <NA>  1946.0     139   Huambo     1   22        <NA>   \n",
       "2        632         <NA>  1946.0     139   Huambo     1   22        <NA>   \n",
       "3        633         <NA>  1946.0     139   Huambo     1   22        <NA>   \n",
       "4        687         <NA>  1946.0     208   Huambo     1   22        <NA>   \n",
       "\n",
       "  morpho_id  \n",
       "0      <NA>  \n",
       "1      <NA>  \n",
       "2      <NA>  \n",
       "3      <NA>  \n",
       "4      <NA>  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_cleaning.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Duplicate sample_id values:\n",
      "Empty DataFrame\n",
      "Columns: [sample_id]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Ensure consistent types and formatting\n",
    "samples_cleaning['profile'] = samples_cleaning['profile'].astype(str).str.replace('/', '_').str.strip().str[:20]\n",
    "samples_cleaning['shelf'] = samples_cleaning['shelf'].astype(\"string\")\n",
    "\n",
    "#formatting site_info_id\n",
    "samples_cleaning['site_info_id'] = samples_cleaning['site_info_id'].astype(str).str.replace('/', '_').str.strip().str[:20]\n",
    "#formatting morpho_id\n",
    "samples_cleaning['morpho_id'] = samples_cleaning['morpho_id'].astype(str).str.strip().str[:20]\n",
    "#formatting lab_info_id\n",
    "samples_cleaning['lab_info_id'] = samples_cleaning['lab_info_id'].astype(str).str.strip().str[:20]\n",
    "# formatting year\n",
    "samples_cleaning['year'] = samples_cleaning['year'].apply(\n",
    "    lambda x: str(int(x)) if pd.notnull(x) else ''\n",
    ")\n",
    "\n",
    "# Convert sample_id to string (no truncation unless necessary)\n",
    "samples_cleaning['sample_id'] = samples_cleaning['sample_id'].astype(str).str.strip()\n",
    "\n",
    "# Check for duplicates AFTER conversion\n",
    "duplicate_ids = samples_cleaning[samples_cleaning.duplicated('sample_id', keep=False)]\n",
    "print(\"üîç Duplicate sample_id values:\")\n",
    "print(duplicate_ids[['sample_id']])\n",
    "\n",
    "samples_cleaning1 = samples_cleaning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sample_id               object\n",
       "site_info_id            object\n",
       "year                    object\n",
       "profile                 object\n",
       "district                object\n",
       "shelf           string[python]\n",
       "room                    object\n",
       "lab_info_id             object\n",
       "morpho_id               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_cleaning1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>site_info_id</th>\n",
       "      <th>morpho_id</th>\n",
       "      <th>lab_info_id</th>\n",
       "      <th>profile</th>\n",
       "      <th>year</th>\n",
       "      <th>shelf</th>\n",
       "      <th>room</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>630</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>139</td>\n",
       "      <td>1946</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>631</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>139</td>\n",
       "      <td>1946</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>632</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>139</td>\n",
       "      <td>1946</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>633</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>139</td>\n",
       "      <td>1946</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>687</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>208</td>\n",
       "      <td>1946</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sample_id site_info_id morpho_id lab_info_id profile  year shelf room\n",
       "0       630         <NA>      <NA>        <NA>     139  1946     1   22\n",
       "1       631         <NA>      <NA>        <NA>     139  1946     1   22\n",
       "2       632         <NA>      <NA>        <NA>     139  1946     1   22\n",
       "3       633         <NA>      <NA>        <NA>     139  1946     1   22\n",
       "4       687         <NA>      <NA>        <NA>     208  1946     1   22"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reorder to match DB schema\n",
    "samples_check = samples_cleaning1[[\n",
    "    'sample_id',\n",
    "    'site_info_id',\n",
    "    'morpho_id',\n",
    "    'lab_info_id',\n",
    "    'profile',\n",
    "    'year',\n",
    "    'shelf',\n",
    "    'room'\n",
    "]]\n",
    "\n",
    "samples_check.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_check.to_csv(\"/Users/inesschwartz/Desktop/samples_check.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soil Profile Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "##rename columns for clarity add FK/PK\n",
    "#create copy of samples\n",
    "soil_profile_record = samples.copy()\n",
    "# Rename columns in the DataFrame\n",
    "samples.rename(columns={\n",
    "    'Registo': 'sample_id',\n",
    "    'N¬∫ Campo': 'site_info_id',\n",
    "    'Ano': 'year',\n",
    "    'Perfil': 'profile',\n",
    "    'Campanha': 'campaign',\n",
    "    'Col√≥nia_Pais': 'country',\n",
    "    'Distrito': 'district',\n",
    "    'AmostraCrivada': 'sample_sifted',\n",
    "    'AmostraNaoCrivada': 'sample_not_sifted',\n",
    "    'Prateleira': 'shelf',\n",
    "    'Sala': 'room'\n",
    "}, inplace=True)\n",
    "\n",
    "soil_profile_cleaning2 = soil_profile_record\n",
    "# Add missing columns\n",
    "soil_profile_cleaning2['site_info_id'] = pd.NA\n",
    "soil_profile_cleaning2['sample_id'] = pd.NA \n",
    "soil_profile_cleaning2['soil_type_id'] = pd.NA \n",
    "soil_profile_cleaning2['site_info_id'] = soil_profile_cleaning2['site_info_id'].astype(str)\n",
    "\n",
    "# Add a new Primary Key ID column starting from 1\n",
    "# Check if 'lab_sample_id' exists and drop it\n",
    "if 'profile_record_id' in soil_profile_cleaning2.columns:\n",
    "    soil_profile_cleaning2 = soil_profile_cleaning2.drop(columns=['profile_record_id'])\n",
    "\n",
    "# Insert a new column, e.g., 'lab_sample_id' as a primary key starting from 1\n",
    "soil_profile_cleaning2.insert(0, 'profile_record_id', range(1, len(soil_profile_cleaning2) + 1))\n",
    "\n",
    "# Reorder columns to match SAMPLES schema\n",
    "profile_record_clean = soil_profile_cleaning2[[\n",
    "    'profile_record_id',\n",
    "    'profile',\n",
    "    'site_info_id',\n",
    "    'sample_id',\n",
    "    'soil_type_id'\n",
    "]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure consistent data types and formatting\n",
    "\n",
    "# correct datatypes\n",
    "#profile to string\n",
    "profile_record_clean['profile'] = profile_record_clean['profile'].astype(str).str.strip().str[:20]\n",
    "\n",
    "#sample_id to string\n",
    "# Convert cleaned values to numeric safely\n",
    "# Convert sample_id to numeric first (coerce errors to NaN)\n",
    "profile_record_clean['sample_id'] = pd.to_numeric(profile_record_clean['sample_id'], errors='coerce')\n",
    "# Then convert to string (will keep NaNs as <NA>)\n",
    "profile_record_clean['sample_id'] = profile_record_clean['sample_id'].astype('Int64').astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<NA>']\n"
     ]
    }
   ],
   "source": [
    "# check for duplicates and nulls\n",
    "# Filter out and print duplicated samples (including the first occurrence)\n",
    "duplicated_values = profile_record_clean['sample_id'][profile_record_clean['sample_id'].duplicated()].unique()\n",
    "print(duplicated_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>profile_record_id</th>\n",
       "      <th>profile</th>\n",
       "      <th>site_info_id</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>soil_type_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>139</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>139</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>139</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>139</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>208</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   profile_record_id profile site_info_id sample_id soil_type_id\n",
       "0                  1     139         <NA>      <NA>         <NA>\n",
       "1                  2     139         <NA>      <NA>         <NA>\n",
       "2                  3     139         <NA>      <NA>         <NA>\n",
       "3                  4     139         <NA>      <NA>         <NA>\n",
       "4                  5     208         <NA>      <NA>         <NA>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the result\n",
    "profile_record_clean.head()\n",
    "#profile_record_clean.to_csv(\"/Users/inesschwartz/Desktop/profile_record_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Site info table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_info_id</th>\n",
       "      <th>ID</th>\n",
       "      <th>profile</th>\n",
       "      <th>X_coord</th>\n",
       "      <th>Y_coord</th>\n",
       "      <th>land_cover_id</th>\n",
       "      <th>climate_id</th>\n",
       "      <th>geology_id</th>\n",
       "      <th>topo_feature_id</th>\n",
       "      <th>sampling_date</th>\n",
       "      <th>districts_id</th>\n",
       "      <th>district</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2770</td>\n",
       "      <td>1_57</td>\n",
       "      <td>12.161278</td>\n",
       "      <td>-15.222598</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Namibe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>1_59</td>\n",
       "      <td>12.575775</td>\n",
       "      <td>-4.866986</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Cabinda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1618</td>\n",
       "      <td>1_61</td>\n",
       "      <td>15.098840</td>\n",
       "      <td>-11.225411</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Cuanza Sul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>881</td>\n",
       "      <td>1_63</td>\n",
       "      <td>17.081955</td>\n",
       "      <td>-9.274587</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Malanje</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1750</td>\n",
       "      <td>1_64</td>\n",
       "      <td>20.788116</td>\n",
       "      <td>-11.568683</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Moxico</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   site_info_id    ID profile    X_coord    Y_coord land_cover_id climate_id  \\\n",
       "0             1  2770    1_57  12.161278 -15.222598          <NA>       <NA>   \n",
       "1             2    48    1_59  12.575775  -4.866986          <NA>       <NA>   \n",
       "2             3  1618    1_61  15.098840 -11.225411          <NA>       <NA>   \n",
       "3             4   881    1_63  17.081955  -9.274587          <NA>       <NA>   \n",
       "4             5  1750    1_64  20.788116 -11.568683          <NA>       <NA>   \n",
       "\n",
       "  geology_id topo_feature_id sampling_date districts_id    district  \n",
       "0       <NA>            <NA>          <NA>         <NA>      Namibe  \n",
       "1       <NA>            <NA>          <NA>         <NA>     Cabinda  \n",
       "2       <NA>            <NA>          <NA>         <NA>  Cuanza Sul  \n",
       "3       <NA>            <NA>          <NA>         <NA>     Malanje  \n",
       "4       <NA>            <NA>          <NA>         <NA>      Moxico  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "site_info_cleaning = profile_loc\n",
    "\n",
    "site_info_cleaning.rename(columns={\n",
    "    'PERFIL': 'profile',\n",
    "    'X_COORD': 'X_coord',\n",
    "    'Y_COORD': 'Y_coord', \n",
    "    'PRO': 'district'\n",
    "}, inplace=True)\n",
    "\n",
    "# Add a new Primary Key ID column starting from 1\n",
    "site_info_cleaning.insert(0, 'site_info_id', range(1, len(site_info_cleaning) + 1))\n",
    "\n",
    "\n",
    "# Add missing columns\n",
    "site_info_cleaning['land_cover_id'] = pd.NA\n",
    "site_info_cleaning['climate_id'] = pd.NA  \n",
    "site_info_cleaning['geology_id'] = pd.NA\n",
    "site_info_cleaning['topo_feature_id'] = pd.NA  \n",
    "site_info_cleaning['sampling_date'] = pd.NA # might leave out...\n",
    "site_info_cleaning['districts_id'] = pd.NA  \n",
    "\n",
    "# Function to remove accents\n",
    "def remove_accents(text):\n",
    "    if isinstance(text, str):\n",
    "        text = unicodedata.normalize('NFKD', text)\n",
    "        return ''.join(c for c in text if not unicodedata.combining(c))\n",
    "    return text\n",
    "\n",
    "# Apply to all object (string) columns\n",
    "for col in site_info_cleaning.select_dtypes(include='object').columns:\n",
    "    site_info_cleaning[col] = site_info_cleaning[col].apply(remove_accents)\n",
    "\n",
    "# Replace / with _ and strip/shorten 'profile' BEFORE slicing into site_info_clean\n",
    "site_info_cleaning['profile'] = (\n",
    "    site_info_cleaning['profile']\n",
    "    .astype(str)\n",
    "    .str.replace('/', '_')\n",
    "    .str.strip()\n",
    "    .str[:20]\n",
    ")\n",
    "\n",
    "# Then select columns\n",
    "site_info_clean = site_info_cleaning[[\n",
    "    'site_info_id',\n",
    "    'ID',\n",
    "    'profile',\n",
    "    'X_coord',\n",
    "    'Y_coord',\n",
    "    'land_cover_id',\n",
    "    'climate_id',\n",
    "    'geology_id',\n",
    "    'topo_feature_id',\n",
    "    'sampling_date',\n",
    "    'districts_id',\n",
    "    'district'\n",
    "]]\n",
    "\n",
    "\n",
    "site_info_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_info_clean.to_csv(\"/Users/inesschwartz/Desktop/site_info1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Morphology Horizon Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "morphology.rename(columns={\n",
    "    'Morfo_id':'horizon_id',\n",
    "    'Amostra': 'sample_id',\n",
    "    'Perfil': 'profile',\n",
    "    'CM':'horizon_layer',\n",
    "    'Limite Superior': 'upper_depth',\n",
    "    'Limite inferior': 'lower_depth',\n",
    "    'Grau de humidade': 'moisture_degree',\n",
    "    'Quantidade de ra√≠zes': 'root_quantity',\n",
    "    'Di√¢metro de ra√≠zes': 'root_diameter',\n",
    "    'Manchas': 'stains',\n",
    "    'Textura': 'texture',\n",
    "    'Abund√¢ncia de elementos grosseiros': 'thick_contents_count',\n",
    "    'Forma de elementos grosseiros': 'thick_contents_shape',\n",
    "    'Natureza de elementos grosseiros': 'thick_contents_nature',\n",
    "    'Tipo de estrutura': 'structure_type',\n",
    "    'Classes de estrutura': 'structure_class',\n",
    "    'Grau de estrutura': 'structure_degree',\n",
    "    'Di√¢metro de poros': 'pore_diameter',\n",
    "    'Quantidade de poros': 'pore_quantity',\n",
    "    'Forma de poros': 'pore_shape',\n",
    "    'Cor (s)': 'dry_color_name',\n",
    "    'Matiz (s)': 'dry_hue',\n",
    "    'Valor (s)':'dry_value',\n",
    "    'Croma (s)': 'dry_chroma',\n",
    "    'Cor (h)': 'moist_color_name',\n",
    "    'Matiz (h)': 'moist_hue',\n",
    "    'Valor (h)': 'moist_value',\n",
    "    'Croma (h)': 'moist_chroma',\n",
    "    'Compacidade':'compaction',\n",
    "    'Dureza': 'durability', \n",
    "    'Friabilidade': 'friability'\n",
    "}, inplace=True)\n",
    "\n",
    "# # Drop unnecessary columns\n",
    "# morphology_cleaning = morphology.drop(columns=[\n",
    "#     'ID1', 'Agrupamento', 'REF', 'Pro', 'Observa√ßoes', 'Horizonte de diagn√≥stico', 'Propriedade de diagn√≥stico', 'Nitidez do limite', 'Designa√ß√£o do horizonte', 'Observa√ßoes', 'Confirmar', 'Adesividade', 'Plasticidade', 'Efervesc√™ncia com HCl', 'Friabilidade', 'Orienta√ß√£o das Fendas', 'Largura das fendas', 'Quantidade de fendas'\n",
    "# ])\n",
    "\n",
    "morphology_cleaning = morphology\n",
    "#add profile_record_id to populate later from soil profile table\n",
    "morphology_cleaning['profile_record_id'] = pd.NA\n",
    "\n",
    "#drop accents\n",
    "import unicodedata\n",
    "def remove_accents(text):\n",
    "    if isinstance(text, str):\n",
    "        # Normalize and remove diacritics\n",
    "        text = unicodedata.normalize('NFKD', text)\n",
    "        text = ''.join(c for c in text if not unicodedata.combining(c))\n",
    "        return text\n",
    "    return text\n",
    "\n",
    "# Apply to all cells in the DataFrame\n",
    "morphology_cleaning = morphology_cleaning.applymap(remove_accents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>morpho_id</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>profile_record_id</th>\n",
       "      <th>profile</th>\n",
       "      <th>horizon_layer</th>\n",
       "      <th>upper_depth</th>\n",
       "      <th>lower_depth</th>\n",
       "      <th>moisture_degree</th>\n",
       "      <th>root_quantity</th>\n",
       "      <th>root_diameter</th>\n",
       "      <th>...</th>\n",
       "      <th>dry_chroma</th>\n",
       "      <th>moist_color_name</th>\n",
       "      <th>moist_hue</th>\n",
       "      <th>moist_value</th>\n",
       "      <th>moist_chroma</th>\n",
       "      <th>compaction</th>\n",
       "      <th>durability</th>\n",
       "      <th>friability</th>\n",
       "      <th>thick_contents_count</th>\n",
       "      <th>thick_contents_nature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B_101/62_1_1</td>\n",
       "      <td>10999.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>101/62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Seco</td>\n",
       "      <td>Muitas finas e bastantes medias</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Pardo-acinzentado-escuro</td>\n",
       "      <td>10YR</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Pequena a minima</td>\n",
       "      <td>Brando</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B_101/62_2_1</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>101/62</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Seco</td>\n",
       "      <td>Bastantes finas e medias e raras grossas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Pardo-amarelado-escuro</td>\n",
       "      <td>10YR</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Pequena</td>\n",
       "      <td>Brando</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B_101/62_3_1</td>\n",
       "      <td>11001.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>101/62</td>\n",
       "      <td>3.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>Seco</td>\n",
       "      <td>Algumas finas e medias e raras grossas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Pardo-amarelado-escuro</td>\n",
       "      <td>10YR</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Pequena a minima</td>\n",
       "      <td>Brando</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B_101/62_4_1</td>\n",
       "      <td>11002.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>101/62</td>\n",
       "      <td>4.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Seco</td>\n",
       "      <td>Poucas finas, algumas medias e raras grossas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Pardo-forte</td>\n",
       "      <td>7,5YR</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Pequena a minima</td>\n",
       "      <td>Brando</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B_101/62_5_2</td>\n",
       "      <td>11003.2</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>101/62</td>\n",
       "      <td>5.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>Seco a humido</td>\n",
       "      <td>Raras</td>\n",
       "      <td>Medias e grossas</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Pardo-forte</td>\n",
       "      <td>7,5YR</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Pequena</td>\n",
       "      <td>Brando</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      morpho_id  sample_id profile_record_id profile  horizon_layer  \\\n",
       "0  B_101/62_1_1    10999.0              <NA>  101/62            1.0   \n",
       "1  B_101/62_2_1    11000.0              <NA>  101/62            2.0   \n",
       "2  B_101/62_3_1    11001.0              <NA>  101/62            3.0   \n",
       "3  B_101/62_4_1    11002.0              <NA>  101/62            4.0   \n",
       "4  B_101/62_5_2    11003.2              <NA>  101/62            5.0   \n",
       "\n",
       "   upper_depth  lower_depth moisture_degree  \\\n",
       "0          0.0         11.0            Seco   \n",
       "1         11.0         28.0            Seco   \n",
       "2         28.0         54.0            Seco   \n",
       "3         54.0         90.0            Seco   \n",
       "4         90.0        160.0   Seco a humido   \n",
       "\n",
       "                                  root_quantity     root_diameter  ...  \\\n",
       "0               Muitas finas e bastantes medias               NaN  ...   \n",
       "1      Bastantes finas e medias e raras grossas               NaN  ...   \n",
       "2        Algumas finas e medias e raras grossas               NaN  ...   \n",
       "3  Poucas finas, algumas medias e raras grossas               NaN  ...   \n",
       "4                                         Raras  Medias e grossas  ...   \n",
       "\n",
       "  dry_chroma          moist_color_name moist_hue moist_value moist_chroma  \\\n",
       "0        2.5  Pardo-acinzentado-escuro      10YR         4.0          2.0   \n",
       "1        3.0    Pardo-amarelado-escuro      10YR         3.0          4.0   \n",
       "2        4.0    Pardo-amarelado-escuro      10YR         4.0          4.0   \n",
       "3        6.0               Pardo-forte     7,5YR         5.0          6.0   \n",
       "4        6.0               Pardo-forte     7,5YR         5.0          6.0   \n",
       "\n",
       "         compaction durability friability thick_contents_count  \\\n",
       "0  Pequena a minima     Brando        NaN                  NaN   \n",
       "1           Pequena     Brando        NaN                  NaN   \n",
       "2  Pequena a minima     Brando        NaN                  NaN   \n",
       "3  Pequena a minima     Brando        NaN                  NaN   \n",
       "4           Pequena     Brando        NaN                  NaN   \n",
       "\n",
       "   thick_contents_nature  \n",
       "0                    NaN  \n",
       "1                    NaN  \n",
       "2                    NaN  \n",
       "3                    NaN  \n",
       "4                    NaN  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reorder columns to match SAMPLES schema\n",
    "morphology_cleaning1 = morphology_cleaning [[\n",
    "    'morpho_id',\n",
    "    'sample_id',\n",
    "    'profile_record_id',\n",
    "    'profile',\n",
    "    'horizon_layer',\n",
    "    'upper_depth',\n",
    "    'lower_depth',\n",
    "    'moisture_degree',\n",
    "    'root_quantity',\n",
    "    'root_diameter',\n",
    "    'texture',\n",
    "    'structure_type',\n",
    "    'structure_class',\n",
    "    'structure_degree',\n",
    "    'pore_diameter',\n",
    "    'pore_quantity',\n",
    "    'pore_shape',\n",
    "    'dry_color_name',\n",
    "    'dry_hue',\n",
    "    'dry_value',\n",
    "    'dry_chroma',\n",
    "    'moist_color_name',\n",
    "    'moist_hue',\n",
    "    'moist_value',\n",
    "    'moist_chroma',\n",
    "    'compaction',\n",
    "    'durability',\n",
    "    'friability',\n",
    "    'thick_contents_count',\n",
    "    'thick_contents_nature'\n",
    "]]\n",
    "\n",
    "# Show first few rows\n",
    "morphology_cleaning1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tp/79mdnyy56_xc3g1jvp9wf4_80000gn/T/ipykernel_7811/4253896047.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  morphology_cleaning1['profile'] = morphology_cleaning1['profile'].astype(str).str.replace('/', '_').str.strip().str[:20]\n",
      "/var/folders/tp/79mdnyy56_xc3g1jvp9wf4_80000gn/T/ipykernel_7811/4253896047.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  morphology_cleaning1['sample_id'] = morphology_cleaning1['sample_id'].apply(clean_sample_id)\n"
     ]
    }
   ],
   "source": [
    "# Ensure consistent data types and formatting\n",
    "morphology_cleaning1['profile'] = morphology_cleaning1['profile'].astype(str).str.replace('/', '_').str.strip().str[:20]\n",
    "\n",
    "#convert sample_to to string of the integer if it's a float like 11003.0\n",
    "#The original string if it's not an integer or has decimal places\n",
    "#\"NULL\" if the value is missing\n",
    "def clean_sample_id(x):\n",
    "    if pd.isnull(x):\n",
    "        return \"NULL\"\n",
    "    try:\n",
    "        float_val = float(x)\n",
    "        if float_val.is_integer():\n",
    "            return str(int(float_val))\n",
    "        else:\n",
    "            return str(float_val)\n",
    "    except:\n",
    "        return str(x)\n",
    "\n",
    "morphology_cleaning1['sample_id'] = morphology_cleaning1['sample_id'].apply(clean_sample_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NULL']\n",
      "üîç Number of sample_id values equal to 'NULL': 6638\n",
      "[]\n",
      "üîç Number of samorpho_idmple_id values equal to 'NULL': 0\n"
     ]
    }
   ],
   "source": [
    "# Check for nulls in 'sample_id' column\n",
    "null_string_values = morphology_cleaning1[morphology_cleaning1['sample_id'] == \"NULL\"]['sample_id'].unique()\n",
    "print(null_string_values)\n",
    "\n",
    "null_string_count = (morphology_cleaning1['sample_id'] == \"NULL\").sum()\n",
    "print(f\"üîç Number of sample_id values equal to 'NULL': {null_string_count}\")\n",
    "\n",
    "#check for nulls in morpho_id column\n",
    "# Check for nulls in 'sample_id' column\n",
    "null_string_values = morphology_cleaning1[morphology_cleaning1['morpho_id'] == \"NULL\"]['sample_id'].unique()\n",
    "print(null_string_values)\n",
    "\n",
    "null_string_count = (morphology_cleaning1['morpho_id'] == \"NULL\").sum()\n",
    "print(f\"üîç Number of samorpho_idmple_id values equal to 'NULL': {null_string_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nan' '4948' '4949']\n",
      "üîç Number of sample_id values equal to 'NULL': 6638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tp/79mdnyy56_xc3g1jvp9wf4_80000gn/T/ipykernel_7811/3405257731.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  null_string_values = morphology_cleaning[morphology_cleaning1['sample_id'] == \"NULL\"]['sample_id'].unique()\n"
     ]
    }
   ],
   "source": [
    "# Check for nulls in 'sample_id' column\n",
    "null_string_values = morphology_cleaning[morphology_cleaning1['sample_id'] == \"NULL\"]['sample_id'].unique()\n",
    "print(null_string_values)\n",
    "\n",
    "null_string_count = (morphology_cleaning1['sample_id'] == \"NULL\").sum()\n",
    "print(f\"üîç Number of sample_id values equal to 'NULL': {null_string_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal** = drop any morpho_id from morphology_cleaning that does not have both:\n",
    "\n",
    "1. Key horizon characteristics\n",
    "\n",
    "2. A valid profile (w location and site characteristics) that appears in site_info_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Found 2589 rows with at least one of the following issues:\n",
      "   ‚Ä¢ missing key horizon data\n",
      "   ‚Ä¢ invalid profile (not in site_info_clean)\n",
      "   ‚Ä¢ missing both upper_depth and lower_depth\n",
      "‚úÖ Remaining rows in morphology_cleaning: 10434\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# -----------------------------------------\n",
    "# 1. Standardize 'profile' column formatting\n",
    "# -----------------------------------------\n",
    "site_info_clean.loc[:, 'profile'] = (\n",
    "    site_info_clean['profile']\n",
    "    .astype(str)\n",
    "    .str.replace('/', '_')\n",
    "    .str.strip()\n",
    "    .str.upper()\n",
    "    .str[:20]\n",
    ")\n",
    "\n",
    "morphology_cleaning1.loc[:, 'profile'] = (\n",
    "    morphology_cleaning1['profile']\n",
    "    .astype(str)\n",
    "    .str.replace('/', '_')\n",
    "    .str.strip()\n",
    "    .str.upper()\n",
    "    .str[:20]\n",
    ")\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Define valid profiles\n",
    "# ---------------------------\n",
    "valid_profiles = set(site_info_clean['profile'])\n",
    "\n",
    "# ---------------------------\n",
    "# 3. Define helper to check for missing/zero\n",
    "# ---------------------------\n",
    "def is_missing(val):\n",
    "    return pd.isna(val) or val == 0 or val == '0'\n",
    "\n",
    "# ---------------------------\n",
    "# 4. Build masks for filtering\n",
    "# ---------------------------\n",
    "\n",
    "# A. Missing key horizon data\n",
    "missing_key_data_mask = (\n",
    "    morphology_cleaning1['morpho_id'].notna() &\n",
    "    morphology_cleaning1['moist_color_name'].apply(is_missing) &\n",
    "    morphology_cleaning1['texture'].apply(is_missing) &\n",
    "    morphology_cleaning1['structure_type'].apply(is_missing)\n",
    ")\n",
    "\n",
    "# B. Invalid profile\n",
    "invalid_profile_mask = ~morphology_cleaning1['profile'].isin(valid_profiles)\n",
    "\n",
    "# C. Missing both upper and lower depth\n",
    "missing_depth_mask = (\n",
    "    morphology_cleaning1['upper_depth'].apply(is_missing) &\n",
    "    morphology_cleaning1['lower_depth'].apply(is_missing)\n",
    ")\n",
    "\n",
    "# ---------------------------\n",
    "# 5. Combine all masks\n",
    "# ---------------------------\n",
    "rows_to_flag_mask = missing_key_data_mask | invalid_profile_mask | missing_depth_mask\n",
    "rows_to_flag = morphology_cleaning[rows_to_flag_mask]\n",
    "\n",
    "# ---------------------------\n",
    "# 6. Report and drop flagged rows\n",
    "# ---------------------------\n",
    "print(f\"‚ö†Ô∏è Found {len(rows_to_flag)} rows with at least one of the following issues:\")\n",
    "print(\"   ‚Ä¢ missing key horizon data\")\n",
    "print(\"   ‚Ä¢ invalid profile (not in site_info_clean)\")\n",
    "print(\"   ‚Ä¢ missing both upper_depth and lower_depth\")\n",
    "\n",
    "# Optional: Save flagged rows for review\n",
    "# rows_to_flag.to_csv(\"/Users/inesschwartz/Desktop/morph_flagged_rows_combined.csv\", index=False)\n",
    "\n",
    "# Drop flagged rows from main DataFrame\n",
    "morphology_cleaning1 = morphology_cleaning1[~rows_to_flag_mask].copy()\n",
    "\n",
    "# Summary after cleanup\n",
    "print(f\"‚úÖ Remaining rows in morphology_cleaning: {len(morphology_cleaning1)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NULL' '8643']\n"
     ]
    }
   ],
   "source": [
    "# check for duplicates\n",
    "# Make sure sample_id and horizon_id are strings\n",
    "morphology_cleaning1['sample_id'] = morphology_cleaning1['sample_id'].astype(str).str.strip()\n",
    "morphology_cleaning1['morpho_id'] = morphology_cleaning1['morpho_id'].astype(str).str.strip()\n",
    "# Filter out and print duplicated samples (including the first occurrence)\n",
    "duplicated_values = morphology_cleaning1['sample_id'][morphology_cleaning1['sample_id'].duplicated()].unique()\n",
    "print(duplicated_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Morphology data cleaned and sample_id updated via morpho_id.\n"
     ]
    }
   ],
   "source": [
    "#addressing duplicates\n",
    "\n",
    "# -----------------------------------\n",
    "# 1. Correct sample_id using morpho_id map\n",
    "# -----------------------------------\n",
    "# Step 1: Make sure IDs are strings and trimmed\n",
    "morphology_cleaning1['morpho_id'] = morphology_cleaning1['morpho_id'].astype(str).str.strip()\n",
    "morphology_cleaning1['sample_id'] = morphology_cleaning1['sample_id'].astype(str).str.strip()\n",
    "\n",
    "# Step 2: Your mapping (morpho_id ‚Üí new sample_id)\n",
    "horizon_to_sample_map = {\n",
    "    'UZ_24c/60_1_1': '8639',\n",
    "    'UZ_24c/60_2_1': '8640',\n",
    "    'UZ_24c/60_3_1': '8641',\n",
    "    'UZ_24c/60_4_1': '8642',\n",
    "    'UZ_24c/60_5_1': '8643',\n",
    "    'UZ_66c/60_1_1': '8777',\n",
    "    'UZ_66c/60_2_1': '8778',\n",
    "    'UZ_66c/60_3_1': '8779',\n",
    "    'UZ_66c/60_4_1': '8780',\n",
    "    'CC_473/66_1_1': '17596',\n",
    "    'CC_473/66_2_1': '17597',\n",
    "    'CC_473/66_3_1': '17598',\n",
    "    'N_85/57_1_0': '4947',\n",
    "    'N_85/57_2_0': '4948',\n",
    "    'N_85/57_3_0': '4949',\n",
    "    'UZ_231/60_4_1': '8255',\n",
    "    'B_139/61_5_1': '10353',\n",
    "    'H_480/55_1_1': '3919',\n",
    "    'H_91/54_1_1': '1255',\n",
    "    'H_90/54_3_3': '1252',\n",
    "    'Hb_136/56_1_1':'2961',\n",
    "    'Hb_136/56_2_1': '2962',\n",
    "    'Hb_136/56_3_1': '2963',\n",
    "    'Hb_136/56_4_1': '2964',\n",
    "    'UZ_216/60_5_1': '8231',\n",
    "    'Bg_217/46_1_1': '694',\n",
    "    'Bg_217/46_2_1': '695',\n",
    "    'Bg_217/46_3_1': '696',\n",
    "    'UZ_215c/60_1_1':'9255',\n",
    "    'UZ_215c/60_2_1': '9256',\n",
    "    'UZ_215c/60_3_1': '9257',\n",
    "    'UZ_215c/60_4_1': '9258',\n",
    "    'UZ_215c/60_5_1': '9259',\n",
    "    'UZ_215c/60_6_1': '9260',\n",
    "    'N_30/57_1_1':'4848',\n",
    "    'N_30/57_2_2':'4849',\n",
    "    'N_30/57_3_1':'4850',\n",
    "    'UZ_66c/60_1_1': '8777',\n",
    "    'UZ_66c/60_2_1': '8778',\n",
    "    'UZ_66c/60_3_1': '8779',\n",
    "    'UZ_66c/60_4_1': '8780',\n",
    "    'UZ_66c/60_5_1': '8781',\n",
    "    'UZ_66c/60_6_1': '8783',\n",
    "    'UZ_66c/60_7_1': '8782',\n",
    "    'H_91/54_1_1': '1255',\n",
    "    'H_91/54_2_1': '1256',\n",
    "    'H_91/54_3_1': '1257'\n",
    "}\n",
    "\n",
    "# Step 3: Apply the mapping to replace sample_id based on horizon_id\n",
    "morphology_cleaning1['sample_id'] = morphology_cleaning1.apply(\n",
    "    lambda row: horizon_to_sample_map.get(row['morpho_id'], row['sample_id']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# -----------------------------------\n",
    "# 2. Drop specific horizon_ids (might have already been dropped)\n",
    "# -----------------------------------\n",
    "horizons_to_drop = [\n",
    "    'B_139/61_4_1', 'H_113/55_1_1', 'H_1306/52_1_1', 'H_1611/52_1_1',\n",
    "    'H_227/46_1_1', 'H_227/46_2_1', 'H_227/46_3_1', 'H_227/46_4_1',\n",
    "    'Mj_178c/63_4_1', 'Mj_321c/63_4_1', 'B_110/62_5_1', 'B_110/62_6_1'\n",
    "]\n",
    "morphology_cleaning1 = morphology_cleaning1[~morphology_cleaning1['morpho_id'].isin(horizons_to_drop)]\n",
    "\n",
    "\n",
    "# -----------------------------------\n",
    "# 3. Done ‚Äî Optional: Save to file\n",
    "# -----------------------------------\n",
    "#df_morpho_cleaned.to_csv(\"/Users/inesschwartz/Desktop/df_morpho_cleaned_corrected.csv\", index=False)\n",
    "print(\"‚úÖ Morphology data cleaned and sample_id updated via morpho_id.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NULL']\n",
      "üîç Number of sample_id values equal to 'NULL': 4713\n"
     ]
    }
   ],
   "source": [
    "#re-count null sample_id's\n",
    "morphology_cleaning1\n",
    "# Check for nulls in 'sample_id' column\n",
    "null_string_values2 = morphology_cleaning1[morphology_cleaning1['sample_id'] == \"NULL\"]['sample_id'].unique()\n",
    "print(null_string_values2)\n",
    "\n",
    "null_string_count2 = (morphology_cleaning1['sample_id'] == \"NULL\").sum()\n",
    "print(f\"üîç Number of sample_id values equal to 'NULL': {null_string_count2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÅ Found 0 duplicated morpho_id(s).\n"
     ]
    }
   ],
   "source": [
    "num_duplicates = morphology_cleaning1['morpho_id'].duplicated().sum()\n",
    "print(f\"üîÅ Found {num_duplicates} duplicated morpho_id(s).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_morpho_cleaned = morphology_cleaning1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dealing w decimals in sample_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Found 439 sample_id(s) with decimal values.\n",
      "\n",
      "üßæ Affected sample_ids:\n",
      "['11003.2' '11285.2' '10843.2' '10428.2' '10470.2' '10480.2' '10485.2'\n",
      " '10446.2' '10849.2' '10509.2' '10562.2' '10536.2' '11327.2' '11356.2'\n",
      " '11393.2' '11176.2' '11454.2' '10885.2' '10904.2' '10922.2' '11485.2'\n",
      " '10933.2' '4972.3' '4981.2' '5810.2' '5045.2' '5822.2' '4989.2' '5006.2'\n",
      " '5010.2' '5839.2' '4996.2' '5082.2' '5026.2' '6314.2' '6317.2' '6323.2'\n",
      " '6332.2' '6336.3' '5883.2' '6342.3' '6348.2' '6350.2' '6358.2' '5902.2'\n",
      " '5897.3' '6376.3' '6381.2' '6383.3' '6388.2' '6391.2' '6402.2' '6405.2'\n",
      " '6416.2' '5914.2' '5916.2' '6439.3' '5088.2' '5053.2' '5101.2' '5107.2'\n",
      " '5123.2' '5945.2' '5174.2' '5176.2' '5963.2' '5973.2' '5202.2' '5207.2'\n",
      " '5192.2' '5214.2' '5218.2' '5225.3' '5983.2' '5990.2' '5270.2' '5995.2'\n",
      " '5997.2' '5447.2' '6014.2' '6022.2' '5417.2' '5332.2' '6032.2' '5476.2'\n",
      " '5478.2' '5434.2' '5359.2' '5442.2' '5444.2' '5327.2' '5342.2' '5315.2'\n",
      " '5348.2' '7390.2' '7397.2' '5717.2' '5745.2' '5751.2' '5737.2' '5777.2'\n",
      " '7408.2' '5770.2' '5780.2' '20912.2' '20921.2' '19554.2' '19255.2'\n",
      " '18814.2' '18740.2' '6787.2' '6903.2' '6924.2' '6684.2' '6686.2' '6921.2'\n",
      " '7047.2' '6726.2' '6815.2' '6754.2' '6633.2' '6635.2' '6890.2' '6908.2'\n",
      " '6895.2' '6897.2' '6652.2' '6964.2' '7108.2' '6872.2' '6669.2' '6768.2'\n",
      " '6931.2' '6853.2' '7268.2' '7141.2' '6988.2' '7011.2' '7184.2' '6974.2'\n",
      " '7289.2' '7291.2' '7255.2' '16853.2' '16870.2' '18498.2' '18513.2'\n",
      " '17536.2' '18575.2' '18588.2' '18671.2' '17607.2' '18703.2' '10064.2'\n",
      " '11560.2' '11794.2' '1100.2' '1557.2' '1560.2' '1752.2' '1754.2' '1747.3'\n",
      " '1275.3' '1785.3' '1792.2' '1343.2' '1352.3' '1356.3' '1802.2' '1366.3'\n",
      " '1325.3' '836.2' '1376.4' '1383.2' '1335.3' '1388.2' '1108.2' '1562.2'\n",
      " '1413.2' '1408.3' '1111.2' '1568.2' '2248.2' '1843.2' '1845.2' '2253.2'\n",
      " '1426.3' '1850.2' '1580.2' '1442.2' '1602.2' '1604.2' '2263.2' '1463.2'\n",
      " '1119.2' '1475.2' '1490.3' '1485.2' '1874.2' '2268.2' '1589.3' '2282.2'\n",
      " '1140.2' '1585.2' '1598.2' '1144.3' '1938.2' '1149.3' '1956.3' '1968.2'\n",
      " '1154.2' '1158.3' '1991.2' '1993.2' '1548.3' '2002.2' '2013.4' '2007.3'\n",
      " '2371.2' '2373.3' '2378.2' '2380.2' '2382.2' '2019.2' '2023.2' '2055.2'\n",
      " '2057.2' '2051.2' '2393.2' '2398.2' '2400.2' '2075.2' '2069.3' '2408.2'\n",
      " '2410.3' '2415.3' '2093.2' '2089.2' '2107.4' '2115.2' '2136.2' '1627.2'\n",
      " '1629.2' '1546.2' '2463.2' '1184.2' '2169.2' '2475.2' '1191.2' '1200.3'\n",
      " '1206.2' '1209.2' '1215.2' '1220.2' '1225.2' '1229.2' '1236.2' '2921.2'\n",
      " '2888.2' '2890.3' '2906.2' '2908.2' '2910.2' '2927.2' '609.2' '612.2'\n",
      " '3506.2' '2945.2' '2716.3' '2994.2' '2987.2' '2978.2' '2981.2' '3021.3'\n",
      " '3006.2' '3008.2' '3014.2' '3016.3' '3535.2' '299.2' '3031.2' '3526.2'\n",
      " '3528.3' '3045.2' '3050.2' '3052.2' '3103.2' '3109.2' '3119.2' '2730.2'\n",
      " '3145.2' '3179.2' '3570.2' '3572.2' '3574.2' '3156.2' '3151.2' '3161.2'\n",
      " '3163.2' '3165.2' '3194.2' '3213.2' '3216.2' '3606.2' '3259.2' '3636.2'\n",
      " '2750.3' '3290.2' '3309.2' '2743.3' '2738.2' '2763.2' '2765.2' '2757.3'\n",
      " '2776.2' '2785.2' '2711.2' '3492.2' '2847.2' '2842.3' '2877.2' '2869.2'\n",
      " '10576.2' '19244.2' '15778.2' '15305.2' '16266.2' '15005.2' '15286.2'\n",
      " '15049.2' '15337.2' '15031.2' '15032.2' '15957.2' '15951.2' '15896.2'\n",
      " '15352.2' '15370.2' '16494.2' '15641.2' '15132.2' '14857.2' '14455.2'\n",
      " '14920.2' '16031.2' '13521.2' '13779.2' '13765.2' '13493.2' '13817.2'\n",
      " '13793.2' '13810.2' '13804.2' '13475.2' '13883.2' '13901.2' '13481.2'\n",
      " '13924.2' '14018.2' '13999.2' '13988.2' '13931.2' '14112.2' '14119.2'\n",
      " '13394.2' '14071.2' '13549.2' '14135.2' '14064.2' '13387.2' '14156.2'\n",
      " '13556.2' '13274.2' '12692.2' '13532.2' '14249.2' '13299.2' '14278.2'\n",
      " '14213.2' '14266.2' '14296.2' '13404.2' '12715.2' '51.2' '12636.2'\n",
      " '578.2' '12630.2' '13599.2' '75.1' '13581.2' '12653.2' '13621.2'\n",
      " '13606.2' '13638.2' '13661.2' '13695.2' '4840.3' '3348.2' '3417.2'\n",
      " '3412.2' '4867.3' '4899.2' '4908.2' '4916.2' '4920.2' '5404.2' '4958.2'\n",
      " '9039.2' '8959.2' '9125.2' '8119.2' '9183.2' '9208.2' '9143.2' '9155.2'\n",
      " '7838.2' '9281.2' '7849.2' '9297.2' '9302.2' '9449.2' '8274.2' '8271.2'\n",
      " '9442.2' '6549.2' '9564.2' '9455.2' '9604.2' '8360.2' '7859.2' '7817.2'\n",
      " '8681.2' '7932.2' '7935.2' '7944.2' '7958.2' '8012.2' '8865.2' '8830.2']\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Ensure sample_id is a string\n",
    "df_morpho_cleaned['sample_id'] = df_morpho_cleaned['sample_id'].astype(str).str.strip()\n",
    "\n",
    "# Step 2: Identify sample_ids that contain a decimal point\n",
    "decimal_sample_ids = df_morpho_cleaned[df_morpho_cleaned['sample_id'].str.contains(r'\\.\\d+$', regex=True)]\n",
    "\n",
    "# Step 3: Output results\n",
    "print(f\"üîç Found {len(decimal_sample_ids)} sample_id(s) with decimal values.\\n\")\n",
    "\n",
    "# Optional: Print the unique sample_ids with decimals\n",
    "print(\"üßæ Affected sample_ids:\")\n",
    "print(decimal_sample_ids['sample_id'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "df_morpho_cleaned.to_csv(\"/Users/inesschwartz/Desktop/morpho_cleaned_updated.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soil Type Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>soil_type_id</th>\n",
       "      <th>profile</th>\n",
       "      <th>CEP_GR</th>\n",
       "      <th>CEP_NAME</th>\n",
       "      <th>FAO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1_51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1_57</td>\n",
       "      <td>Aridicos</td>\n",
       "      <td>Aridicos com calcario Pardo-cinzentos</td>\n",
       "      <td>CLha</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   soil_type_id profile    CEP_GR                               CEP_NAME   FAO\n",
       "0             1    1_51       NaN                                    NaN   NaN\n",
       "1             2    1_57  Aridicos  Aridicos com calcario Pardo-cinzentos  CLha"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename columns\n",
    "soil_type = soil_profile.copy()\n",
    "\n",
    "soil_type.rename(columns={\n",
    "    'Perfil': 'profile',\n",
    "    'Agrupamento': 'grouping',\n",
    "    'Pro': 'province',\n",
    "    'Pa√≠s': 'country',\n",
    "    'Local': 'location',\n",
    "    'DATA': 'date',\n",
    "    'CEP_NOME': 'CEP_NAME',\n",
    "}, inplace=True)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "soil_type_cleaning = soil_type.drop(columns=[\n",
    "    'REF', 'province', 'country', 'location', 'DESCRITOR1', 'DESCRITOR2', 'DESCRITOR3',\n",
    "    'date', 'Fase', 'D_INSER√áAO', 'Publica√ß√£o', 'WRB_old', 'Miss√£o'\n",
    "], errors='ignore')  # use errors='ignore' in case some columns were already missing\n",
    "\n",
    "# Add a new Primary Key ID column starting from 1\n",
    "soil_type_cleaning.insert(0, 'soil_type_id', range(1, len(soil_type_cleaning) + 1))\n",
    "\n",
    "# Drop accents\n",
    "import unicodedata\n",
    "\n",
    "def remove_accents(text):\n",
    "    if isinstance(text, str):\n",
    "        text = unicodedata.normalize('NFKD', text)\n",
    "        return ''.join(c for c in text if not unicodedata.combining(c))\n",
    "    return text\n",
    "\n",
    "# Apply to all cells in the DataFrame\n",
    "soil_type_cleaning = soil_type_cleaning.applymap(remove_accents)\n",
    "\n",
    "# Replace / with _ and strip/shorten 'profile' BEFORE slicing into site_info_clean\n",
    "soil_type_cleaning['profile'] = (\n",
    "    soil_type_cleaning['profile']\n",
    "    .astype(str)\n",
    "    .str.replace('/', '_')\n",
    "    .str.strip()\n",
    "    .str[:20]\n",
    ")\n",
    "\n",
    "# Keep only relevant columns\n",
    "soil_type_clean = soil_type_cleaning[[\n",
    "    'soil_type_id',\n",
    "    'profile',\n",
    "    'CEP_GR',\n",
    "    'CEP_NAME',\n",
    "    'FAO'\n",
    "]]\n",
    "\n",
    "# Preview\n",
    "soil_type_clean.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "üîç Unique 'profile' values equal to string 'NULL': []\n",
      "üî¢ Number of 'profile' values equal to string 'NULL': 0\n"
     ]
    }
   ],
   "source": [
    "# check duplicates\n",
    "# Filter out and print duplicated samples (including the first occurrence)\n",
    "duplicated_values_st = soil_type_clean['profile'][soil_type_clean['profile'].duplicated()].unique()\n",
    "print(duplicated_values_st)\n",
    "\n",
    "# Check for profile values that are the string \"NULL\"\n",
    "null_string_values_st = soil_type_clean[soil_type_clean['profile'] == \"NULL\"]['profile'].unique()\n",
    "print(\"üîç Unique 'profile' values equal to string 'NULL':\", null_string_values_st)\n",
    "\n",
    "null_string_count_st = (soil_type_clean['profile'] == \"NULL\").sum()\n",
    "print(f\"üî¢ Number of 'profile' values equal to string 'NULL': {null_string_count_st}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save clean table\n",
    "soil_type_clean.to_csv(\"/Users/inesschwartz/Desktop/soil_type_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Climate table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>climate_id</th>\n",
       "      <th>profile</th>\n",
       "      <th>ID</th>\n",
       "      <th>mean_annual_temp</th>\n",
       "      <th>mean_annual_precip</th>\n",
       "      <th>koppen_climate</th>\n",
       "      <th>thornthwaite_climate</th>\n",
       "      <th>hydric_regime</th>\n",
       "      <th>thermal_regime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1_57</td>\n",
       "      <td>2770</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arido</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1_59</td>\n",
       "      <td>48</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>Humido</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1_61</td>\n",
       "      <td>1618</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1_63</td>\n",
       "      <td>881</td>\n",
       "      <td>21.5</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>Tropical chuvoso com estacao seca no Inverno, ...</td>\n",
       "      <td>Humido</td>\n",
       "      <td>Tropustico udico</td>\n",
       "      <td>Iso-Hipertermico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1_64</td>\n",
       "      <td>1750</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   climate_id profile    ID mean_annual_temp mean_annual_precip  \\\n",
       "0           1    1_57  2770                                       \n",
       "1           2    1_59    48                                       \n",
       "2           3    1_61  1618                                       \n",
       "3           4    1_63   881             21.5             1500.0   \n",
       "4           5    1_64  1750                                       \n",
       "\n",
       "                                      koppen_climate thornthwaite_climate  \\\n",
       "0                                                NaN                Arido   \n",
       "1                                                NaN               Humido   \n",
       "2                                                NaN                  NaN   \n",
       "3  Tropical chuvoso com estacao seca no Inverno, ...               Humido   \n",
       "4                                                NaN                  NaN   \n",
       "\n",
       "      hydric_regime    thermal_regime  \n",
       "0               NaN               NaN  \n",
       "1               NaN               NaN  \n",
       "2               NaN               NaN  \n",
       "3  Tropustico udico  Iso-Hipertermico  \n",
       "4               NaN               NaN  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load original Excel data\n",
    "profile_loc = pd.read_excel(\"/Users/inesschwartz/GreenDataScience/Thesis/tables_soil_database/Perfis_local.xlsx\")\n",
    "\n",
    "# Create a copy for cleaning\n",
    "climate_features_cleaning = profile_loc.copy()\n",
    "\n",
    "# Mapping from climate codes to descriptions\n",
    "code_to_description = {\n",
    "    \"B1\": \"H√∫mido\",\n",
    "    \"B2\": \"H√∫mido\",\n",
    "    \"B3\": \"H√∫mido\",\n",
    "    \"B4\": \"H√∫mido\",\n",
    "    \"C1\": \"Sub-h√∫mido seco\",\n",
    "    \"C2\": \"Sub-h√∫mido chuvoso\",\n",
    "    \"D\": \"Semi-√°rido\",\n",
    "    \"E\": \"√Årido\",\n",
    "    \"Aw\": \"Tropical chuvoso com esta√ß√£o seca no Inverno, de savana\",\n",
    "    \"BSw\": \"Seco de estepe, com chuva predominante no Ver√£o\",\n",
    "    \"BWw\": \"Seco de deserto, com chuva predominante no Ver√£o\",\n",
    "    \"Cw\": \"Mesot√©rmico h√∫mido com esta√ß√£o seca no Inverno\",\n",
    "    \"ARe\": \"Ar√≠dico extremo\",\n",
    "    \"ARf\": \"Ar√≠dico fraco\",\n",
    "    \"ARt\": \"Ar√≠dico t√≠pico\",\n",
    "    \"tUDs\": \"Temp√∫dico seco\",\n",
    "    \"tUSh\": \"Temp√∫stico h√∫mido\",\n",
    "    \"tUSt\": \"Temp√∫stico t√≠pico\",\n",
    "    \"TUDs\": \"Trop√∫dico seco\",\n",
    "    \"TUSa\": \"Trop√∫stico ar√≠dico\",\n",
    "    \"TUSu\": \"Trop√∫stico √∫dico\",\n",
    "    \"TUSt\": \"Tropustico t√≠pico\",\n",
    "    \"H\": \"Hipert√©rmico\",\n",
    "    \"iH\": \"Iso-Hipert√©rmico\",\n",
    "    \"iT\": \"Iso-T√©rmico\",\n",
    "    \"T\": \"T√©rmico\"\n",
    "}\n",
    "\n",
    "# Replace climate codes with descriptions\n",
    "for col in [\"CL_THORNTH\", \"CL_KOPPEN\", \"REG_H√çDRIC\", \"REG_T√âRMIC\"]:\n",
    "    climate_features_cleaning[col] = climate_features_cleaning[col].replace(code_to_description)\n",
    "\n",
    "# Function to average values like \"21-22\" -> 21.5\n",
    "def average_range(value):\n",
    "    if isinstance(value, str) and '-' in value:\n",
    "        try:\n",
    "            nums = [float(x.strip()) for x in value.split('-')]\n",
    "            return sum(nums) / len(nums)\n",
    "        except:\n",
    "            return None\n",
    "    try:\n",
    "        return float(value)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Apply to temperature and precipitation columns\n",
    "climate_features_cleaning[\"TMA\"] = climate_features_cleaning[\"TMA\"].apply(average_range)\n",
    "climate_features_cleaning[\"PMA\"] = climate_features_cleaning[\"PMA\"].apply(average_range)\n",
    "\n",
    "# Rename columns for clarity\n",
    "climate_features_cleaning.rename(columns={\n",
    "    'PERFIL': 'profile',\n",
    "    'CL_THORNTH': 'thornthwaite_climate',\n",
    "    'CL_KOPPEN': 'koppen_climate',\n",
    "    'TMA': 'mean_annual_temp',\n",
    "    'PMA': 'mean_annual_precip',\n",
    "    'REG_H√çDRIC': 'hydric_regime',\n",
    "    'REG_T√âRMIC': 'thermal_regime'\n",
    "}, inplace=True)\n",
    "\n",
    "# ensure consistent profile formatting\n",
    "climate_features_cleaning['profile'] = climate_features_cleaning['profile'].astype(str).str.replace('/', '_').str.strip().str[:20]\n",
    "\n",
    "# Drop accents from text values\n",
    "def remove_accents(text):\n",
    "    if isinstance(text, str):\n",
    "        text = unicodedata.normalize('NFKD', text)\n",
    "        return ''.join(c for c in text if not unicodedata.combining(c))\n",
    "    return text\n",
    "\n",
    "climate_features_cleaning = climate_features_cleaning.applymap(remove_accents)\n",
    "\n",
    "# Add primary key column\n",
    "climate_features_cleaning.insert(0, 'climate_id', range(1, len(climate_features_cleaning) + 1))\n",
    "\n",
    "# Replace empty strings or nulls in numeric columns with \\N (Postgres null)\n",
    "for col in ['mean_annual_temp', 'mean_annual_precip']:\n",
    "    climate_features_cleaning[col] = climate_features_cleaning[col].replace(\n",
    "        ['', ' ', 'NULL', None, pd.NA, pd.NaT, 'nan', float('nan')], ''\n",
    "    )\n",
    "\n",
    "# Select and reorder relevant columns for export\n",
    "climate_features_clean = climate_features_cleaning[[\n",
    "    'climate_id',\n",
    "    'profile',\n",
    "    'ID',\n",
    "    'mean_annual_temp',\n",
    "    'mean_annual_precip',\n",
    "    'koppen_climate',\n",
    "    'thornthwaite_climate',\n",
    "    'hydric_regime',\n",
    "    'thermal_regime'\n",
    "]]\n",
    "\n",
    "# Preview\n",
    "climate_features_clean.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check FK relationships and datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types of each column in profile_clean:\n",
      "\n",
      "climate_id               int64\n",
      "profile                 object\n",
      "ID                       int64\n",
      "mean_annual_temp        object\n",
      "mean_annual_precip      object\n",
      "koppen_climate          object\n",
      "thornthwaite_climate    object\n",
      "hydric_regime           object\n",
      "thermal_regime          object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check and print the datatypes of each column\n",
    "print(\"Data types of each column in profile_clean:\\n\")\n",
    "print(climate_features_clean.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topo features table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topo_features_id</th>\n",
       "      <th>ID</th>\n",
       "      <th>profile</th>\n",
       "      <th>slope_code</th>\n",
       "      <th>altitude</th>\n",
       "      <th>aspect</th>\n",
       "      <th>land_surface_temp</th>\n",
       "      <th>dem_elevation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2770</td>\n",
       "      <td>1_57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>1_59</td>\n",
       "      <td>D5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1618</td>\n",
       "      <td>1_61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>881</td>\n",
       "      <td>1_63</td>\n",
       "      <td>D1</td>\n",
       "      <td>1210.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1750</td>\n",
       "      <td>1_64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topo_features_id    ID profile slope_code  altitude aspect  \\\n",
       "0                 1  2770    1_57        NaN      32.0   <NA>   \n",
       "1                 2    48    1_59         D5       NaN   <NA>   \n",
       "2                 3  1618    1_61        NaN       NaN   <NA>   \n",
       "3                 4   881    1_63         D1    1210.0   <NA>   \n",
       "4                 5  1750    1_64        NaN       NaN   <NA>   \n",
       "\n",
       "  land_surface_temp dem_elevation  \n",
       "0              <NA>          <NA>  \n",
       "1              <NA>          <NA>  \n",
       "2              <NA>          <NA>  \n",
       "3              <NA>          <NA>  \n",
       "4              <NA>          <NA>  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a copy for cleaning\n",
    "topo_features_cleaning = profile_loc.copy()\n",
    "\n",
    "# Rename columns for clarity\n",
    "topo_features_cleaning.rename(columns={\n",
    "    'PERFIL': 'profile',\n",
    "    'TOPOGRAFIA': 'slope_code',\n",
    "    'ALTITUDE': 'altitude',\n",
    "}, inplace=True)\n",
    "\n",
    "# ensure consistent profile formatting\n",
    "topo_features_cleaning['profile'] = topo_features_cleaning['profile'].astype(str).str.replace('/', '_').str.strip().str[:20]\n",
    "\n",
    "# Add missing columns\n",
    "topo_features_cleaning['aspect'] = pd.NA  \n",
    "topo_features_cleaning['land_surface_temp'] = pd.NA\n",
    "topo_features_cleaning['dem_elevation'] = pd.NA  \n",
    "\n",
    "# Add primary key column\n",
    "topo_features_cleaning.insert(0, 'topo_features_id', range(1, len(topo_features_cleaning) + 1))\n",
    "\n",
    "# Create slope class mapping dictionary\n",
    "slope_code_to_description = {\n",
    "    \"D1\": \"Plano (Declives < 2%)\",\n",
    "    \"D2\": \"Ondulado muito suave (Declives > 2% e < 3%)\",\n",
    "    \"D3\": \"Ondulado suave (Declives > 3% e < 5%)\",\n",
    "    \"D4\": \"Ondulado (Declives > 5% e < 8%)\",\n",
    "    \"D5\": \"Acidentado (Declives > 8% e < 15%)\",\n",
    "    \"D6\": \"Escarpado (Declives >15% e < 30%)\",\n",
    "    \"D7\": \"Montanhoso (Declives > 30%)\"\n",
    "}\n",
    "\n",
    "# Create a mapping DataFrame for slope classes\n",
    "slope_classes_df = pd.DataFrame([\n",
    "    {\"slope_code\": code, \"slope_description\": desc}\n",
    "    for code, desc in slope_code_to_description.items()\n",
    "])\n",
    "\n",
    "#drop accents\n",
    "import unicodedata\n",
    "def remove_accents(text):\n",
    "    if isinstance(text, str):\n",
    "        # Normalize and remove diacritics\n",
    "        text = unicodedata.normalize('NFKD', text)\n",
    "        text = ''.join(c for c in text if not unicodedata.combining(c))\n",
    "        return text\n",
    "    return text\n",
    "\n",
    "# Apply to all cells in the DataFrame\n",
    "topo_features_cleaning = topo_features_cleaning.applymap(remove_accents)\n",
    "\n",
    "# Final cleaned topo features table (referencing slope_code, not description)\n",
    "topo_features_clean = topo_features_cleaning[[\n",
    "    'topo_features_id',\n",
    "    'ID',\n",
    "    'profile', \n",
    "    'slope_code',\n",
    "    'altitude',\n",
    "    'aspect',\n",
    "    'land_surface_temp',\n",
    "    'dem_elevation'\n",
    "]]\n",
    "\n",
    "# Preview\n",
    "topo_features_clean.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geological features table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tp/79mdnyy56_xc3g1jvp9wf4_80000gn/T/ipykernel_2227/2818143663.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  geo_features_clean['profile'] = geo_features_clean['profile'].astype(str).str.replace('/', '_').str.strip().str[:20]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_features_id</th>\n",
       "      <th>profile</th>\n",
       "      <th>ID</th>\n",
       "      <th>geology_id</th>\n",
       "      <th>lithology_id</th>\n",
       "      <th>lithology_1954_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1_57</td>\n",
       "      <td>2770</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1_59</td>\n",
       "      <td>48</td>\n",
       "      <td>Oendolongo</td>\n",
       "      <td>pp</td>\n",
       "      <td>Sistema do Maiombe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1_61</td>\n",
       "      <td>1618</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1_63</td>\n",
       "      <td>881</td>\n",
       "      <td>Karroo</td>\n",
       "      <td>Cs/Cal</td>\n",
       "      <td>Serie de Cassanje - T2'T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1_64</td>\n",
       "      <td>1750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   geo_features_id profile    ID  geology_id lithology_id  \\\n",
       "0                1    1_57  2770         NaN            d   \n",
       "1                2    1_59    48  Oendolongo           pp   \n",
       "2                3    1_61  1618         NaN          NaN   \n",
       "3                4    1_63   881      Karroo       Cs/Cal   \n",
       "4                5    1_64  1750         NaN          NaN   \n",
       "\n",
       "           lithology_1954_id  \n",
       "0                        NaN  \n",
       "1         Sistema do Maiombe  \n",
       "2                        NaN  \n",
       "3  Serie de Cassanje - T2'T1  \n",
       "4                        NaN  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load cleaned geo features data\n",
    "geo_features_cleaning = pd.read_excel(\"/Users/inesschwartz/GreenDataScience/Thesis/tables_soil_database/Perfis_local.xlsx\")\n",
    "\n",
    "# Rename columns\n",
    "geo_features_cleaning.rename(columns={\n",
    "    'PERFIL': 'profile',\n",
    "    'GEOLOGIA': 'geology_id',\n",
    "    'LITOLOGIA': 'lithology_id',\n",
    "    'LITOLOGIA_1954': 'lithology_1954_id',\n",
    "}, inplace=True)\n",
    "\n",
    "# Add primary key column\n",
    "geo_features_cleaning.insert(0, 'geo_features_id', range(1, len(geo_features_cleaning) + 1))\n",
    "\n",
    "# Final normalized geo_features table (with codes as foreign keys)\n",
    "geo_features_clean = geo_features_cleaning[[\n",
    "    'geo_features_id',\n",
    "    'profile',\n",
    "    'ID',\n",
    "    'geology_id',\n",
    "    'lithology_id',\n",
    "    'lithology_1954_id'\n",
    "]]\n",
    "\n",
    "# ensure consistent profile formatting\n",
    "geo_features_clean['profile'] = geo_features_clean['profile'].astype(str).str.replace('/', '_').str.strip().str[:20]\n",
    "\n",
    "#drop accents\n",
    "import unicodedata\n",
    "def remove_accents(text):\n",
    "    if isinstance(text, str):\n",
    "        # Normalize and remove diacritics\n",
    "        text = unicodedata.normalize('NFKD', text)\n",
    "        text = ''.join(c for c in text if not unicodedata.combining(c))\n",
    "        return text\n",
    "    return text\n",
    "\n",
    "# Apply to all cells in the DataFrame\n",
    "geo_features_clean = geo_features_clean.applymap(remove_accents)\n",
    "\n",
    "#preview\n",
    "geo_features_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "## mapping tables\n",
    "# Mappings for geology\n",
    "geology_mapping = {\n",
    "    \"Kalahari\": \"Sistema do Kalahari\",\n",
    "    \"Superficiais\": \"Forma√ß√µes Superficiais\",\n",
    "    \"Karroo\": \"Sistema do Karroo\",\n",
    "    \"Bembe\": \"Sistema do Bembe\",\n",
    "    \"Oendolongo\": \"Sistema do Oendolongo\",\n",
    "    \"Base\": \"Complexo de base\",\n",
    "    \"Proteroz√≥ico\": \"Proteroz√≥ico\",\n",
    "    \"Pleistoc√©nico\": \"Pleistoc√©nico\",\n",
    "    \"Terci√°rio\": \"Terci√°rio (m√©dio e inferior)\",\n",
    "    \"TQ\": \"Quatern√°rio e Terci√°rio superior\",\n",
    "    \"Cret√°cio\": \"\",  # no description provided\n",
    "    \"RPKS\": \"Recente Plistoc√©nico e Kalahari Superior\"\n",
    "}\n",
    "\n",
    "# Mappings for lithology_1954\n",
    "lithology_1954_mapping = {\n",
    "    \"Œ≥\": \"Granitos, Granodioritos e Quartzodioritos\",\n",
    "    \"PL\": \"Xistos, metaquartzitos, conglomerados, arcoses, ect.\",\n",
    "    \"Œª\": \"Rochas eruptivas indeterminadas\",\n",
    "    \"Œ¥p\": \"Doleritos, doleritos pigeon√≠ticos\",\n",
    "    \"Œ¥ab\": \"Diabases, diabases albito-cloriticas\",\n",
    "    \"Œµ\": \"Noritos, gabros e peridotitos\",\n",
    "    \"JK\": \"Composto de conglomerados, areias, cascalhos do Kalahari\",\n",
    "    \"C\": \"S√©rie Xisto - calc√°ria\",\n",
    "    \"Cal\": \"Sedimentos arenosos n√£o consolidados\",\n",
    "    \"K\": \"S√©rie xisto - gresosa\",\n",
    "    \"RT\": \"N√£o diferenciado\",\n",
    "    \"œÉ\": \"Sienitos, sienitos nefel√≠nicos\",\n",
    "    \"Q\": \"Dep√≥sitos fossil√≠feros\",\n",
    "    \"CS\": \"Grande conglomerado e s√©rie de Mwashya\"\n",
    "}\n",
    "\n",
    "# Mappings for lithology\n",
    "lithology_mapping = {\n",
    "    \"a\": \"Rochas aren√°ceas consolidadas\",\n",
    "    \"aq\": \"Gr√©s quartz√≠ticos do Oendolongo\",\n",
    "    \"b\": \"Rochas eruptivas b√°sicas\",\n",
    "    \"c\": \"Rochas sedimentares consolidadas calc√°rias\",\n",
    "    \"c'\": \"Rochas sedimentares n√£o consolidadas calc√°rias\",\n",
    "    \"cg\": \"Rochas cristalof√≠licas argil√°ceas\",\n",
    "    \"d\": \"Sedimentos n√£o consolidados de origem marinha\",\n",
    "    \"dc\": \"Dep√≥sitos coluvionares\",\n",
    "    \"dr\": \"Dior√≠tos\",\n",
    "    \"e\": \"Rochas sedimentares consolidadas n√£o calc√°rias\",\n",
    "    \"g\": \"Rochas argil√°ceas consolidadas n√£o calc√°rias\",\n",
    "    \"g'\": \"Rochas argil√°ceas n√£o consolidadas n√£o calc√°rias\",\n",
    "    \"g''\": \"Rochas cristalinas pouco micas em quartzo\",\n",
    "    \"gp\": \"Rochas do  complexo gabro-plagioclast√≠co\",\n",
    "    \"k\": \"Sedimentos n√£o consolidados grosseiros do Kalahari\",\n",
    "    \"m\": \"Rochas sedimentares n√£o consolidadas calco-gips√≠feras\",\n",
    "    \"m'\": \"Dep√≥sitos coluvionares margosos\",\n",
    "    \"mm\": \"Materiais mistos\",\n",
    "    \"n\": \"Sedimentos n√£o consolidados de origem continental\",\n",
    "    \"nd\": \"n√£o descrito\",\n",
    "    \"pp\": \"Sedimentos n√£o consolidados grosseiros plio-plistoc√©nicos\",\n",
    "    \"q\": \"Rochas cristalinas quartz√≠feras\",\n",
    "    \"q'\": \"Materiais redistribu√≠dos provenientes de desagrega√ß√£o rochas crist. quartz√≠feras\",\n",
    "    \"qf\": \"Quartzitos ferruginosos do Oendolongo\",\n",
    "    \"r\": \"Sedimentos grosseiros n√£o especificados\",\n",
    "    \"s\": \"Sienitos\",\n",
    "    \"sx\": \"Forma√ß√µes (ou rochas) sedimentares n√£o especificadas\",\n",
    "    \"sx1\": \"Rochas sedimentares consolidadas com e sem calc√°rio\",\n",
    "    \"sx2\": \"Rochas sedimentares consolidadas\",\n",
    "    \"v\": \"Materiais vulc√¢nicos\",\n",
    "    \"v'\": \"Rochas do complexo alcalino e/ou carboat√≠tico\",\n",
    "    \"x\": \"Rochas consolidadas n√£o especificadas\",\n",
    "    \"xm\": \"Xistos metam√≥rficos\",\n",
    "    \"xq\": \"Rochas cristalinas n√£o especificadas\",\n",
    "    \"z\": \"Rochas metassedimentares\"\n",
    "}\n",
    "\n",
    "# Save each mapping as a DataFrame\n",
    "pd.DataFrame([\n",
    "    {\"geology_code\": k, \"geology_description\": v}\n",
    "    for k, v in geology_mapping.items()\n",
    "]).to_csv(\"/Users/inesschwartz/GreenDataScience/Thesis/tables_clean/geology_mapping.csv\", index=False)\n",
    "\n",
    "pd.DataFrame([\n",
    "    {\"lithology_code\": k, \"lithology_description\": v}\n",
    "    for k, v in lithology_mapping.items()\n",
    "]).to_csv(\"/Users/inesschwartz/GreenDataScience/Thesis/tables_clean/lithology_mapping.csv\", index=False)\n",
    "\n",
    "pd.DataFrame([\n",
    "    {\"lithology_1954_code\": k, \"lithology_1954_description\": v}\n",
    "    for k, v in lithology_1954_mapping.items()\n",
    "]).to_csv(\"/Users/inesschwartz/GreenDataScience/Thesis/tables_clean/lithology1954_mapping.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# District table\n",
    "\n",
    "**don't need**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do I need to make a separate table??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minerology info table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biology Info table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking CSV Datatypes before DB export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÑ File: analyses.csv\n",
      "lab_sample_id      int64\n",
      "sample_id        float64\n",
      "EG               float64\n",
      "thick_clay       float64\n",
      "fine_clay        float64\n",
      "                  ...   \n",
      "Tl               float64\n",
      "Pb               float64\n",
      "Bi               float64\n",
      "Th               float64\n",
      "U                float64\n",
      "Length: 68, dtype: object\n",
      "\n",
      "üìÑ File: soil_type_clean.csv\n",
      "soil_type_id     int64\n",
      "profile         object\n",
      "CEP_GR          object\n",
      "CEP_NAME        object\n",
      "FAO             object\n",
      "dtype: object\n",
      "\n",
      "üìÑ File: analyses_clean.csv\n",
      "lab_sample_id      int64\n",
      "analysis_id       object\n",
      "horizon_id        object\n",
      "sample_id         object\n",
      "EG               float64\n",
      "                  ...   \n",
      "Tl               float64\n",
      "Pb               float64\n",
      "Bi               float64\n",
      "Th               float64\n",
      "U                float64\n",
      "Length: 70, dtype: object\n",
      "\n",
      "üìÑ File: profile_record.csv\n",
      "profile_record_id      int64\n",
      "profile               object\n",
      "site_info_id         float64\n",
      "soil_type_id         float64\n",
      "sample_id              int64\n",
      "dtype: object\n",
      "\n",
      "üìÑ File: soil_type.csv\n",
      "soil_type_id     int64\n",
      "profile         object\n",
      "CEP_GR          object\n",
      "CEP_NAME        object\n",
      "FAO             object\n",
      "dtype: object\n",
      "\n",
      "üìÑ File: morpho_cleaned.csv\n",
      "Unnamed: 0                              int64\n",
      "horizon_id                             object\n",
      "sample_id                             float64\n",
      "profile                                object\n",
      "horizon_layer                         float64\n",
      "upper_depth                           float64\n",
      "lower_depth                           float64\n",
      "dry_color_name                         object\n",
      "dry_hue                                object\n",
      "dry_value                             float64\n",
      "dry_chroma                            float64\n",
      "moist_color_name                       object\n",
      "moist_hue                              object\n",
      "moist_value                           float64\n",
      "moist_chroma                          float64\n",
      "Manchas                                object\n",
      "texture                                object\n",
      "Abund√¢ncia de elementos grosseiros     object\n",
      "Forma de elementos grosseiros          object\n",
      "Natureza de elementos grosseiros       object\n",
      "structure_type                         object\n",
      "structure_class                        object\n",
      "structure_degree                       object\n",
      "compaction                             object\n",
      "durability                             object\n",
      "pore_quantity                          object\n",
      "pore_diameter                          object\n",
      "pore_shape                            float64\n",
      "root_quantity                          object\n",
      "root_diameter                          object\n",
      "moisture_degree                        object\n",
      "Unnamed: 46                           float64\n",
      "profile_record_id                     float64\n",
      "dtype: object\n",
      "\n",
      "üìÑ File: geology_mapping.csv\n",
      "geology_code           object\n",
      "geology_description    object\n",
      "dtype: object\n",
      "\n",
      "üìÑ File: topo_feat_clean.csv\n",
      "topo_features_id       int64\n",
      "slope_code            object\n",
      "altitude             float64\n",
      "aspect               float64\n",
      "land_surface_temp    float64\n",
      "dem_elevation        float64\n",
      "dtype: object\n",
      "\n",
      "üìÑ File: lithology1954_mapping.csv\n",
      "lithology_1954_code           object\n",
      "lithology_1954_description    object\n",
      "dtype: object\n",
      "\n",
      "üìÑ File: samples.csv\n",
      "sample_id         int64\n",
      "site_info_id     object\n",
      "profile          object\n",
      "horizon_id       object\n",
      "year            float64\n",
      "shelf            object\n",
      "room             object\n",
      "dtype: object\n",
      "\n",
      "üìÑ File: morphology_horizon.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tp/79mdnyy56_xc3g1jvp9wf4_80000gn/T/ipykernel_2227/3654665737.py:16: DtypeWarning: Columns (13,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "horizon_id            object\n",
      "sample_id            float64\n",
      "profile_record_id    float64\n",
      "horizon_layer        float64\n",
      "upper_depth          float64\n",
      "lower_depth          float64\n",
      "moisture_degree       object\n",
      "root_quantity         object\n",
      "root_diameter         object\n",
      "texture               object\n",
      "structure_type        object\n",
      "structure_class       object\n",
      "structure_degree      object\n",
      "pore_diameter         object\n",
      "pore_quantity         object\n",
      "pore_shape            object\n",
      "dry_color_name        object\n",
      "dry_hue               object\n",
      "dry_value            float64\n",
      "dry_chroma           float64\n",
      "moist_color_name      object\n",
      "moist_hue             object\n",
      "moist_value          float64\n",
      "moist_chroma         float64\n",
      "compaction            object\n",
      "durability            object\n",
      "dtype: object\n",
      "\n",
      "üìÑ File: site_info.csv\n",
      "site_info_id          int64\n",
      "profile              object\n",
      "X_coord             float64\n",
      "Y_coord             float64\n",
      "district             object\n",
      "geo_features_id       int64\n",
      "climate_id            int64\n",
      "topo_features_id      int64\n",
      "dtype: object\n",
      "\n",
      "üìÑ File: profile_record_clean.csv\n",
      "profile_record_id      int64\n",
      "profile               object\n",
      "site_info_id         float64\n",
      "soil_type_id         float64\n",
      "sample_id              int64\n",
      "dtype: object\n",
      "\n",
      "üìÑ File: morphology_horizon_clean.csv\n",
      "horizon_id            object\n",
      "sample_id            float64\n",
      "profile_record_id    float64\n",
      "horizon_layer        float64\n",
      "upper_depth          float64\n",
      "lower_depth          float64\n",
      "moisture_degree       object\n",
      "root_quantity         object\n",
      "root_diameter         object\n",
      "texture               object\n",
      "structure_type        object\n",
      "structure_class       object\n",
      "structure_degree      object\n",
      "pore_diameter         object\n",
      "pore_quantity         object\n",
      "pore_shape            object\n",
      "dry_color_name        object\n",
      "dry_hue               object\n",
      "dry_value            float64\n",
      "dry_chroma           float64\n",
      "moist_color_name      object\n",
      "moist_hue             object\n",
      "moist_value          float64\n",
      "moist_chroma         float64\n",
      "compaction            object\n",
      "durability            object\n",
      "dtype: object\n",
      "\n",
      "üìÑ File: lithology_mapping.csv\n",
      "lithology_code           object\n",
      "lithology_description    object\n",
      "dtype: object\n",
      "\n",
      "üìÑ File: topo_feat.csv\n",
      "topo_features_id       int64\n",
      "slope_code            object\n",
      "altitude             float64\n",
      "aspect               float64\n",
      "land_surface_temp    float64\n",
      "dem_elevation        float64\n",
      "dtype: object\n",
      "\n",
      "üìÑ File: climate_feat_clean.csv\n",
      "climate_id                int64\n",
      "mean_annual_temp        float64\n",
      "mean_annual_precip      float64\n",
      "koppen_climate           object\n",
      "thornthwaite_climate     object\n",
      "hydric_regime            object\n",
      "thermal_regime           object\n",
      "dtype: object\n",
      "\n",
      "üìÑ File: geo_feat.csv\n",
      "geo_features_id       int64\n",
      "geology_id           object\n",
      "lithology_id         object\n",
      "lithology_1954_id    object\n",
      "dtype: object\n",
      "\n",
      "üìÑ File: site_info_clean.csv\n",
      "site_info_id          int64\n",
      "profile              object\n",
      "X_coord             float64\n",
      "Y_coord             float64\n",
      "district             object\n",
      "geo_features_id       int64\n",
      "climate_id            int64\n",
      "topo_features_id      int64\n",
      "dtype: object\n",
      "\n",
      "üìÑ File: samples_clean.csv\n",
      "sample_id         int64\n",
      "site_info_id     object\n",
      "profile          object\n",
      "horizon_id       object\n",
      "year            float64\n",
      "shelf            object\n",
      "room             object\n",
      "dtype: object\n",
      "\n",
      "üìÑ File: districts_clean.csv\n",
      "district_id     int64\n",
      "district       object\n",
      "dtype: object\n",
      "\n",
      "üìÑ File: geo_feat_clean.csv\n",
      "geo_features_id       int64\n",
      "geology_id           object\n",
      "lithology_id         object\n",
      "lithology_1954_id    object\n",
      "dtype: object\n",
      "\n",
      "üìÑ File: climate_feat.csv\n",
      "climate_id                int64\n",
      "mean_annual_temp        float64\n",
      "mean_annual_precip      float64\n",
      "koppen_climate           object\n",
      "thornthwaite_climate     object\n",
      "hydric_regime            object\n",
      "thermal_regime           object\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tp/79mdnyy56_xc3g1jvp9wf4_80000gn/T/ipykernel_2227/3654665737.py:16: DtypeWarning: Columns (13,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Set the path to your folder containing the 10 CSV files\n",
    "csv_folder = \"/Users/inesschwartz/GreenDataScience/Thesis/tables_clean\"  \n",
    "\n",
    "# List all CSV files in the folder\n",
    "csv_files = [f for f in os.listdir(csv_folder) if f.endswith(\".csv\")]\n",
    "\n",
    "# Loop through each file and display column data types\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(csv_folder, file)\n",
    "    print(f\"\\nüìÑ File: {file}\")\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(df.dtypes)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error reading {file}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foreign key imports and datatype consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "## standardize datatypes for identifiers\n",
    "def convert_identifiers_to_string(df, id_columns):\n",
    "    \"\"\"\n",
    "    Converts specified identifier columns in a DataFrame to string type,\n",
    "    safely handling float64 values and preserving missing values (NA).\n",
    "    Avoids SettingWithCopyWarning.\n",
    "    \"\"\"\n",
    "    df = df.copy()  # ensure we're working with a copy, not a slice\n",
    "    for col in id_columns:\n",
    "        if col in df.columns:\n",
    "            df.loc[:, col] = df[col].apply(\n",
    "                lambda x: str(int(x)) if pd.notna(x) and isinstance(x, float) and x.is_integer()\n",
    "                else str(x) if pd.notna(x)\n",
    "                else pd.NA\n",
    "            ).astype(\"string\")\n",
    "    return df\n",
    "\n",
    "#usage\n",
    "\n",
    "# Define identifier columns\n",
    "identifier_columns = [\n",
    "    'sample_id', 'site_info_id', 'profile',\n",
    "    'horizon_id', 'lab_sample_id', 'lab_sample_id', 'climate_id', 'geo_features_id', 'topo_features_id', 'profile_record_id'\n",
    "]\n",
    "\n",
    "# Apply to each relevant dataframe\n",
    "samples_check = convert_identifiers_to_string(samples_check, identifier_columns)\n",
    "df_morpho_cleaned = convert_identifiers_to_string(df_morpho_cleaned, identifier_columns)\n",
    "profile_clean = convert_identifiers_to_string(profile_record_clean, identifier_columns)\n",
    "merged1 = convert_identifiers_to_string(merged1, identifier_columns)\n",
    "site_info_clean = convert_identifiers_to_string(site_info_clean, identifier_columns)\n",
    "#district_clean = convert_identifiers_to_string(district_clean, identifier_columns)\n",
    "soil_type_clean = convert_identifiers_to_string(soil_type_clean, identifier_columns)\n",
    "geo_features_clean = convert_identifiers_to_string(geo_features_clean, identifier_columns)\n",
    "topo_features_clean = convert_identifiers_to_string(topo_features_clean, identifier_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "samples column types:\n",
      "  sample_id: object\n",
      "  site_info_id: object\n",
      "  profile: object\n",
      "  horizon_id: object\n",
      "  profile_record_id: object\n",
      "\n",
      "horizon column types:\n",
      "  sample_id: object\n",
      "  profile: object\n",
      "  horizon_id: object\n",
      "  profile_record_id: object\n",
      "\n",
      "profile column types:\n",
      "  sample_id: object\n",
      "  site_info_id: object\n",
      "  profile: object\n",
      "  profile_record_id: string\n",
      "\n",
      "lab_analysis column types:\n",
      "  sample_id: object\n",
      "  horizon_id: object\n",
      "  lab_sample_id: string\n",
      "  lab_sample_id: string\n",
      "\n",
      "site_info column types:\n",
      "  site_info_id: string\n",
      "  profile: object\n",
      "  climate_id: object\n",
      "\n",
      "soil_type column types:\n",
      "  profile: object\n",
      "\n",
      "geo_features column types:\n",
      "  profile: object\n",
      "  geo_features_id: string\n",
      "\n",
      "topo_features column types:\n",
      "  profile: object\n",
      "  topo_features_id: string\n"
     ]
    }
   ],
   "source": [
    "# Check types of identifier columns in each dataframe\n",
    "dfs = {\n",
    "    \"samples\": samples_check,\n",
    "    \"horizon\": df_morpho_cleaned,\n",
    "    \"profile\": profile_clean,\n",
    "    \"lab_analysis\": merged1,\n",
    "    \"site_info\": site_info_clean,\n",
    "    #\"district_clean\": district_clean,\n",
    "    \"soil_type\": soil_type_clean,\n",
    "    \"geo_features\": geo_features_clean,\n",
    "    \"topo_features\": topo_features_clean,\n",
    "}\n",
    "\n",
    "for name, df in dfs.items():\n",
    "    print(f\"\\n{name} column types:\")\n",
    "    for col in identifier_columns:\n",
    "        if col in df.columns:\n",
    "            print(f\"  {col}: {df[col].dtype}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9704 sample_id(s) in samples_check are missing in horizon.\n",
      "      sample_id\n",
      "1           631\n",
      "3           633\n",
      "7           697\n",
      "8           698\n",
      "9           699\n",
      "...         ...\n",
      "14710     18867\n",
      "14711     18868\n",
      "14712     18869\n",
      "14713     18870\n",
      "14714     18871\n",
      "\n",
      "[9704 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "## validate FK references in tables\n",
    "\n",
    "samples_check['sample_id'] = samples_check['sample_id'].astype(str).str.strip().str.replace('.0', '')\n",
    "df_morpho_cleaned['sample_id'] = df_morpho_cleaned['sample_id'].astype(str).str.strip().str.replace('.0', '')\n",
    "\n",
    "# Check for missing FK references in morphology\n",
    "missing_samples = samples_check[~samples_check['sample_id'].isin(df_morpho_cleaned['sample_id'])]\n",
    "\n",
    "print(f\"{len(missing_samples)} sample_id(s) in samples_check are missing in horizon.\")\n",
    "print(missing_samples[['sample_id']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sample_id\n",
      "0       2044\n",
      "1      15936\n",
      "2      17780\n",
      "3       5288\n",
      "4      13422\n",
      "5      10276\n",
      "6      12228\n",
      "7       9094\n",
      "8      15374\n",
      "9       7359\n",
      "10      1762\n",
      "11     17363\n",
      "12     12169\n",
      "13     18754\n",
      "14      2236\n",
      "15      9709\n",
      "16     16539\n",
      "17     17941\n",
      "18     14442\n",
      "19      7699\n",
      "20     11951\n",
      "21     15690\n",
      "22     11558\n",
      "23      1823\n",
      "24      6124\n"
     ]
    }
   ],
   "source": [
    "#inspecting a random 25 samples that are missing in horizon\n",
    "\n",
    "# Print random sample of 25 missing sample_ids\n",
    "sample_subset = missing_samples.sample(n=25, random_state=42)  # Set random_state for reproducibility\n",
    "print(sample_subset[['sample_id']].reset_index(drop=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9704 samples could not be matched with a horizon_id.\n"
     ]
    }
   ],
   "source": [
    "# Samples table horizon_id FK \n",
    "\n",
    "# Drop old horizon_id if it exists (to avoid confusion)\n",
    "samples_check = samples_check.drop(columns=['horizon_id'], errors='ignore')\n",
    "\n",
    "samples_check['sample_id'] = samples_check['sample_id'].astype(str).str.strip().str.replace('.0', '', regex=False)\n",
    "df_morpho_cleaned['sample_id'] = df_morpho_cleaned['sample_id'].astype(str).str.strip().str.replace('.0', '', regex=False)\n",
    "\n",
    "\n",
    "# Merge horizon_id from morph into samples\n",
    "samples_check = samples_check.merge(\n",
    "    df_morpho_cleaned[['sample_id', 'horizon_id']],\n",
    "    on='sample_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "missing = samples_check[samples_check['horizon_id'].isna()]\n",
    "print(f\"{len(missing)} samples could not be matched with a horizon_id.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>site_info_id</th>\n",
       "      <th>profile</th>\n",
       "      <th>horizon_id</th>\n",
       "      <th>year</th>\n",
       "      <th>shelf</th>\n",
       "      <th>room</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>630</td>\n",
       "      <td>172</td>\n",
       "      <td>139</td>\n",
       "      <td>Hb_139/46_1_1</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>631</td>\n",
       "      <td>173</td>\n",
       "      <td>139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>632</td>\n",
       "      <td>174</td>\n",
       "      <td>139</td>\n",
       "      <td>Hb_139/46_3_1</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>633</td>\n",
       "      <td>175</td>\n",
       "      <td>139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>687</td>\n",
       "      <td>1034</td>\n",
       "      <td>208</td>\n",
       "      <td>Hb_208/46_1_1</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sample_id site_info_id profile     horizon_id    year shelf room\n",
       "0       630          172     139  Hb_139/46_1_1  1946.0     1   22\n",
       "1       631          173     139            NaN  1946.0     1   22\n",
       "2       632          174     139  Hb_139/46_3_1  1946.0     1   22\n",
       "3       633          175     139            NaN  1946.0     1   22\n",
       "4       687         1034     208  Hb_208/46_1_1  1946.0     1   22"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-order and select relevant columns\n",
    "samples_clean1 = samples_check[[\n",
    "    'sample_id',\n",
    "    'site_info_id', \n",
    "    'profile',\n",
    "    'horizon_id',\n",
    "    'year',\n",
    "    'shelf',\n",
    "    'room'  # Ensure this matches the column name in your DataFrame\n",
    "]].copy()\n",
    "\n",
    "# Preview the result\n",
    "samples_clean1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>site_info_id</th>\n",
       "      <th>profile</th>\n",
       "      <th>horizon_id</th>\n",
       "      <th>year</th>\n",
       "      <th>shelf</th>\n",
       "      <th>room</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>630</td>\n",
       "      <td>172</td>\n",
       "      <td>139</td>\n",
       "      <td>Hb_139/46_1_1</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>631</td>\n",
       "      <td>173</td>\n",
       "      <td>139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>632</td>\n",
       "      <td>174</td>\n",
       "      <td>139</td>\n",
       "      <td>Hb_139/46_3_1</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>633</td>\n",
       "      <td>175</td>\n",
       "      <td>139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>687</td>\n",
       "      <td>1034</td>\n",
       "      <td>208</td>\n",
       "      <td>Hb_208/46_1_1</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sample_id site_info_id profile     horizon_id    year shelf room\n",
       "0       630          172     139  Hb_139/46_1_1  1946.0     1   22\n",
       "1       631          173     139            NaN  1946.0     1   22\n",
       "2       632          174     139  Hb_139/46_3_1  1946.0     1   22\n",
       "3       633          175     139            NaN  1946.0     1   22\n",
       "4       687         1034     208  Hb_208/46_1_1  1946.0     1   22"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_clean1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## completing profile_record_clean table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>profile_record_id</th>\n",
       "      <th>profile</th>\n",
       "      <th>site_info_id</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>soil_type_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>139</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>139</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>139</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>139</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>208</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   profile_record_id profile site_info_id sample_id soil_type_id\n",
       "0                  1     139         <NA>      <NA>         <NA>\n",
       "1                  2     139         <NA>      <NA>         <NA>\n",
       "2                  3     139         <NA>      <NA>         <NA>\n",
       "3                  4     139         <NA>      <NA>         <NA>\n",
       "4                  5     208         <NA>      <NA>         <NA>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile_record_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ID'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/tp/79mdnyy56_xc3g1jvp9wf4_80000gn/T/ipykernel_2227/388914968.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'site_info_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sample_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'soil_type_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Merge site_info_id (one-to-one or many-to-one) using 'ID'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m profile_record_clean = profile_record_clean.merge(\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0msite_info_clean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'profile'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'site_info_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ID'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m   9839\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9840\u001b[0m     ) -> DataFrame:\n\u001b[1;32m   9841\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 9843\u001b[0;31m         return merge(\n\u001b[0m\u001b[1;32m   9844\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9845\u001b[0m             \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9846\u001b[0m             \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0mindicator\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0mvalidate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m ) -> DataFrame:\n\u001b[0;32m--> 148\u001b[0;31m     op = _MergeOperation(\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    733\u001b[0m         (\n\u001b[1;32m    734\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m         ) = self._get_merge_keys()\n\u001b[0m\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m         \u001b[0;31m# to avoid incompatible dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1199\u001b[0m                         \u001b[0;31m# Then we're either Hashable or a wrong-length arraylike,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m                         \u001b[0;31m#  the latter of which will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m                         \u001b[0mrk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHashable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mrk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1203\u001b[0;31m                             \u001b[0mright_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1204\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m                             \u001b[0;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m                             \u001b[0mright_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1774\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1776\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1778\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1780\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1781\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ID'"
     ]
    }
   ],
   "source": [
    "# Drop old foreign key columns if they exist\n",
    "profile_record_clean = profile_record_clean.drop(\n",
    "    columns=['site_info_id', 'sample_id', 'soil_type_id'], errors='ignore'\n",
    ")\n",
    "\n",
    "# Merge site_info_id (one-to-one or many-to-one) using 'ID'\n",
    "profile_record_clean = profile_record_clean.merge(\n",
    "    site_info_clean[['profile', 'site_info_id']],\n",
    "    on='ID',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Merge soil_type_id (one-to-one or many-to-one) using 'profile'\n",
    "profile_record_clean = profile_record_clean.merge(\n",
    "    soil_type_clean[['profile', 'soil_type_id']],\n",
    "    on='profile',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Merge sample_id (one-to-one or many-to-one) using 'profile'\n",
    "profile_record_clean = profile_record_clean.merge(\n",
    "    samples_clean1[['profile', 'sample_id']],\n",
    "    on='profile',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "#drop PK and replace w new profile_record_id PK\n",
    "# Drop old FK columns if they exist\n",
    "profile_record_clean = profile_record_clean.drop(\n",
    "    columns=['profile_record_id' ],\n",
    "    errors='ignore'\n",
    ")\n",
    "\n",
    "# Ensure primary key 'profile_record_id' exists\n",
    "if 'profile_record_id' not in profile_record_clean.columns:\n",
    "    profile_record_clean.insert(0, 'profile_record_id', range(1, len(profile_record_clean) + 1))\n",
    "\n",
    "profile_record_clean['profile_record_id'] = profile_record_clean['profile_record_id'].astype(str)\n",
    "\n",
    "# Final column order\n",
    "column_order = [\n",
    "    'profile_record_id',\n",
    "    'profile',\n",
    "    'site_info_id',\n",
    "    'soil_type_id',\n",
    "    'sample_id'\n",
    "]\n",
    "profile_record_clean = profile_record_clean[column_order]\n",
    "\n",
    "# Check for missing links (optional sanity check)\n",
    "missing_site = profile_record_clean[profile_record_clean['site_info_id'].isna()]\n",
    "missing_soil = profile_record_clean[profile_record_clean['soil_type_id'].isna()]\n",
    "\n",
    "print(f\"{len(missing_site)} profiles missing site_info_id\")\n",
    "print(f\"{len(missing_soil)} profiles missing soil_type_id\")\n",
    "\n",
    "profile_record_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horizon_id</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>profile</th>\n",
       "      <th>horizon_layer</th>\n",
       "      <th>upper_depth</th>\n",
       "      <th>lower_depth</th>\n",
       "      <th>dry_color_name</th>\n",
       "      <th>dry_hue</th>\n",
       "      <th>dry_value</th>\n",
       "      <th>dry_chroma</th>\n",
       "      <th>...</th>\n",
       "      <th>compaction</th>\n",
       "      <th>durability</th>\n",
       "      <th>pore_quantity</th>\n",
       "      <th>pore_diameter</th>\n",
       "      <th>pore_shape</th>\n",
       "      <th>root_quantity</th>\n",
       "      <th>root_diameter</th>\n",
       "      <th>moisture_degree</th>\n",
       "      <th>Unnamed: 46</th>\n",
       "      <th>profile_record_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B_101/62_1_1</td>\n",
       "      <td>10999</td>\n",
       "      <td>101_62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Pardo-acinzentado a pardo</td>\n",
       "      <td>10YR</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>Pequena a minima</td>\n",
       "      <td>Brando</td>\n",
       "      <td>Pouco poroso</td>\n",
       "      <td>Muito finos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Muitas finas e bastantes medias</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Seco</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B_101/62_2_1</td>\n",
       "      <td>11000</td>\n",
       "      <td>101_62</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Pardo</td>\n",
       "      <td>10YR</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Pequena</td>\n",
       "      <td>Brando</td>\n",
       "      <td>Pouco poroso</td>\n",
       "      <td>Muito finos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bastantes finas e medias e raras grossas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Seco</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B_101/62_3_1</td>\n",
       "      <td>11001</td>\n",
       "      <td>101_62</td>\n",
       "      <td>3.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>Pardo-amarelado-claro</td>\n",
       "      <td>10YR</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Pequena a minima</td>\n",
       "      <td>Brando</td>\n",
       "      <td>Pouco poroso</td>\n",
       "      <td>Muito finos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Algumas finas e medias e raras grossas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Seco</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B_101/62_4_1</td>\n",
       "      <td>11002</td>\n",
       "      <td>101_62</td>\n",
       "      <td>4.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Amarelo a amarelo-avermelhado</td>\n",
       "      <td>8,75YR</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Pequena a minima</td>\n",
       "      <td>Brando</td>\n",
       "      <td>Pouco a medianamente poroso</td>\n",
       "      <td>Muito finos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Poucas finas, algumas medias e raras grossas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Seco</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B_101/62_5_2</td>\n",
       "      <td>11003</td>\n",
       "      <td>101_62</td>\n",
       "      <td>5.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>Pardo-avermelhado</td>\n",
       "      <td>7,5YR</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Pequena</td>\n",
       "      <td>Brando</td>\n",
       "      <td>Pouco a medianamente poroso</td>\n",
       "      <td>Muito finos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Raras</td>\n",
       "      <td>Medias e grossas</td>\n",
       "      <td>Seco a humido</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     horizon_id sample_id profile  horizon_layer  upper_depth  lower_depth  \\\n",
       "0  B_101/62_1_1     10999  101_62            1.0          0.0         11.0   \n",
       "1  B_101/62_2_1     11000  101_62            2.0         11.0         28.0   \n",
       "2  B_101/62_3_1     11001  101_62            3.0         28.0         54.0   \n",
       "3  B_101/62_4_1     11002  101_62            4.0         54.0         90.0   \n",
       "4  B_101/62_5_2     11003  101_62            5.0         90.0        160.0   \n",
       "\n",
       "                  dry_color_name dry_hue  dry_value  dry_chroma  ...  \\\n",
       "0      Pardo-acinzentado a pardo    10YR        5.0         2.5  ...   \n",
       "1                          Pardo    10YR        5.0         3.0  ...   \n",
       "2          Pardo-amarelado-claro    10YR        6.0         4.0  ...   \n",
       "3  Amarelo a amarelo-avermelhado  8,75YR        7.0         6.0  ...   \n",
       "4              Pardo-avermelhado   7,5YR        7.0         6.0  ...   \n",
       "\n",
       "         compaction durability                pore_quantity  pore_diameter  \\\n",
       "0  Pequena a minima     Brando                 Pouco poroso    Muito finos   \n",
       "1           Pequena     Brando                 Pouco poroso    Muito finos   \n",
       "2  Pequena a minima     Brando                 Pouco poroso    Muito finos   \n",
       "3  Pequena a minima     Brando  Pouco a medianamente poroso    Muito finos   \n",
       "4           Pequena     Brando  Pouco a medianamente poroso    Muito finos   \n",
       "\n",
       "  pore_shape                                 root_quantity     root_diameter  \\\n",
       "0        NaN               Muitas finas e bastantes medias               NaN   \n",
       "1        NaN      Bastantes finas e medias e raras grossas               NaN   \n",
       "2        NaN        Algumas finas e medias e raras grossas               NaN   \n",
       "3        NaN  Poucas finas, algumas medias e raras grossas               NaN   \n",
       "4        NaN                                         Raras  Medias e grossas   \n",
       "\n",
       "  moisture_degree Unnamed: 46 profile_record_id  \n",
       "0            Seco         NaN              <NA>  \n",
       "1            Seco         NaN              <NA>  \n",
       "2            Seco         NaN              <NA>  \n",
       "3            Seco         NaN              <NA>  \n",
       "4   Seco a humido         NaN              <NA>  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_morpho_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to string dtype in both DataFrames before merge\n",
    "df_morpho_cleaned['profile_record_id'] = df_morpho_cleaned['profile_record_id'].astype(str)\n",
    "profile_record_clean['profile_record_id'] = profile_record_clean['profile_record_id'].astype(str)\n",
    "\n",
    "#drop old FK\n",
    "# Drop old FK columns if they exist\n",
    "df_morpho_cleaned = df_morpho_cleaned.drop(\n",
    "    columns=['profile_record_id'],\n",
    "    errors='ignore'\n",
    ")\n",
    "# Now merge on 'profile_record_id'\n",
    "df_morpho_cleaned = df_morpho_cleaned.merge(\n",
    "    profile_record_clean[['profile', 'profile_record_id']],\n",
    "    on='profile',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "df_morpho_cleaned1 = df_morpho_cleaned[[\n",
    "    'horizon_id',\n",
    "    'sample_id',\n",
    "    #'profile_record_id',\n",
    "    'profile',\n",
    "    'horizon_layer',\n",
    "    'upper_depth',\n",
    "    'lower_depth',\n",
    "    'moisture_degree',\n",
    "    'root_quantity',\n",
    "    'root_diameter',\n",
    "    'texture',\n",
    "    'structure_type',\n",
    "    'structure_class',\n",
    "    'structure_degree',\n",
    "    'pore_diameter',\n",
    "    'pore_quantity',\n",
    "    'pore_shape',\n",
    "    'dry_color_name',\n",
    "    'dry_hue',\n",
    "    'dry_value',\n",
    "    'dry_chroma',\n",
    "    'moist_color_name',\n",
    "    'moist_hue',\n",
    "    'moist_value',\n",
    "    'moist_chroma',\n",
    "    'compaction',\n",
    "    'durability'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horizon_id</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>profile</th>\n",
       "      <th>horizon_layer</th>\n",
       "      <th>upper_depth</th>\n",
       "      <th>lower_depth</th>\n",
       "      <th>moisture_degree</th>\n",
       "      <th>root_quantity</th>\n",
       "      <th>root_diameter</th>\n",
       "      <th>texture</th>\n",
       "      <th>...</th>\n",
       "      <th>dry_color_name</th>\n",
       "      <th>dry_hue</th>\n",
       "      <th>dry_value</th>\n",
       "      <th>dry_chroma</th>\n",
       "      <th>moist_color_name</th>\n",
       "      <th>moist_hue</th>\n",
       "      <th>moist_value</th>\n",
       "      <th>moist_chroma</th>\n",
       "      <th>compaction</th>\n",
       "      <th>durability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B_101/62_1_1</td>\n",
       "      <td>10999</td>\n",
       "      <td>101_62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Seco</td>\n",
       "      <td>Muitas finas e bastantes medias</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arenoso</td>\n",
       "      <td>...</td>\n",
       "      <td>Pardo-acinzentado a pardo</td>\n",
       "      <td>10YR</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Pardo-acinzentado-escuro</td>\n",
       "      <td>10YR</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Pequena a minima</td>\n",
       "      <td>Brando</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B_101/62_2_1</td>\n",
       "      <td>11000</td>\n",
       "      <td>101_62</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Seco</td>\n",
       "      <td>Bastantes finas e medias e raras grossas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arenoso-franco</td>\n",
       "      <td>...</td>\n",
       "      <td>Pardo</td>\n",
       "      <td>10YR</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Pardo-amarelado-escuro</td>\n",
       "      <td>10YR</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Pequena</td>\n",
       "      <td>Brando</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B_101/62_3_1</td>\n",
       "      <td>11001</td>\n",
       "      <td>101_62</td>\n",
       "      <td>3.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>Seco</td>\n",
       "      <td>Algumas finas e medias e raras grossas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arenoso-franco</td>\n",
       "      <td>...</td>\n",
       "      <td>Pardo-amarelado-claro</td>\n",
       "      <td>10YR</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Pardo-amarelado-escuro</td>\n",
       "      <td>10YR</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Pequena a minima</td>\n",
       "      <td>Brando</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B_101/62_4_1</td>\n",
       "      <td>11002</td>\n",
       "      <td>101_62</td>\n",
       "      <td>4.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Seco</td>\n",
       "      <td>Poucas finas, algumas medias e raras grossas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Franco-arenoso a arenoso-franco</td>\n",
       "      <td>...</td>\n",
       "      <td>Amarelo a amarelo-avermelhado</td>\n",
       "      <td>8,75YR</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Pardo-forte</td>\n",
       "      <td>7,5YR</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Pequena a minima</td>\n",
       "      <td>Brando</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B_101/62_5_2</td>\n",
       "      <td>11003</td>\n",
       "      <td>101_62</td>\n",
       "      <td>5.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>Seco a humido</td>\n",
       "      <td>Raras</td>\n",
       "      <td>Medias e grossas</td>\n",
       "      <td>Arenoso-franco</td>\n",
       "      <td>...</td>\n",
       "      <td>Pardo-avermelhado</td>\n",
       "      <td>7,5YR</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Pardo-forte</td>\n",
       "      <td>7,5YR</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Pequena</td>\n",
       "      <td>Brando</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     horizon_id sample_id profile  horizon_layer  upper_depth  lower_depth  \\\n",
       "0  B_101/62_1_1     10999  101_62            1.0          0.0         11.0   \n",
       "1  B_101/62_2_1     11000  101_62            2.0         11.0         28.0   \n",
       "2  B_101/62_3_1     11001  101_62            3.0         28.0         54.0   \n",
       "3  B_101/62_4_1     11002  101_62            4.0         54.0         90.0   \n",
       "4  B_101/62_5_2     11003  101_62            5.0         90.0        160.0   \n",
       "\n",
       "  moisture_degree                                 root_quantity  \\\n",
       "0            Seco               Muitas finas e bastantes medias   \n",
       "1            Seco      Bastantes finas e medias e raras grossas   \n",
       "2            Seco        Algumas finas e medias e raras grossas   \n",
       "3            Seco  Poucas finas, algumas medias e raras grossas   \n",
       "4   Seco a humido                                         Raras   \n",
       "\n",
       "      root_diameter                          texture  ...  \\\n",
       "0               NaN                          Arenoso  ...   \n",
       "1               NaN                   Arenoso-franco  ...   \n",
       "2               NaN                   Arenoso-franco  ...   \n",
       "3               NaN  Franco-arenoso a arenoso-franco  ...   \n",
       "4  Medias e grossas                   Arenoso-franco  ...   \n",
       "\n",
       "                  dry_color_name dry_hue dry_value dry_chroma  \\\n",
       "0      Pardo-acinzentado a pardo    10YR       5.0        2.5   \n",
       "1                          Pardo    10YR       5.0        3.0   \n",
       "2          Pardo-amarelado-claro    10YR       6.0        4.0   \n",
       "3  Amarelo a amarelo-avermelhado  8,75YR       7.0        6.0   \n",
       "4              Pardo-avermelhado   7,5YR       7.0        6.0   \n",
       "\n",
       "           moist_color_name moist_hue moist_value moist_chroma  \\\n",
       "0  Pardo-acinzentado-escuro      10YR         4.0          2.0   \n",
       "1    Pardo-amarelado-escuro      10YR         3.0          4.0   \n",
       "2    Pardo-amarelado-escuro      10YR         4.0          4.0   \n",
       "3               Pardo-forte     7,5YR         5.0          6.0   \n",
       "4               Pardo-forte     7,5YR         5.0          6.0   \n",
       "\n",
       "         compaction  durability  \n",
       "0  Pequena a minima      Brando  \n",
       "1           Pequena      Brando  \n",
       "2  Pequena a minima      Brando  \n",
       "3  Pequena a minima      Brando  \n",
       "4           Pequena      Brando  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_morpho_cleaned1.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_morpho_cleaned1.to_csv('/Users/inesschwartz/Desktop/morpho_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Completing site_info_clean table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tp/79mdnyy56_xc3g1jvp9wf4_80000gn/T/ipykernel_8750/4452788.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  climate_features_clean['ID'] = climate_features_clean['ID'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "# Convert keys to string before merge to avoid dtype mismatch errors\n",
    "site_info_clean['site_info_id'] = site_info_clean['ID'].astype(str)\n",
    "geo_features_clean['ID'] = geo_features_clean['ID'].astype(str)\n",
    "climate_features_clean['ID'] = climate_features_clean['ID'].astype(str)\n",
    "topo_features_clean['ID'] = topo_features_clean['ID'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop old FK columns if they exist\n",
    "site_info_clean = site_info_clean.drop(\n",
    "    columns=['geo_features_id', 'climate_id', 'topo_features_id', 'district_id', 'land_cover_id', 'geology_id','topo_feature_id','sampling_date', 'districts_id' ],\n",
    "    errors='ignore'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dropped 'ID' from site_info_clean\n",
      "‚úÖ Dropped 'ID' from geo_features_clean\n",
      "‚úÖ Dropped 'ID' from climate_features_clean\n",
      "‚úÖ Dropped 'ID' from topo_features_clean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tp/79mdnyy56_xc3g1jvp9wf4_80000gn/T/ipykernel_8750/2925909182.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  climate_features_clean['ID'] = climate_features_clean['ID'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "# --- Step 1: Convert 'ID' columns to string ---\n",
    "site_info_clean['ID'] = site_info_clean['ID'].astype(str)\n",
    "geo_features_clean['ID'] = geo_features_clean['ID'].astype(str)\n",
    "climate_features_clean['ID'] = climate_features_clean['ID'].astype(str)\n",
    "topo_features_clean['ID'] = topo_features_clean['ID'].astype(str)\n",
    "\n",
    "# --- Step 2: Merge feature tables into site_info_clean ---\n",
    "site_info_clean = site_info_clean.merge(\n",
    "    geo_features_clean[['ID', 'geo_features_id']],\n",
    "    on='ID',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "site_info_clean = site_info_clean.merge(\n",
    "    climate_features_clean[['ID', 'climate_id']],\n",
    "    on='ID',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "site_info_clean = site_info_clean.merge(\n",
    "    topo_features_clean[['ID', 'topo_features_id']],\n",
    "    on='ID',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# --- Step 3: Drop 'ID' column from all involved tables ---\n",
    "for table in ['site_info_clean', 'geo_features_clean', 'climate_features_clean', 'topo_features_clean']:\n",
    "    df = globals().get(table)\n",
    "    if df is not None and 'ID' in df.columns:\n",
    "        df = df.drop(columns=['ID'])\n",
    "        globals()[table] = df\n",
    "        print(f\"‚úÖ Dropped 'ID' from {table}\")\n",
    "    else:\n",
    "        print(f\"‚è≠Ô∏è Skipping {table}: not found or no 'ID' column\")\n",
    "\n",
    "# --- District: Skip merging district_id, use district name directly ---\n",
    "\n",
    "# don't see need for district_id, just use district name\n",
    "# For district (assuming district columns are already strings)\n",
    "# site_info_clean = site_info_clean.merge(\n",
    "#     district_clean[['district', 'district_id']],\n",
    "#     on='district',\n",
    "#     how='left'\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_info_id</th>\n",
       "      <th>profile</th>\n",
       "      <th>X_coord</th>\n",
       "      <th>Y_coord</th>\n",
       "      <th>district</th>\n",
       "      <th>geo_features_id</th>\n",
       "      <th>climate_id</th>\n",
       "      <th>topo_features_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2770</td>\n",
       "      <td>1/57</td>\n",
       "      <td>12.161278</td>\n",
       "      <td>-15.222598</td>\n",
       "      <td>Namibe</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>1/59</td>\n",
       "      <td>12.575775</td>\n",
       "      <td>-4.866986</td>\n",
       "      <td>Cabinda</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1618</td>\n",
       "      <td>1/61</td>\n",
       "      <td>15.098840</td>\n",
       "      <td>-11.225411</td>\n",
       "      <td>Cuanza Sul</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>881</td>\n",
       "      <td>1/63</td>\n",
       "      <td>17.081955</td>\n",
       "      <td>-9.274587</td>\n",
       "      <td>Malanje</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1750</td>\n",
       "      <td>1/64</td>\n",
       "      <td>20.788116</td>\n",
       "      <td>-11.568683</td>\n",
       "      <td>Moxico</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  site_info_id profile    X_coord    Y_coord    district  geo_features_id  \\\n",
       "0         2770    1/57  12.161278 -15.222598      Namibe                1   \n",
       "1           48    1/59  12.575775  -4.866986     Cabinda                2   \n",
       "2         1618    1/61  15.098840 -11.225411  Cuanza Sul                3   \n",
       "3          881    1/63  17.081955  -9.274587     Malanje                4   \n",
       "4         1750    1/64  20.788116 -11.568683      Moxico                5   \n",
       "\n",
       "   climate_id  topo_features_id  \n",
       "0           1                 1  \n",
       "1           2                 2  \n",
       "2           3                 3  \n",
       "3           4                 4  \n",
       "4           5                 5  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "site_info_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "## need to drop ID from climate, geo_features, topo_features, and site_info_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_info_id</th>\n",
       "      <th>profile</th>\n",
       "      <th>X_coord</th>\n",
       "      <th>Y_coord</th>\n",
       "      <th>district</th>\n",
       "      <th>geo_features_id</th>\n",
       "      <th>climate_id</th>\n",
       "      <th>topo_features_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2770</td>\n",
       "      <td>1/57</td>\n",
       "      <td>12.161278</td>\n",
       "      <td>-15.222598</td>\n",
       "      <td>Namibe</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>1/59</td>\n",
       "      <td>12.575775</td>\n",
       "      <td>-4.866986</td>\n",
       "      <td>Cabinda</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1618</td>\n",
       "      <td>1/61</td>\n",
       "      <td>15.098840</td>\n",
       "      <td>-11.225411</td>\n",
       "      <td>Cuanza Sul</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>881</td>\n",
       "      <td>1/63</td>\n",
       "      <td>17.081955</td>\n",
       "      <td>-9.274587</td>\n",
       "      <td>Malanje</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1750</td>\n",
       "      <td>1/64</td>\n",
       "      <td>20.788116</td>\n",
       "      <td>-11.568683</td>\n",
       "      <td>Moxico</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  site_info_id profile    X_coord    Y_coord    district  geo_features_id  \\\n",
       "0         2770    1/57  12.161278 -15.222598      Namibe                1   \n",
       "1           48    1/59  12.575775  -4.866986     Cabinda                2   \n",
       "2         1618    1/61  15.098840 -11.225411  Cuanza Sul                3   \n",
       "3          881    1/63  17.081955  -9.274587     Malanje                4   \n",
       "4         1750    1/64  20.788116 -11.568683      Moxico                5   \n",
       "\n",
       "   climate_id  topo_features_id  \n",
       "0           1                 1  \n",
       "1           2                 2  \n",
       "2           3                 3  \n",
       "3           4                 4  \n",
       "4           5                 5  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "site_info_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>profile_record_id</th>\n",
       "      <th>profile</th>\n",
       "      <th>site_info_id</th>\n",
       "      <th>soil_type_id</th>\n",
       "      <th>sample_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>139</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>139</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>139</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>139</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>139</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  profile_record_id profile site_info_id  soil_type_id sample_id\n",
       "0                 1     139         <NA>           NaN       630\n",
       "1                 2     139         <NA>           NaN       631\n",
       "2                 3     139         <NA>           NaN       632\n",
       "3                 4     139         <NA>           NaN       633\n",
       "4                 5     139         <NA>           NaN      1817"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile_record_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "## changing column headers to be SQL friendly\n",
    "# Rename problematic columns\n",
    "merged1 = merged1.rename(columns={\n",
    "    'atm_1/3': 'atm_1_3',\n",
    "    'Ca++': 'Ca',\n",
    "    'Mg++': 'Mg',\n",
    "    'Na+': 'Na',\n",
    "    'K+': 'K',\n",
    "    'Min_<0,002': 'Min_lt_0002',\n",
    "    'Min_0,05-0,02': 'Min_005_002',\n",
    "    'Min_0,2-0,05': 'Min_02_005',\n",
    "    'Min_2-0,2': 'Min_2_02',\n",
    "    'As': 'arsenic',\n",
    "    'P': 'phosphorus',\n",
    "    'S': 'sulfur',\n",
    "    'V': 'vanadium'\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVING CLEANED TABLES TO CSV FOR DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Prepare dictionary of clean tables\n",
    "tables = {\n",
    "    \"samples\": samples_clean1,\n",
    "    \"analyses\": merged1,\n",
    "    \"profile_record\": profile_record_clean,\n",
    "    \"morphology_horizon\": morphology_clean1,\n",
    "    \"soil_type\": soil_type_clean,\n",
    "    \"site_info\": site_info_clean,\n",
    "    \"climate_feat\": climate_features_clean,\n",
    "    \"topo_feat\": topo_features_clean,\n",
    "    \"geo_feat\": geo_features_clean,\n",
    "    #\"districts\": district_clean\n",
    "}\n",
    "\n",
    "# # Save each table to CSV with 'NULL' in empty cells\n",
    "for name, df in tables.items():\n",
    "#     df.replace(\"\", pd.NA, inplace=True)  # Replace empty strings with NA\n",
    "    df.to_csv(f\"/Users/inesschwartz/GreenDataScience/Thesis/tables_clean/{name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save random 100 rows of each table as mini versions for DB test\n",
    "import os\n",
    "\n",
    "# Create folder if it doesn't exist\n",
    "mini_path = \"/Users/inesschwartz/GreenDataScience/Thesis/tables_clean_mini\"\n",
    "os.makedirs(mini_path, exist_ok=True)\n",
    "\n",
    "# Save random 100 rows of each table as mini versions\n",
    "samples_clean.sample(n=100, random_state=42).to_csv(f\"{mini_path}/samples.csv\", index=False)\n",
    "merged1.sample(n=100, random_state=42).to_csv(f\"{mini_path}/analyses.csv\", index=False)\n",
    "profile_record_clean.sample(n=100, random_state=42).to_csv(f\"{mini_path}/profile_record.csv\", index=False)\n",
    "morphology_clean1.sample(n=100, random_state=42).to_csv(f\"{mini_path}/morphology_horizon.csv\", index=False)\n",
    "soil_type_clean.sample(n=100, random_state=42).to_csv(f\"{mini_path}/soil_type.csv\", index=False)\n",
    "site_info_clean.sample(n=100, random_state=42).to_csv(f\"{mini_path}/site_info.csv\", index=False)\n",
    "climate_features_clean.sample(n=100, random_state=42).to_csv(f\"{mini_path}/climate_feat.csv\", index=False)\n",
    "topo_features_clean.sample(n=100, random_state=42).to_csv(f\"{mini_path}/topo_feat.csv\", index=False)\n",
    "geo_features_clean.sample(n=100, random_state=42).to_csv(f\"{mini_path}/geo_feat.csv\", index=False)\n",
    "#district_clean.sample(n=100, random_state=42).to_csv(f\"{mini_path}/districts.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "samples (14766 rows):\n",
      "  - sample_id (object)\n",
      "  - site_info_id (object)\n",
      "  - profile (object)\n",
      "  - horizon_id (object)\n",
      "  - year (float64)\n",
      "  - shelf (string)\n",
      "  - room (object)\n",
      "\n",
      "analyses (7847 rows):\n",
      "  - lab_sample_id (object)\n",
      "  - sample_id (object)\n",
      "  - EG (float64)\n",
      "  - thick_clay (float64)\n",
      "  - fine_clay (float64)\n",
      "  - silt (float64)\n",
      "  - clay (float64)\n",
      "  - Eq_Hum (float64)\n",
      "  - atm_1_3 (float64)\n",
      "  - atm_15 (float64)\n",
      "  - CACO3 (float64)\n",
      "  - gypsum (float64)\n",
      "  - free_iron (float64)\n",
      "  - organic_carbon (float64)\n",
      "  - total_N (float64)\n",
      "  - P205 (float64)\n",
      "  - organic_material (float64)\n",
      "  - pH_H2O (float64)\n",
      "  - pH_KCL (float64)\n",
      "  - Ca (float64)\n",
      "  - Mg (float64)\n",
      "  - Na (float64)\n",
      "  - K (float64)\n",
      "  - exchangable_bases_sum (float64)\n",
      "  - CEC (float64)\n",
      "  - vanadium (object)\n",
      "  - conductivity (float64)\n",
      "  - soluble_sodium (float64)\n",
      "  - Min_lt_0002 (object)\n",
      "  - Min_005_002 (object)\n",
      "  - Min_02_005 (object)\n",
      "  - Min_2_02 (object)\n",
      "  - field_sample_code (object)\n",
      "  - Depth (object)\n",
      "  - Al (float64)\n",
      "  - Si (float64)\n",
      "  - phosphorus (float64)\n",
      "  - sulfur (object)\n",
      "  - Cl (float64)\n",
      "  - Ti (float64)\n",
      "  - Cr (float64)\n",
      "  - Mn (float64)\n",
      "  - Fe (float64)\n",
      "  - Co (float64)\n",
      "  - Ni (float64)\n",
      "  - Cu (float64)\n",
      "  - Zn (float64)\n",
      "  - arsenic (float64)\n",
      "  - Se (float64)\n",
      "  - Rb (float64)\n",
      "  - Sr (float64)\n",
      "  - Zr (float64)\n",
      "  - Nb (float64)\n",
      "  - Mo (float64)\n",
      "  - Cd (float64)\n",
      "  - Sn (float64)\n",
      "  - Sb (float64)\n",
      "  - Ba (float64)\n",
      "  - Ta (float64)\n",
      "  - W (float64)\n",
      "  - Pt (float64)\n",
      "  - Au (float64)\n",
      "  - Hg (float64)\n",
      "  - Tl (float64)\n",
      "  - Pb (float64)\n",
      "  - Bi (float64)\n",
      "  - Th (float64)\n",
      "  - U (float64)\n",
      "\n",
      "profile_record (86665 rows):\n",
      "  - profile_record_id (object)\n",
      "  - profile (object)\n",
      "  - site_info_id (string)\n",
      "  - soil_type_id (float64)\n",
      "  - sample_id (object)\n",
      "\n",
      "morphology_horizon (207408 rows):\n",
      "  - horizon_id (object)\n",
      "  - sample_id (string)\n",
      "  - profile_record_id (object)\n",
      "  - horizon_layer (float64)\n",
      "  - upper_depth (float64)\n",
      "  - lower_depth (float64)\n",
      "  - moisture_degree (object)\n",
      "  - root_quantity (object)\n",
      "  - root_diameter (object)\n",
      "  - texture (object)\n",
      "  - structure_type (object)\n",
      "  - structure_class (object)\n",
      "  - structure_degree (object)\n",
      "  - pore_diameter (object)\n",
      "  - pore_quantity (object)\n",
      "  - pore_shape (object)\n",
      "  - dry_color_name (object)\n",
      "  - dry_hue (object)\n",
      "  - dry_value (float64)\n",
      "  - dry_chroma (float64)\n",
      "  - moist_color_name (object)\n",
      "  - moist_hue (object)\n",
      "  - moist_value (float64)\n",
      "  - moist_chroma (float64)\n",
      "  - compaction (object)\n",
      "  - durability (object)\n",
      "\n",
      "soil_type (2518 rows):\n",
      "  - soil_type_id (int64)\n",
      "  - profile (object)\n",
      "  - CEP_GR (object)\n",
      "  - CEP_NAME (object)\n",
      "  - FAO (object)\n",
      "\n",
      "site_info (4321 rows):\n",
      "  - site_info_id (object)\n",
      "  - profile (object)\n",
      "  - X_coord (float64)\n",
      "  - Y_coord (float64)\n",
      "  - district (object)\n",
      "  - geo_features_id (int64)\n",
      "  - climate_id (int64)\n",
      "  - topo_features_id (int64)\n",
      "\n",
      "climate_feat (4321 rows):\n",
      "  - climate_id (int64)\n",
      "  - mean_annual_temp (object)\n",
      "  - mean_annual_precip (object)\n",
      "  - koppen_climate (object)\n",
      "  - thornthwaite_climate (object)\n",
      "  - hydric_regime (object)\n",
      "  - thermal_regime (object)\n",
      "\n",
      "topo_feat (4321 rows):\n",
      "  - topo_features_id (int64)\n",
      "  - slope_code (object)\n",
      "  - altitude (float64)\n",
      "  - aspect (object)\n",
      "  - land_surface_temp (object)\n",
      "  - dem_elevation (object)\n",
      "\n",
      "geo_feat (4321 rows):\n",
      "  - geo_features_id (int64)\n",
      "  - geology_id (object)\n",
      "  - lithology_id (object)\n",
      "  - lithology_1954_id (object)\n"
     ]
    }
   ],
   "source": [
    "# List your DataFrame variables here\n",
    "dataframes = {\n",
    "    \"samples\": samples_clean1,\n",
    "    \"analyses\": merged1,\n",
    "    \"profile_record\": profile_record_clean,\n",
    "    \"morphology_horizon\": morphology_clean1,\n",
    "    \"soil_type\": soil_type_clean,\n",
    "    \"site_info\": site_info_clean,\n",
    "    \"climate_feat\": climate_features_clean,\n",
    "    \"topo_feat\": topo_features_clean,\n",
    "    \"geo_feat\": geo_features_clean\n",
    "    #\"districts\": district_clean\n",
    "}\n",
    "\n",
    "# Print column names and their datatypes\n",
    "for name, df in dataframes.items():\n",
    "    print(f\"\\n{name} ({len(df)} rows):\")\n",
    "    for col in df.columns:\n",
    "        dtype = df[col].dtype\n",
    "        print(f\"  - {col} ({dtype})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      profile_record_id profile site_info_id  soil_type_id sample_id\n",
      "0                     1     139         <NA>           NaN       630\n",
      "1                     2     139         <NA>           NaN       631\n",
      "2                     3     139         <NA>           NaN       632\n",
      "3                     4     139         <NA>           NaN       633\n",
      "4                     5     139         <NA>           NaN      1817\n",
      "...                 ...     ...          ...           ...       ...\n",
      "86660             86661  540/67         3627           NaN     18867\n",
      "86661             86662  540/67         3627           NaN     18868\n",
      "86662             86663  540/67         3627           NaN     18869\n",
      "86663             86664  540/67         3627           NaN     18870\n",
      "86664             86665  538/67         3611           NaN     18871\n",
      "\n",
      "[51532 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "missing = profile_record_clean[~profile_record_clean['soil_type_id'].isin(soil_type_clean['soil_type_id'])]\n",
    "print(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>site_info_id</th>\n",
       "      <th>profile</th>\n",
       "      <th>horizon_id</th>\n",
       "      <th>year</th>\n",
       "      <th>shelf</th>\n",
       "      <th>room</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>630</td>\n",
       "      <td>172</td>\n",
       "      <td>139</td>\n",
       "      <td>Hb_139/46_1_1</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>631</td>\n",
       "      <td>173</td>\n",
       "      <td>139</td>\n",
       "      <td>Hb_139/46_2_1</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>632</td>\n",
       "      <td>174</td>\n",
       "      <td>139</td>\n",
       "      <td>Hb_139/46_3_1</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>633</td>\n",
       "      <td>175</td>\n",
       "      <td>139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>687</td>\n",
       "      <td>1034</td>\n",
       "      <td>208</td>\n",
       "      <td>Hb_208/46_1_1</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sample_id site_info_id profile     horizon_id    year shelf room\n",
       "0       630          172     139  Hb_139/46_1_1  1946.0     1   22\n",
       "1       631          173     139  Hb_139/46_2_1  1946.0     1   22\n",
       "2       632          174     139  Hb_139/46_3_1  1946.0     1   22\n",
       "3       633          175     139            NaN  1946.0     1   22\n",
       "4       687         1034     208  Hb_208/46_1_1  1946.0     1   22"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_clean1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     site_info_id profile    X_coord    Y_coord    district  geo_features_id  \\\n",
      "0            2770    1/57  12.161278 -15.222598      Namibe                1   \n",
      "2            1618    1/61  15.098840 -11.225411  Cuanza Sul                3   \n",
      "4            1750    1/64  20.788116 -11.568683      Moxico                5   \n",
      "5            3097    1/66  17.666766 -14.655526         NaN                6   \n",
      "8            2675   10/54  14.445188 -14.922688       Huila                9   \n",
      "...           ...     ...        ...        ...         ...              ...   \n",
      "4313         1689   99/63  18.164654 -11.382465     Malanje             4314   \n",
      "4314         3247   99/66  18.994294 -15.814591         NaN             4315   \n",
      "4317         1485  99c/63  17.541534 -10.890781     Malanje             4318   \n",
      "4319         1213   9c/63  16.357859  -9.986349     Malanje             4320   \n",
      "4320         1505   9c/65  20.937136 -10.942842   Lunda Sul             4321   \n",
      "\n",
      "      climate_id  topo_features_id  \n",
      "0              1                 1  \n",
      "2              3                 3  \n",
      "4              5                 5  \n",
      "5              6                 6  \n",
      "8              9                 9  \n",
      "...          ...               ...  \n",
      "4313        4314              4314  \n",
      "4314        4315              4315  \n",
      "4317        4318              4318  \n",
      "4319        4320              4320  \n",
      "4320        4321              4321  \n",
      "\n",
      "[3136 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "missing1 = site_info_clean[~site_info_clean['site_info_id'].isin(samples_clean['site_info_id'])]\n",
    "print(missing1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>soil_type_id</th>\n",
       "      <th>profile</th>\n",
       "      <th>CEP_GR</th>\n",
       "      <th>CEP_NAME</th>\n",
       "      <th>FAO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1/51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1/57</td>\n",
       "      <td>Aridicos</td>\n",
       "      <td>Aridicos com calcario Pardo-cinzentos</td>\n",
       "      <td>CLha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1/59</td>\n",
       "      <td>Psamoferralicos</td>\n",
       "      <td>Psamo-ferralicos Amarelos ou Alaranjados, sedi...</td>\n",
       "      <td>FRxa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1/63</td>\n",
       "      <td>Ferraliticos</td>\n",
       "      <td>Fracamente Ferralicos Vermelhos Clino-argilico...</td>\n",
       "      <td>FRh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>10/54</td>\n",
       "      <td>Ferraliticos</td>\n",
       "      <td>Fracamente Ferralicos pardo-amarelados</td>\n",
       "      <td>FRh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   soil_type_id profile           CEP_GR  \\\n",
       "0             1    1/51              NaN   \n",
       "1             2    1/57         Aridicos   \n",
       "2             3    1/59  Psamoferralicos   \n",
       "3             4    1/63     Ferraliticos   \n",
       "4             5   10/54     Ferraliticos   \n",
       "\n",
       "                                            CEP_NAME   FAO  \n",
       "0                                                NaN   NaN  \n",
       "1              Aridicos com calcario Pardo-cinzentos  CLha  \n",
       "2  Psamo-ferralicos Amarelos ou Alaranjados, sedi...  FRxa  \n",
       "3  Fracamente Ferralicos Vermelhos Clino-argilico...   FRh  \n",
       "4             Fracamente Ferralicos pardo-amarelados   FRh  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soil_type_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå These rows reference soil_type_id values that do NOT exist in soil_type.csv:\n",
      "      profile_record_id profile site_info_id  soil_type_id sample_id\n",
      "0                     1     139         <NA>           NaN       630\n",
      "1                     2     139         <NA>           NaN       631\n",
      "2                     3     139         <NA>           NaN       632\n",
      "3                     4     139         <NA>           NaN       633\n",
      "4                     5     139         <NA>           NaN      1817\n",
      "...                 ...     ...          ...           ...       ...\n",
      "86660             86661  540/67         3627           NaN     18867\n",
      "86661             86662  540/67         3627           NaN     18868\n",
      "86662             86663  540/67         3627           NaN     18869\n",
      "86663             86664  540/67         3627           NaN     18870\n",
      "86664             86665  538/67         3611           NaN     18871\n",
      "\n",
      "[51532 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Get list of valid soil_type_ids\n",
    "valid_soil_type_ids = set(soil_type_clean['soil_type_id'])\n",
    "\n",
    "# Find invalid soil_type_ids in profile_df\n",
    "invalid_rows = profile_record_clean[~profile_record_clean['soil_type_id'].isin(valid_soil_type_ids)]\n",
    "\n",
    "# Show the result\n",
    "if not invalid_rows.empty:\n",
    "    print(\"‚ùå These rows reference soil_type_id values that do NOT exist in soil_type.csv:\")\n",
    "    print(invalid_rows)\n",
    "else:\n",
    "    print(\"‚úÖ All soil_type_id values in profile_record.csv are valid.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>profile_record_id</th>\n",
       "      <th>profile</th>\n",
       "      <th>site_info_id</th>\n",
       "      <th>soil_type_id</th>\n",
       "      <th>sample_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>139</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>139</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>139</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>139</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>139</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  profile_record_id profile site_info_id  soil_type_id sample_id\n",
       "0                 1     139         <NA>           NaN       630\n",
       "1                 2     139         <NA>           NaN       631\n",
       "2                 3     139         <NA>           NaN       632\n",
       "3                 4     139         <NA>           NaN       633\n",
       "4                 5     139         <NA>           NaN      1817"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile_record_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå These rows have NULL values in the site_info_id column of profile_record.csv:\n",
      "      profile_record_id profile site_info_id  soil_type_id sample_id\n",
      "0                     1     139         <NA>           NaN       630\n",
      "1                     2     139         <NA>           NaN       631\n",
      "2                     3     139         <NA>           NaN       632\n",
      "3                     4     139         <NA>           NaN       633\n",
      "4                     5     139         <NA>           NaN      1817\n",
      "...                 ...     ...          ...           ...       ...\n",
      "86240             86241  508/71         <NA>           NaN     18765\n",
      "86267             86268  516/68         <NA>           NaN     18772\n",
      "86268             86269  516/69         <NA>           NaN     18773\n",
      "86270             86271  493/68         <NA>           NaN     18781\n",
      "86271             86272  493/69         <NA>           NaN     18782\n",
      "\n",
      "[29884 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Find rows where soil_type_id is null in profile_record_clean\n",
    "null_rows = profile_record_clean[profile_record_clean['site_info_id'].isnull()]\n",
    "\n",
    "# Show the result\n",
    "if not null_rows.empty:\n",
    "    print(\"‚ùå These rows have NULL values in the site_info_id column of profile_record.csv:\")\n",
    "    print(null_rows)\n",
    "else:\n",
    "    print(\"‚úÖ No NULL values found in the site_info_id column of profile_record.csv.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ No NULL values found in the ID column of perfis_local.csv.\n"
     ]
    }
   ],
   "source": [
    "# Find rows where soil_type_id is null in profile_record_clean\n",
    "null_rows = profile_loc[profile_loc['ID'].isnull()]\n",
    "\n",
    "# Show the result\n",
    "if not null_rows.empty:\n",
    "    print(\"‚ùå These rows have NULL values in the ID column of perfis_local.csv:\")\n",
    "    print(null_rows)\n",
    "else:\n",
    "    print(\"‚úÖ No NULL values found in the ID column of perfis_local.csv.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soil_type_ids in profile_record missing from soil_type.csv: {nan}\n"
     ]
    }
   ],
   "source": [
    "soil_type_ids = set(soil_type_clean['soil_type_id'].unique())\n",
    "profile_soil_type_ids = set(profile_record_clean['soil_type_id'].unique())\n",
    "\n",
    "missing_ids = profile_soil_type_ids - soil_type_ids\n",
    "\n",
    "print(\"soil_type_ids in profile_record missing from soil_type.csv:\", missing_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4835 in soil_type.csv? False\n",
      "4835 in profile_record.csv? False\n"
     ]
    }
   ],
   "source": [
    "# Check if 4835 is in soil_type_id column of soil_type.csv\n",
    "soil_type_has_4835 = 4835 in soil_type_clean['soil_type_id'].values\n",
    "\n",
    "# Check if 4835 is in soil_type_id column of profile_record.csv\n",
    "profile_record_has_4835 = 4835 in profile_record_clean['soil_type_id'].values\n",
    "\n",
    "print(f\"4835 in soil_type.csv? {soil_type_has_4835}\")\n",
    "print(f\"4835 in profile_record.csv? {profile_record_has_4835}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(4835 in profile_record_clean['soil_type_id'].values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
