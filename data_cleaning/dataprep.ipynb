{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepping (joining) datasets for DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in cleaned datasets for joins\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "samples_check = pd.read_csv(\"/Users/inesschwartz/Desktop/cleandata/samples.csv\")\n",
    "morpho = pd.read_csv(\"/Users/inesschwartz/Desktop/cleandata/morpho.csv\")\n",
    "lab_analysis = pd.read_csv(\"/Users/inesschwartz/Desktop/cleandata/analyses.csv\")\n",
    "site_info = pd.read_csv(\"/Users/inesschwartz/Desktop/cleandata/site_info.csv\")\n",
    "soil_type = pd.read_csv(\"/Users/inesschwartz/Desktop/cleandata/soil_type.csv\")\n",
    "climate = pd.read_csv(\"//Users/inesschwartz/Desktop/cleandata/climate_feat.csv\")\n",
    "topo = pd.read_csv(\"/Users/inesschwartz/Desktop/cleandata/topo_feat.csv\")\n",
    "geo = pd.read_csv(\"/Users/inesschwartz/Desktop/cleandata/geo_feat.csv\")\n",
    "geo_mapping = pd.read_csv(\"/Users/inesschwartz/Desktop/cleandata/geology_mapping.csv\")\n",
    "litho_mapping = pd.read_csv(\"/Users/inesschwartz/Desktop/cleandata/lithology_mapping.csv\")\n",
    "litho54_mapping = pd.read_csv(\"/Users/inesschwartz/Desktop/cleandata/lithology1954_mapping.csv\")\n",
    "\n",
    "#profile_record = pd.read_csv(\"/Users/inesschwartz/Desktop/cleandata/profile_record_clean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## checking csv datatypes before importing to db ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÑ File: analyses.csv\n",
      "lab_sample_id      int64\n",
      "analysis_id       object\n",
      "morpho_id         object\n",
      "sample_id         object\n",
      "profile           object\n",
      "                  ...   \n",
      "Tl               float64\n",
      "Pb               float64\n",
      "Bi               float64\n",
      "Th               float64\n",
      "U                float64\n",
      "Length: 72, dtype: object\n",
      "\n",
      "üìÑ File: soil_type.csv\n",
      "soil_type_id     int64\n",
      "profile         object\n",
      "CEP_GR          object\n",
      "CEP_NAME        object\n",
      "FAO             object\n",
      "dtype: object\n",
      "\n",
      "üìÑ File: geology_mapping.csv\n",
      "geology_code           object\n",
      "geology_description    object\n",
      "dtype: object\n",
      "\n",
      "üìÑ File: lithology1954_mapping.csv\n",
      "lithology_1954_code           object\n",
      "lithology_1954_description    object\n",
      "dtype: object\n",
      "\n",
      "üìÑ File: morpho.csv\n",
      "morpho_id                 object\n",
      "sample_id                float64\n",
      "profile                   object\n",
      "horizon_layer            float64\n",
      "upper_depth              float64\n",
      "lower_depth              float64\n",
      "moisture_degree           object\n",
      "root_quantity             object\n",
      "root_diameter             object\n",
      "texture                   object\n",
      "structure_type            object\n",
      "structure_class           object\n",
      "structure_degree          object\n",
      "pore_diameter             object\n",
      "pore_quantity             object\n",
      "pore_shape               float64\n",
      "dry_color_name            object\n",
      "dry_hue                   object\n",
      "dry_value                float64\n",
      "dry_chroma               float64\n",
      "moist_color_name          object\n",
      "moist_hue                 object\n",
      "moist_value              float64\n",
      "moist_chroma             float64\n",
      "compaction                object\n",
      "durability                object\n",
      "friability                object\n",
      "thick_contents_count      object\n",
      "thick_contents_nature     object\n",
      "dtype: object\n",
      "\n",
      "üìÑ File: samples.csv\n",
      "sample_id         int64\n",
      "profile          object\n",
      "year            float64\n",
      "shelf            object\n",
      "room             object\n",
      "site_info_id    float64\n",
      "dtype: object\n",
      "\n",
      "üìÑ File: site_info.csv\n",
      "site_info_id         int64\n",
      "profile             object\n",
      "X_coord            float64\n",
      "Y_coord            float64\n",
      "district            object\n",
      "geo_features_id      int64\n",
      "climate_id           int64\n",
      "topo_id              int64\n",
      "soil_type_id       float64\n",
      "dtype: object\n",
      "\n",
      "üìÑ File: lithology_mapping.csv\n",
      "lithology_code           object\n",
      "lithology_description    object\n",
      "dtype: object\n",
      "\n",
      "üìÑ File: topo_feat.csv\n",
      "topo_id                int64\n",
      "slope_code            object\n",
      "altitude             float64\n",
      "aspect               float64\n",
      "land_surface_temp    float64\n",
      "dem_elevation        float64\n",
      "dtype: object\n",
      "\n",
      "üìÑ File: geo_feat.csv\n",
      "geo_features_id       int64\n",
      "geology_id           object\n",
      "lithology_id         object\n",
      "lithology_1954_id    object\n",
      "dtype: object\n",
      "\n",
      "üìÑ File: climate_feat.csv\n",
      "climate_id                int64\n",
      "mean_annual_temp        float64\n",
      "mean_annual_precip      float64\n",
      "koppen_climate           object\n",
      "thornthwaite_climate     object\n",
      "hydric_regime            object\n",
      "thermal_regime           object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Set the path to your folder containing the 10 CSV files\n",
    "csv_folder = \"/Users/inesschwartz/Desktop/cleandata\"  \n",
    "\n",
    "# List all CSV files in the folder\n",
    "csv_files = [f for f in os.listdir(csv_folder) if f.endswith(\".csv\")]\n",
    "\n",
    "# Loop through each file and display column data types\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(csv_folder, file)\n",
    "    print(f\"\\nüìÑ File: {file}\")\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(df.dtypes)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error reading {file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Processing DataFrame: lab_analysis\n",
      "  üîß Converted column 'analysis_id' to object.\n",
      "  üîß Converted column 'sample_id' to object.\n",
      "  üîß Converted column 'profile' to object.\n",
      "‚úÖ Updated in memory: lab_analysis\n",
      "\n",
      "üìÇ Processing DataFrame: soil_type\n",
      "  üîß Converted column 'soil_type_id' to object.\n",
      "‚úÖ Updated in memory: soil_type\n",
      "\n",
      "üìÇ Processing DataFrame: site_info\n",
      "  üîß Converted column 'site_info_id' to object.\n",
      "  üîß Converted column 'profile' to object.\n",
      "  üîß Converted column 'climate_id' to object.\n",
      "  üîß Converted column 'geo_features_id' to object.\n",
      "  üîß Converted column 'topo_id' to object.\n",
      "  üîß Converted column 'soil_type_id' to object.\n",
      "‚úÖ Updated in memory: site_info\n",
      "\n",
      "üìÇ Processing DataFrame: topo\n",
      "  üîß Converted column 'topo_id' to object.\n",
      "‚úÖ Updated in memory: topo\n",
      "\n",
      "üìÇ Processing DataFrame: geo\n",
      "  üîß Converted column 'geo_features_id' to object.\n",
      "‚úÖ Updated in memory: geo\n",
      "\n",
      "üìÇ Processing DataFrame: climate\n",
      "  üîß Converted column 'climate_id' to object.\n",
      "‚úÖ Updated in memory: climate\n",
      "\n",
      "üéØ All specified columns converted to object dtype in memory.\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ STEP 1: Create a mapping of DataFrame objects to the columns to convert\n",
    "dataframe_column_map = {\n",
    "    \"lab_analysis\": (lab_analysis, [\"lab_analysis_id\", \"analysis_id\", \"sample_id\", \"profile\"]),\n",
    "    \"soil_type\": (soil_type, [\"soil_type_id\"]),\n",
    "    \"site_info\": (site_info, [\"site_info_id\", \"profile\", \"climate_id\", \"geo_features_id\", \"topo_id\", \"soil_type_id\"]),\n",
    "    \"topo\": (topo, [\"topo_id\"]),\n",
    "    \"geo\": (geo, [\"geo_features_id\"]),\n",
    "    \"climate\": (climate, [\"climate_id\"])\n",
    "}\n",
    "\n",
    "# ‚úÖ STEP 2: Define function to convert specified columns to object type\n",
    "def convert_columns_to_object(df, columns):\n",
    "    df = df.copy()\n",
    "    for col in columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].apply(\n",
    "                lambda x: str(int(x)) if pd.notna(x) and isinstance(x, (int, float)) and float(x).is_integer()\n",
    "                else str(x) if pd.notna(x)\n",
    "                else pd.NA\n",
    "            ).astype(\"object\")\n",
    "            print(f\"  üîß Converted column '{col}' to object.\")\n",
    "    return df\n",
    "\n",
    "# ‚úÖ STEP 3: Apply transformation to each DataFrame in memory\n",
    "for name, (df, columns) in dataframe_column_map.items():\n",
    "    print(f\"üìÇ Processing DataFrame: {name}\")\n",
    "    converted_df = convert_columns_to_object(df, columns)\n",
    "\n",
    "    # Optionally: overwrite the original DataFrame in memory\n",
    "    globals()[name] = converted_df\n",
    "\n",
    "    #Save updated file\n",
    "    converted_df.to_csv(f\"/Users/inesschwartz/Desktop/cleandata/{name}.csv\", index=False)\n",
    "    print(f\"‚úÖ Updated in memory: {name}\\n\")\n",
    "\n",
    "print(\"üéØ All specified columns converted to object dtype in memory.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataprep work below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding soil_biology_id column (just in case we add a biology table)\n",
    "lab_analysis['soil_biology_id'] = pd.NA\n",
    "\n",
    "# Define the final column order\n",
    "lab_analysis_final_columns = [\n",
    "    'lab_sample_id', 'analysis_id', 'morpho_id', 'sample_id', 'profile', 'soil_biology_id', 'EG', 'thick_clay', 'fine_clay', 'silt', 'clay', 'Eq_Hum', 'atm_1/3', 'atm_15',\n",
    "    'CACO3', 'gypsum', 'free_iron', 'organic_carbon', 'total_N', 'P205', 'organic_material', 'pH_H2O', 'pH_KCL',\n",
    "    'Ca++', 'Mg++', 'Na+', 'K+', 'exchangable_bases_sum', 'CEC', 'V', 'conductivity', 'soluble_sodium', 'Min_<0,002',\n",
    "    'Min_0,05-0,02', 'Min_0,2-0,05', 'Min_2-0,2', \n",
    "    'field_sample_code', 'Depth', 'Al', 'Si', 'P', 'S', 'Cl', 'Ti', 'Cr', 'Mn', 'Fe', 'Co', 'Ni', 'Cu', 'Zn',\n",
    "    'As', 'Se', 'Rb', 'Sr', 'Zr', 'Nb', 'Mo', 'Cd', 'Sn', 'Sb', 'Ba', 'Ta', 'W', 'Pt', 'Au', 'Hg', 'Tl', 'Pb', 'Bi',\n",
    "    'Th', 'U'\n",
    "]\n",
    "\n",
    "# Filter and save the cleaned DataFrame\n",
    "lab_analysis[lab_analysis_final_columns].to_csv('/Users/inesschwartz/Desktop/cleandata/analyses.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## completing site_info mapping table\n",
    "\n",
    "this is a mapping table to link site info, location to soil samples (which samples and when taken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_info_id</th>\n",
       "      <th>profile</th>\n",
       "      <th>X_coord</th>\n",
       "      <th>Y_coord</th>\n",
       "      <th>district</th>\n",
       "      <th>geo_features_id</th>\n",
       "      <th>climate_id</th>\n",
       "      <th>topo_id</th>\n",
       "      <th>soil_type_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2770</td>\n",
       "      <td>1_57</td>\n",
       "      <td>12.161278</td>\n",
       "      <td>-15.222598</td>\n",
       "      <td>Namibe</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>1_59</td>\n",
       "      <td>12.575775</td>\n",
       "      <td>-4.866986</td>\n",
       "      <td>Cabinda</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1618</td>\n",
       "      <td>1_61</td>\n",
       "      <td>15.098840</td>\n",
       "      <td>-11.225411</td>\n",
       "      <td>Cuanza Sul</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>881</td>\n",
       "      <td>1_63</td>\n",
       "      <td>17.081955</td>\n",
       "      <td>-9.274587</td>\n",
       "      <td>Malanje</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1750</td>\n",
       "      <td>1_64</td>\n",
       "      <td>20.788116</td>\n",
       "      <td>-11.568683</td>\n",
       "      <td>Moxico</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   site_info_id profile    X_coord    Y_coord    district  geo_features_id  \\\n",
       "0          2770    1_57  12.161278 -15.222598      Namibe                1   \n",
       "1            48    1_59  12.575775  -4.866986     Cabinda                2   \n",
       "2          1618    1_61  15.098840 -11.225411  Cuanza Sul                3   \n",
       "3           881    1_63  17.081955  -9.274587     Malanje                4   \n",
       "4          1750    1_64  20.788116 -11.568683      Moxico                5   \n",
       "\n",
       "   climate_id  topo_id  soil_type_id  \n",
       "0           1        1           2.0  \n",
       "1           2        2           3.0  \n",
       "2           3        3           NaN  \n",
       "3           4        4           4.0  \n",
       "4           5        5           NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "site_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ID'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ID'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Convert keys to string before merge to avoid dtype mismatch errors\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m site_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msite_info_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43msite_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m      3\u001b[0m geo[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m geo[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m      4\u001b[0m climate[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m climate[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/indexes/base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ID'"
     ]
    }
   ],
   "source": [
    "# Convert keys to string before merge to avoid dtype mismatch errors\n",
    "site_info['site_info_id'] = site_info['ID'].astype(str)\n",
    "geo['ID'] = geo['ID'].astype(str)\n",
    "climate['ID'] = climate['ID'].astype(str)\n",
    "topo['ID'] = topo['ID'].astype(str)\n",
    "\n",
    "# Drop old FK columns if they exist\n",
    "site_info = site_info.drop(\n",
    "    columns=['geo_features_id', 'climate_id', 'topo_features_id', 'district_id', 'land_cover_id', 'geology_id','topo_feature_id','soil_type_id', 'districts_id' ],\n",
    "    errors='ignore'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dropped 'ID' from site_info\n",
      "‚úÖ Dropped 'ID' from geo\n",
      "‚úÖ Dropped 'ID' from climate\n",
      "‚úÖ Dropped 'ID' from topo\n"
     ]
    }
   ],
   "source": [
    "# --- Step 1: Convert 'ID' columns to string ---\n",
    "site_info['ID'] = site_info['ID'].astype(str)\n",
    "geo['ID'] = geo['ID'].astype(str)\n",
    "climate['ID'] = climate['ID'].astype(str)\n",
    "topo['ID'] = topo['ID'].astype(str)\n",
    "\n",
    "# --- Step 2: Merge feature tables into site_info_clean ---\n",
    "site_info = site_info.merge(\n",
    "    geo[['ID', 'geo_features_id']],\n",
    "    on='ID',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "site_info = site_info.merge(\n",
    "    climate[['ID', 'climate_id']],\n",
    "    on='ID',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "site_info = site_info.merge(\n",
    "    topo[['ID', 'topo_id']],\n",
    "    on='ID',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# --- Step 3: Drop 'ID' column from all involved tables ---\n",
    "for table in ['site_info', 'geo', 'climate', 'topo']:\n",
    "    df = globals().get(table)\n",
    "    if df is not None and 'ID' in df.columns:\n",
    "        df = df.drop(columns=['ID'])\n",
    "        globals()[table] = df\n",
    "        print(f\"‚úÖ Dropped 'ID' from {table}\")\n",
    "    else:\n",
    "        print(f\"‚è≠Ô∏è Skipping {table}: not found or no 'ID' column\")\n",
    "\n",
    "# --- District: Skip merging district_id, use district name directly ---\n",
    "\n",
    "# don't see need for district_id, just use district name\n",
    "# For district (assuming district columns are already strings)\n",
    "# site_info_clean = site_info_clean.merge(\n",
    "#     district_clean[['district', 'district_id']],\n",
    "#     on='district',\n",
    "#     how='left'\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save updated csvs\n",
    "geo.to_csv('/Users/inesschwartz/Desktop/cleandata/geo_feat.csv', index=False)\n",
    "climate.to_csv('/Users/inesschwartz/Desktop/cleandata/climate_feat.csv', index = False)\n",
    "topo.to_csv('/Users/inesschwartz/Desktop/cleandata/topo_feat.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Ensure 'profile' columns are strings\n",
    "site_info['profile'] = site_info['profile'].astype(str)\n",
    "soil_type['profile'] = soil_type['profile'].astype(str)\n",
    "\n",
    "# Step 2: Merge 'soil_type_id' from soil_type into site_info via profile\n",
    "site_info = site_info.merge(\n",
    "    soil_type[['profile', 'soil_type_id']],\n",
    "    on='profile',\n",
    "    how='left'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "soil_type_id     int64\n",
       "profile         object\n",
       "CEP_GR          object\n",
       "CEP_NAME        object\n",
       "FAO             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soil_type.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "site_info_id         int64\n",
       "profile             object\n",
       "X_coord            float64\n",
       "Y_coord            float64\n",
       "district            object\n",
       "geo_features_id      int64\n",
       "climate_id           int64\n",
       "topo_id              int64\n",
       "soil_type_id_x     float64\n",
       "soil_type_id_y     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "site_info.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['soil_type_id'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Columns to convert to string\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m id_columns \u001b[38;5;241m=\u001b[39m \u001b[43msite_info\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgeo_features_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclimate_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtopo_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msoil_type_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Force conversion to string (robust handling of int, float, NaN)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m id_columns:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/frame.py:3767\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3766\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3767\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3769\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/indexes/base.py:5877\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5874\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5875\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 5877\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5879\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   5880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   5881\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/indexes/base.py:5941\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5938\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5940\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 5941\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['soil_type_id'] not in index\""
     ]
    }
   ],
   "source": [
    "# Columns to convert to string\n",
    "id_columns = site_info[[\"geo_features_id\", \"climate_id\", \"topo_id\", \"soil_type_id\"]]\n",
    "\n",
    "# Force conversion to string (robust handling of int, float, NaN)\n",
    "for col in id_columns:\n",
    "    if col in site_info.columns:\n",
    "        site_info[col] = site_info[col].apply(\n",
    "            lambda x: str(int(x)) if pd.notna(x) and isinstance(x, (float, int)) and float(x).is_integer()\n",
    "            else str(x) if pd.notna(x)\n",
    "            else pd.NA\n",
    "        ).astype(\"string\")\n",
    "        print(f\"‚úÖ Converted {col} to string.\")\n",
    "\n",
    "# Optional: verify the result\n",
    "print(\"\\nüìä Data types after conversion:\")\n",
    "print(site_info.dtypes)\n",
    "\n",
    "# # Save the updated CSV\n",
    "# site_info.to_csv(site_info_path, index=False)\n",
    "# print(\"\\nüíæ site_info.csv saved with updated string columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to csv\n",
    "site_info.to_csv('/Users/inesschwartz/Desktop/cleandata/site_info.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Completing samples table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>profile</th>\n",
       "      <th>year</th>\n",
       "      <th>shelf</th>\n",
       "      <th>room</th>\n",
       "      <th>site_info_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>630</td>\n",
       "      <td>139</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>631</td>\n",
       "      <td>139</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>632</td>\n",
       "      <td>139</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>633</td>\n",
       "      <td>139</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>687</td>\n",
       "      <td>208</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_id profile    year shelf room site_info_id\n",
       "0        630     139  1946.0     1   22          NaN\n",
       "1        631     139  1946.0     1   22          NaN\n",
       "2        632     139  1946.0     1   22          NaN\n",
       "3        633     139  1946.0     1   22          NaN\n",
       "4        687     208  1946.0     1   22          NaN"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_check.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop existing site_info_id, morpho_id, and lab_info_id columns if present\n",
    "samples_check = samples_check.drop(columns=['site_info_id', 'morpho_id', 'lab_info_id'], errors='ignore')\n",
    "\n",
    "# Merge site_info_id into samples_check using profile\n",
    "samples_check = samples_check.merge(\n",
    "    site_info[['site_info_id', 'profile']],\n",
    "    on='profile',\n",
    "    how='left'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unmatched profiles (missing site_info_id): 4070\n",
      "Profiles in samples_check with no match in site_info:\n",
      "['139' '208' '227' '238' '245' '252' '11' '6' '234' '221' '240' '1' '241'\n",
      " '280' '21-C' '16-C' '26-C' '165-C' '167-C' '262-C' '139-C' '128-C'\n",
      " '382-C' '526-C' '490-C' '492-C' '217-C' '192-C' '286-C' '420-C' '219-C'\n",
      " '462-C' '460-C' '39-C' '31-C' '207-C' '303-C' '1092' '1074' '1106' '1016'\n",
      " '1152' '1035' '1068' '1504' '1253' '1231' '1278' '1249' '1179' '1286'\n",
      " '1306' '1365' '1372' '1313' '1299' '1554' '1637' '1611' '1353' '1280'\n",
      " '378' '1364' '2055' '2391' '2215' '5' '4' '9' '10' '15' '17' '18' '19'\n",
      " '28' '24' '31' '20' '37' '33' '42' '48' '49' '53' '52' '57' '56' '62'\n",
      " '61' '65' '67' '85' '93' '95' '96' '98' '100' '103' '102' '101' '104'\n",
      " '113' '110' '111' '114' '118' '121' '122' '130' '138' '159' '162' '172'\n",
      " '183' '189' '214' '224' '228' '231' '243' '259' '286' '296' '298' '308'\n",
      " '303' '325' '336' '333' '337' '340' '348' '347' '362' '367' '370' '382'\n",
      " '392' '397' '400' '406' '402' '412' '414' '416' '419' '428' '427' '435'\n",
      " '441' '440' '446' '457' '455' '454' '459' '468' '465' '480' '475' '483'\n",
      " '484' '498' '512' '515' '517' '534' '535' '536' '542' '545' '549' '553'\n",
      " '127' '142' '144' '146' '152' '154' '160' '164' '167' '165' '177' '184'\n",
      " '195' '203' '207' '200' '239' '244' '250' '258' '263' '268' '272' '287'\n",
      " '301' '345' '350' '351' '360' '359' '375' '384' '390' '389' '408' '410'\n",
      " '411' '433' '434' '447' '445' '453' '460' '470' '478' '482' '487' '504'\n",
      " '503' '507' '521' '523' '525' '527' '532' '543' '544' '546' '548' '8' '7'\n",
      " '14' '13' '22' '29' '26' '32' '36' '40' '47' '50' '59' '66' '71' '75'\n",
      " '74' '80' '78' '87' '86' '82' '90' '81' '107' '105' '99' '115' '124'\n",
      " '123' '132' '131' '136' '135' '140' '150' '149' '147' '145' '155' '151'\n",
      " '163' '168' '166' '176' '174' '181' '182' '180' '191' '198' '196' '202'\n",
      " '211' '210' '215' '205' '206' '193' '217' '216' '220' '225' '246' '251'\n",
      " '261' '260' '266' '267' '271' '273' '27' '274' '276' '277' '282' '281'\n",
      " '283' '289' '293' '304' '302' '306' '305' '313' '312' '310' '318' '314'\n",
      " '324' '322' '321' '329' '335' '320' '331' '342' '349' '63' '60' '64' '72'\n",
      " 'NAN' '120' '125' '129' '134' '156' '175' '179' '188' '197' '194' '235'\n",
      " '236' '247' '254' '253' '257' '255' '307' '323' '55' '89' '148' '141'\n",
      " '171' '185' 'PII S2' 'PI S10 S' 'PI S11 S' 'PI S13 S' 'PI S14 S' 'PI S17'\n",
      " 'P IV S17' 'PI S19' 'PIV S19' 'PVI S17' 'PII S1 S' 'PI S3 S' 'PII S3 S'\n",
      " 'PI S6 S' 'PIII S10 S' 'P8_V S1' 'P11_IV S3' 'P13_IV S7 S' 'P21_II S1'\n",
      " 'P24_I S5' 'P26_I S3' 'P34_V S7 S' 'P38_II S5' 'P41_II S3' 'P42_II S10'\n",
      " 'P46_II S7 S' '27_57' '125_57' '260_57' '266_57' '270_57' '126_57'\n",
      " '275_57' '279_57' '280_57' '282_57' '292_57' '314_57' '324_57' '329_57'\n",
      " '185A_58' '213_58' 'A.S.' '127_57' '128_57' '129_57' '130_57' '131_57'\n",
      " '132_57' '133_57' '134_57' '135_57' '136_57' '137_57' '138_57' '139_57'\n",
      " '140_57' '141_57' '142_57' '143_57' '144_57' '145_57' '146_57' '147_57'\n",
      " '148_57' '149_57' '155_57' '156_57' '157_57' '158_57' '159_57' '160_57'\n",
      " '161_57' '162_57' '163_57' '164_57' '165_57' '166_57' '167_57' '184_57'\n",
      " '191_57' '293_59' '167_58' '1024_59' '1344_59' '1085_59' '1214_59'\n",
      " '1212_59' '1282_59' '1303_59' '1147_59' '1222_59' '1140_59' '1123_59'\n",
      " '1143_59' '1142_59' '1321_59' '1292_59' '1312_59' '1149_59' '1015_59'\n",
      " '1227_59' '976_59' '1032_59' '1036_59' '1138_59' '1035_59' '1033_59'\n",
      " '1266_59' '1141_59' '1159_59' '1218_59' '1220_59' '1168_59' '1258_59'\n",
      " '1023_59' '1051_59' '1074_59' '1049_59' '1054_59' '1339_59' '1337_59'\n",
      " '1191_59' '1324_59' '1165_59' '1305_59' '1271_59' '998_59' '1403_60'\n",
      " '1398_59' '1393_59' '1375_59' '967_59' '1322_59' '48_60' '58_60' '55_60'\n",
      " '144_60' '159_60' '65_60' '68_60' '77_60' '79_60' '37_60' '180_60'\n",
      " '95_60' '25_60' '22_60' '30_60' '125_60' '181_60' '42_60' '85_60'\n",
      " '103_60' '82_60' '39_60' '34_60' '57_60' '201_60' '183_60' '196_60'\n",
      " '251_60' '267_60' '209_60' '273_60' '302_60' '315_60' '398_60' '29C_60'\n",
      " '98C_60' '229C_60' '260C_60' '266C_60' '276C_60' '365_60' '364_60'\n",
      " '402_60' '388_60' 'P.47III1B' 'P.49III2B' 'P.53III3B' 'P.55III4B'\n",
      " 'P.43III5B' 'P.45III6' 'P.56III7A' 'P.138A' 'P.57III9B' '10_61' '15_61'\n",
      " '84_61' '105_61' '96_61' '242_61' '255_61' '258_61' '3_62' '29_62'\n",
      " '48_62' '184_62' '302_62' '215_62' '224_62' '53C_62' '56C_62' '263_62'\n",
      " '277_62' '278_62' 'S.P' '332_62' '1C_62' '2C_62' '4C_62' '8C_62' '19C_62'\n",
      " '17C_62' '33C_62' '27C_62' '28C_62' '37C_62' '85C_62' '69C_62' '68C_62'\n",
      " '67C_62' '73C_62' '72C_62' '71C_62' '84C_62' '74C_62' '79C_62' '363_62'\n",
      " '371_62' '373_62' '376_62' '378_62' '414_62' '425_62' '381_62' '509_62'\n",
      " '468_62' '519_62' '525_62' '536_62' '187C_62' '181C_62' '134C_62'\n",
      " '137C_62' '204C_62' '218C_62' '237C_62' '236C_62' '245C_62' '243C_62'\n",
      " '305C_62' '252C_62' '260C_62' '253C_62' '197C_62' '295C_62' '293C_62'\n",
      " '312C_62' '499C_62' '276C_62' '232C_62' '274C_59' '274C_61' 'C-74 PIIIA'\n",
      " 'C-671-PIV' 'C-911-PIV' 'E-235-PI6' 'E-797-MI' 'E-943-MI' '92C_53'\n",
      " '143C_53' '149C_53' '456_63' '43C_63' '382_63' '384_63' '379_63' '383_63'\n",
      " '381_63' '44_64' '7C_64' '50C_64' '158C_64' '162C_64' '180C_64' '46C_64'\n",
      " '118C_64' '134C_64' '204C_64' '206C_64' '219C_64' '189C_64' '166C_64'\n",
      " '167C_64' '177C_64' '1HB' '4H' '5H' '6H' '7HB' '9CS' '52_65' '65_65'\n",
      " '160_65' '118C_65' '182C_65' '149C_65' '209C_65' '241C_65' '323C_65'\n",
      " '343C_65' 'IC_65' 'IIC_65' 'IIIC_65' 'IVC_65' 'VC_65' 'VIC_65' '272_66'\n",
      " '6_67' '5_67' '10_67' '11_67' '15_67' '56_67' '57_67' '23_67' '32_67'\n",
      " '34_67' '36_67' '49_67' '153_67' '152_67' '151_67' '157_67' '169_67'\n",
      " '174_67' '173_67' '185_67' '61_67' '108_67' '52_67' '54_67' '77_67'\n",
      " '55_67' '62_67' '83_67' '76_67' '78_67' '126_67' '128_67' '129_67'\n",
      " '130_67' '28_67' '117_67' '118_67' '119_67' '120_67' '87_67' '82_67'\n",
      " '85_67' '80_67' '93_67' '184_67' '103_67' '104_67' '20_67' '21_67'\n",
      " '116_67' '122_67' '125_67' '24_67' '47_67' '50_67' '141_67' '252_67'\n",
      " '146_67' '176_67' '96_67' '135_67' '210_67' '254_67' '88_67' '89_67'\n",
      " '91_67' '92_67' '212_67' '187_67' '196_67' '231_67' '228_67' '189_67'\n",
      " '186_67' '220_67' '217_67' '94_67' '221_67' '357_67' '145_67' '99_67'\n",
      " '181_67' '179_67' '178_67' '223_67' '195_67' '194_67' '301_67' '199_67'\n",
      " '227_67' '234_67' '235_67' '188_67' '304_67' '302_67' '308_67' '306_67'\n",
      " '311_67' '326_67' '338_67' '336_67' '345_67' '342_67' '147_67' '269_67'\n",
      " '271_67' '273_67' '281_67' '276_67' '287_67' '293_67' '291_67' '288_67'\n",
      " '286_67' '284_67' '341_67' '343_67' '237_67' '239_67' '313_67' '315_67'\n",
      " '317_67' '318_67' '319_67' '312_67' '325_67' '323_67' '322_67' '334_67'\n",
      " '358_67' '351_67' '499_68' '499_69' '499_70' '498_68' '498_69' '498_70'\n",
      " '498_71' '543_68' '543_69' '500_68' '500_69' '500_70' '500_71' '503_68'\n",
      " '503_69' '503_70' '503_71' '503_72' '519_68' '515_68' '515_69' '515_70'\n",
      " '515_71' '517_67' '517_68' '517_69' '517_70' '517_71' '517_72' '507_67'\n",
      " '507_68' '507_69' '507_70' '507_71' '507_72' '508_68' '508_69' '508_70'\n",
      " '508_71' '516_68' '516_69' '493_68' '493_69']\n",
      "\n",
      "Frequency of unmatched profiles:\n",
      "profile\n",
      "A.S.      56\n",
      "NAN       28\n",
      "207       17\n",
      "167       16\n",
      "238       15\n",
      "          ..\n",
      "67         1\n",
      "85         1\n",
      "215_62     1\n",
      "98         1\n",
      "493_69     1\n",
      "Name: count, Length: 854, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 1. Check how many rows in samples_check are missing site_info_id\n",
    "missing_count = samples_check['site_info_id'].isna().sum()\n",
    "print(f\"Number of unmatched profiles (missing site_info_id): {missing_count}\")\n",
    "\n",
    "# 2. Show the unmatched profiles\n",
    "unmatched_profiles = samples_check[samples_check['site_info_id'].isna()]['profile'].unique()\n",
    "print(\"Profiles in samples_check with no match in site_info:\")\n",
    "print(unmatched_profiles)\n",
    "\n",
    "# Optional: count how many times each unmatched profile appears\n",
    "unmatched_counts = samples_check[samples_check['site_info_id'].isna()]['profile'].value_counts()\n",
    "print(\"\\nFrequency of unmatched profiles:\")\n",
    "print(unmatched_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_check.to_csv('/Users/inesschwartz/Desktop/cleandata/samples.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
